import { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types';
/**
  Feature ranking with recursive feature elimination.

  Given an external estimator that assigns weights to features (e.g., the coefficients of a linear model), the goal of recursive feature elimination (RFE) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through any specific attribute or callable. Then, the least important features are pruned from current set of features. That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached.

  Read more in the [User Guide](../feature_selection.html#rfe).

  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html)
 */
export declare class RFE {
    id: string;
    opts: any;
    _py: PythonBridge;
    _isInitialized: boolean;
    _isDisposed: boolean;
    constructor(opts?: {
        /**
          A supervised learning estimator with a `fit` method that provides information about feature importance (e.g. `coef\_`, `feature\_importances\_`).
         */
        estimator?: any;
        /**
          The number of features to select. If `undefined`, half of the features are selected. If integer, the parameter is the absolute number of features to select. If float between 0 and 1, it is the fraction of features to select.
         */
        n_features_to_select?: number;
        /**
          If greater than or equal to 1, then `step` corresponds to the (integer) number of features to remove at each iteration. If within (0.0, 1.0), then `step` corresponds to the percentage (rounded down) of features to remove at each iteration.
    
          @defaultValue `1`
         */
        step?: number;
        /**
          Controls verbosity of output.
    
          @defaultValue `0`
         */
        verbose?: number;
        /**
          If ‘auto’, uses the feature importance either through a `coef\_` or `feature\_importances\_` attributes of estimator.
    
          Also accepts a string that specifies an attribute name/path for extracting feature importance (implemented with `attrgetter`). For example, give `regressor\_.coef\_` in case of [`TransformedTargetRegressor`](sklearn.compose.TransformedTargetRegressor.html#sklearn.compose.TransformedTargetRegressor "sklearn.compose.TransformedTargetRegressor") or `named\_steps.clf.feature\_importances\_` in case of class:`~sklearn.pipeline.Pipeline` with its last step named `clf`.
    
          If `callable`, overrides the default feature importance getter. The callable is passed with the fitted estimator and it should return importance for each feature.
    
          @defaultValue `'auto'`
         */
        importance_getter?: string;
    });
    get py(): PythonBridge;
    set py(pythonBridge: PythonBridge);
    /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
    init(py: PythonBridge): Promise<void>;
    /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
    dispose(): Promise<void>;
    /**
      Compute the decision function of `X`.
     */
    decision_function(opts: {
        /**
          The input samples. Internally, it will be converted to `dtype=np.float32` and if a sparse matrix is provided to a sparse `csr\_matrix`.
         */
        X?: any[];
    }): Promise<any>;
    /**
      Fit the RFE model and then the underlying estimator on the selected features.
     */
    fit(opts: {
        /**
          The training input samples.
         */
        X?: ArrayLike | SparseMatrix[];
        /**
          The target values.
         */
        y?: ArrayLike;
        /**
          Additional parameters passed to the `fit` method of the underlying estimator.
         */
        fit_params?: any;
    }): Promise<any>;
    /**
      Fit to data, then transform it.
  
      Fits transformer to `X` and `y` with optional parameters `fit\_params` and returns a transformed version of `X`.
     */
    fit_transform(opts: {
        /**
          Input samples.
         */
        X?: ArrayLike[];
        /**
          Target values (`undefined` for unsupervised transformations).
         */
        y?: ArrayLike;
        /**
          Additional fit parameters.
         */
        fit_params?: any;
    }): Promise<any[]>;
    /**
      Mask feature names according to selected features.
     */
    get_feature_names_out(opts: {
        /**
          Input features.
         */
        input_features?: any;
    }): Promise<any>;
    /**
      Get a mask, or integer index, of the features selected.
     */
    get_support(opts: {
        /**
          If `true`, the return value will be an array of integers, rather than a boolean mask.
    
          @defaultValue `false`
         */
        indices?: boolean;
    }): Promise<any>;
    /**
      Reverse the transformation operation.
     */
    inverse_transform(opts: {
        /**
          The input samples.
         */
        X?: any;
    }): Promise<any>;
    /**
      Reduce X to the selected features and predict using the estimator.
     */
    predict(opts: {
        /**
          The input samples.
         */
        X?: any;
    }): Promise<any>;
    /**
      Predict class log-probabilities for X.
     */
    predict_log_proba(opts: {
        /**
          The input samples.
         */
        X?: any;
    }): Promise<any[]>;
    /**
      Predict class probabilities for X.
     */
    predict_proba(opts: {
        /**
          The input samples. Internally, it will be converted to `dtype=np.float32` and if a sparse matrix is provided to a sparse `csr\_matrix`.
         */
        X?: any[];
    }): Promise<any[]>;
    /**
      Reduce X to the selected features and return the score of the estimator.
     */
    score(opts: {
        /**
          The input samples.
         */
        X?: any;
        /**
          The target values.
         */
        y?: any;
        /**
          Parameters to pass to the `score` method of the underlying estimator.
         */
        fit_params?: any;
    }): Promise<number>;
    /**
      Set output container.
  
      See [Introducing the set\_output API](../../auto_examples/miscellaneous/plot_set_output.html#sphx-glr-auto-examples-miscellaneous-plot-set-output-py) for an example on how to use the API.
     */
    set_output(opts: {
        /**
          Configure output of `transform` and `fit\_transform`.
         */
        transform?: 'default' | 'pandas';
    }): Promise<any>;
    /**
      Reduce X to the selected features.
     */
    transform(opts: {
        /**
          The input samples.
         */
        X?: any;
    }): Promise<any>;
    /**
      The fitted estimator used to select features.
     */
    get estimator_(): Promise<any>;
    /**
      The number of selected features.
     */
    get n_features_(): Promise<number>;
    /**
      Number of features seen during [fit](../../glossary.html#term-fit). Only defined if the underlying estimator exposes such an attribute when fit.
     */
    get n_features_in_(): Promise<number>;
    /**
      Names of features seen during [fit](../../glossary.html#term-fit). Defined only when `X` has feature names that are all strings.
     */
    get feature_names_in_(): Promise<NDArray>;
    /**
      The feature ranking, such that `ranking\_\[i\]` corresponds to the ranking position of the i-th feature. Selected (i.e., estimated best) features are assigned rank 1.
     */
    get ranking_(): Promise<NDArray>;
    /**
      The mask of selected features.
     */
    get support_(): Promise<NDArray>;
}
//# sourceMappingURL=RFE.d.ts.map