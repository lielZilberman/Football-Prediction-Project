import { PythonBridge, NDArray, ArrayLike } from '@/sklearn/types';
/**
  LabelSpreading model for semi-supervised learning.

  This model is similar to the basic Label Propagation algorithm, but uses affinity matrix based on the normalized graph Laplacian and soft clamping across the labels.

  Read more in the [User Guide](../semi_supervised.html#label-propagation).

  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.semi_supervised.LabelSpreading.html)
 */
export declare class LabelSpreading {
    id: string;
    opts: any;
    _py: PythonBridge;
    _isInitialized: boolean;
    _isDisposed: boolean;
    constructor(opts?: {
        /**
          String identifier for kernel function to use or the kernel function itself. Only ‘rbf’ and ‘knn’ strings are valid inputs. The function passed should take two inputs, each of shape (n\_samples, n\_features), and return a (n\_samples, n\_samples) shaped weight matrix.
    
          @defaultValue `'rbf'`
         */
        kernel?: 'knn' | 'rbf';
        /**
          Parameter for rbf kernel.
    
          @defaultValue `20`
         */
        gamma?: number;
        /**
          Parameter for knn kernel which is a strictly positive integer.
    
          @defaultValue `7`
         */
        n_neighbors?: number;
        /**
          Clamping factor. A value in (0, 1) that specifies the relative amount that an instance should adopt the information from its neighbors as opposed to its initial label. alpha=0 means keeping the initial label information; alpha=1 means replacing all initial information.
    
          @defaultValue `0.2`
         */
        alpha?: number;
        /**
          Maximum number of iterations allowed.
    
          @defaultValue `30`
         */
        max_iter?: number;
        /**
          Convergence tolerance: threshold to consider the system at steady state.
    
          @defaultValue `0.001`
         */
        tol?: number;
        /**
          The number of parallel jobs to run. `undefined` means 1 unless in a [`joblib.parallel\_backend`](https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend "(in joblib v1.3.0.dev0)") context. `\-1` means using all processors. See [Glossary](../../glossary.html#term-n_jobs) for more details.
         */
        n_jobs?: number;
    });
    get py(): PythonBridge;
    set py(pythonBridge: PythonBridge);
    /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
    init(py: PythonBridge): Promise<void>;
    /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
    dispose(): Promise<void>;
    /**
      Fit a semi-supervised label propagation model to X.
  
      The input samples (labeled and unlabeled) are provided by matrix X, and target labels are provided by matrix y. We conventionally apply the label -1 to unlabeled samples in matrix y in a semi-supervised classification.
     */
    fit(opts: {
        /**
          Training data, where `n\_samples` is the number of samples and `n\_features` is the number of features.
         */
        X?: ArrayLike[];
        /**
          Target class values with unlabeled points marked as -1. All unlabeled samples will be transductively assigned labels internally, which are stored in `transduction\_`.
         */
        y?: ArrayLike;
    }): Promise<any>;
    /**
      Perform inductive inference across the model.
     */
    predict(opts: {
        /**
          The data matrix.
         */
        X?: ArrayLike[];
    }): Promise<NDArray>;
    /**
      Predict probability for each possible outcome.
  
      Compute the probability estimates for each single sample in X and each possible outcome seen during training (categorical distribution).
     */
    predict_proba(opts: {
        /**
          The data matrix.
         */
        X?: ArrayLike[];
    }): Promise<NDArray[]>;
    /**
      Return the mean accuracy on the given test data and labels.
  
      In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.
     */
    score(opts: {
        /**
          Test samples.
         */
        X?: ArrayLike[];
        /**
          True labels for `X`.
         */
        y?: ArrayLike;
        /**
          Sample weights.
         */
        sample_weight?: ArrayLike;
    }): Promise<number>;
    /**
      Input array.
     */
    get X_(): Promise<NDArray[]>;
    /**
      The distinct labels used in classifying instances.
     */
    get classes_(): Promise<NDArray>;
    /**
      Categorical distribution for each item.
     */
    get label_distributions_(): Promise<NDArray[]>;
    /**
      Label assigned to each item during [fit](../../glossary.html#term-fit).
     */
    get transduction_(): Promise<NDArray>;
    /**
      Number of features seen during [fit](../../glossary.html#term-fit).
     */
    get n_features_in_(): Promise<number>;
    /**
      Names of features seen during [fit](../../glossary.html#term-fit). Defined only when `X` has feature names that are all strings.
     */
    get feature_names_in_(): Promise<NDArray>;
    /**
      Number of iterations run.
     */
    get n_iter_(): Promise<number>;
}
//# sourceMappingURL=LabelSpreading.d.ts.map