import { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types';
/**
  Prediction voting regressor for unfitted estimators.

  A voting regressor is an ensemble meta-estimator that fits several base regressors, each on the whole dataset. Then it averages the individual predictions to form a final prediction.

  Read more in the [User Guide](../ensemble.html#voting-regressor).

  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingRegressor.html)
 */
export declare class VotingRegressor {
    id: string;
    opts: any;
    _py: PythonBridge;
    _isInitialized: boolean;
    _isDisposed: boolean;
    constructor(opts?: {
        /**
          Invoking the `fit` method on the `VotingRegressor` will fit clones of those original estimators that will be stored in the class attribute `self.estimators\_`. An estimator can be set to `'drop'` using [`set\_params`](#sklearn.ensemble.VotingRegressor.set_params "sklearn.ensemble.VotingRegressor.set_params").
         */
        estimators?: any;
        /**
          Sequence of weights (`float` or `int`) to weight the occurrences of predicted values before averaging. Uses uniform weights if `undefined`.
         */
        weights?: ArrayLike;
        /**
          The number of jobs to run in parallel for `fit`. `undefined` means 1 unless in a [`joblib.parallel\_backend`](https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend "(in joblib v1.3.0.dev0)") context. `\-1` means using all processors. See [Glossary](../../glossary.html#term-n_jobs) for more details.
         */
        n_jobs?: number;
        /**
          If `true`, the time elapsed while fitting will be printed as it is completed.
    
          @defaultValue `false`
         */
        verbose?: boolean;
    });
    get py(): PythonBridge;
    set py(pythonBridge: PythonBridge);
    /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
    init(py: PythonBridge): Promise<void>;
    /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
    dispose(): Promise<void>;
    /**
      Fit the estimators.
     */
    fit(opts: {
        /**
          Training vectors, where `n\_samples` is the number of samples and `n\_features` is the number of features.
         */
        X?: ArrayLike | SparseMatrix[];
        /**
          Target values.
         */
        y?: ArrayLike;
        /**
          Sample weights. If `undefined`, then samples are equally weighted. Note that this is supported only if all underlying estimators support sample weights.
         */
        sample_weight?: ArrayLike;
    }): Promise<any>;
    /**
      Return class labels or probabilities for each estimator.
  
      Return predictions for X for each estimator.
     */
    fit_transform(opts: {
        /**
          Input samples.
         */
        X?: ArrayLike | SparseMatrix[];
        /**
          Target values (`undefined` for unsupervised transformations).
         */
        y?: NDArray;
        /**
          Additional fit parameters.
         */
        fit_params?: any;
    }): Promise<any[]>;
    /**
      Get output feature names for transformation.
     */
    get_feature_names_out(opts: {
        /**
          Not used, present here for API consistency by convention.
         */
        input_features?: any;
    }): Promise<any>;
    /**
      Predict regression target for X.
  
      The predicted regression target of an input sample is computed as the mean predicted regression targets of the estimators in the ensemble.
     */
    predict(opts: {
        /**
          The input samples.
         */
        X?: ArrayLike | SparseMatrix[];
    }): Promise<NDArray>;
    /**
      Return the coefficient of determination of the prediction.
  
      The coefficient of determination \\(R^2\\) is defined as \\((1 - \\frac{u}{v})\\), where \\(u\\) is the residual sum of squares `((y\_true \- y\_pred)\*\* 2).sum()` and \\(v\\) is the total sum of squares `((y\_true \- y\_true.mean()) \*\* 2).sum()`. The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of `y`, disregarding the input features, would get a \\(R^2\\) score of 0.0.
     */
    score(opts: {
        /**
          Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape `(n\_samples, n\_samples\_fitted)`, where `n\_samples\_fitted` is the number of samples used in the fitting for the estimator.
         */
        X?: ArrayLike[];
        /**
          True values for `X`.
         */
        y?: ArrayLike;
        /**
          Sample weights.
         */
        sample_weight?: ArrayLike;
    }): Promise<number>;
    /**
      Set output container.
  
      See [Introducing the set\_output API](../../auto_examples/miscellaneous/plot_set_output.html#sphx-glr-auto-examples-miscellaneous-plot-set-output-py) for an example on how to use the API.
     */
    set_output(opts: {
        /**
          Configure output of `transform` and `fit\_transform`.
         */
        transform?: 'default' | 'pandas';
    }): Promise<any>;
    /**
      Return predictions for X for each estimator.
     */
    transform(opts: {
        /**
          The input samples.
         */
        X?: ArrayLike | SparseMatrix[];
    }): Promise<NDArray[]>;
    /**
      The collection of fitted sub-estimators as defined in `estimators` that are not ‘drop’.
     */
    get estimators_(): Promise<any>;
    /**
      Attribute to access any fitted sub-estimators by name.
     */
    get named_estimators_(): Promise<any>;
    /**
      Names of features seen during [fit](../../glossary.html#term-fit). Only defined if the underlying estimators expose such an attribute when fit.
     */
    get feature_names_in_(): Promise<NDArray>;
}
//# sourceMappingURL=VotingRegressor.d.ts.map