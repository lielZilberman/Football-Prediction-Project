import { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types';
/**
  Stack of estimators with a final classifier.

  Stacked generalization consists in stacking the output of individual estimator and use a classifier to compute the final prediction. Stacking allows to use the strength of each individual estimator by using their output as input of a final estimator.

  Note that `estimators\_` are fitted on the full `X` while `final\_estimator\_` is trained using cross-validated predictions of the base estimators using `cross\_val\_predict`.

  Read more in the [User Guide](../ensemble.html#stacking).

  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html)
 */
export declare class StackingClassifier {
    id: string;
    opts: any;
    _py: PythonBridge;
    _isInitialized: boolean;
    _isDisposed: boolean;
    constructor(opts?: {
        /**
          Base estimators which will be stacked together. Each element of the list is defined as a tuple of string (i.e. name) and an estimator instance. An estimator can be set to ‘drop’ using `set\_params`.
    
          The type of estimator is generally expected to be a classifier. However, one can pass a regressor for some use case (e.g. ordinal regression).
         */
        estimators?: any;
        /**
          A classifier which will be used to combine the base estimators. The default classifier is a [`LogisticRegression`](sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression "sklearn.linear_model.LogisticRegression").
         */
        final_estimator?: any;
        /**
          Determines the cross-validation splitting strategy used in `cross\_val\_predict` to train `final\_estimator`. Possible inputs for cv are:
         */
        cv?: number | 'prefit';
        /**
          Methods called for each base estimator. It can be:
    
          @defaultValue `'auto'`
         */
        stack_method?: 'auto' | 'predict_proba' | 'decision_function' | 'predict';
        /**
          The number of jobs to run in parallel all `estimators` `fit`. `undefined` means 1 unless in a `joblib.parallel\_backend` context. -1 means using all processors. See Glossary for more details.
         */
        n_jobs?: number;
        /**
          When `false`, only the predictions of estimators will be used as training data for `final\_estimator`. When `true`, the `final\_estimator` is trained on the predictions as well as the original training data.
    
          @defaultValue `false`
         */
        passthrough?: boolean;
        /**
          Verbosity level.
    
          @defaultValue `0`
         */
        verbose?: number;
    });
    get py(): PythonBridge;
    set py(pythonBridge: PythonBridge);
    /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
    init(py: PythonBridge): Promise<void>;
    /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
    dispose(): Promise<void>;
    /**
      Decision function for samples in `X` using the final estimator.
     */
    decision_function(opts: {
        /**
          Training vectors, where `n\_samples` is the number of samples and `n\_features` is the number of features.
         */
        X?: ArrayLike | SparseMatrix[];
    }): Promise<NDArray>;
    /**
      Fit the estimators.
     */
    fit(opts: {
        /**
          Training vectors, where `n\_samples` is the number of samples and `n\_features` is the number of features.
         */
        X?: ArrayLike | SparseMatrix[];
        /**
          Target values. Note that `y` will be internally encoded in numerically increasing order or lexicographic order. If the order matter (e.g. for ordinal regression), one should numerically encode the target `y` before calling [fit](../../glossary.html#term-fit).
         */
        y?: ArrayLike;
        /**
          Sample weights. If `undefined`, then samples are equally weighted. Note that this is supported only if all underlying estimators support sample weights.
         */
        sample_weight?: ArrayLike;
    }): Promise<any>;
    /**
      Fit to data, then transform it.
  
      Fits transformer to `X` and `y` with optional parameters `fit\_params` and returns a transformed version of `X`.
     */
    fit_transform(opts: {
        /**
          Input samples.
         */
        X?: ArrayLike[];
        /**
          Target values (`undefined` for unsupervised transformations).
         */
        y?: ArrayLike;
        /**
          Additional fit parameters.
         */
        fit_params?: any;
    }): Promise<any[]>;
    /**
      Get output feature names for transformation.
     */
    get_feature_names_out(opts: {
        /**
          Input features. The input feature names are only used when `passthrough` is `true`.
         */
        input_features?: any;
    }): Promise<any>;
    /**
      Predict target for X.
     */
    predict(opts: {
        /**
          Training vectors, where `n\_samples` is the number of samples and `n\_features` is the number of features.
         */
        X?: ArrayLike | SparseMatrix[];
        /**
          Parameters to the `predict` called by the `final\_estimator`. Note that this may be used to return uncertainties from some estimators with `return\_std` or `return\_cov`. Be aware that it will only accounts for uncertainty in the final estimator.
         */
        predict_params?: any;
    }): Promise<NDArray>;
    /**
      Predict class probabilities for `X` using the final estimator.
     */
    predict_proba(opts: {
        /**
          Training vectors, where `n\_samples` is the number of samples and `n\_features` is the number of features.
         */
        X?: ArrayLike | SparseMatrix[];
    }): Promise<NDArray[] | any[]>;
    /**
      Return the mean accuracy on the given test data and labels.
  
      In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.
     */
    score(opts: {
        /**
          Test samples.
         */
        X?: ArrayLike[];
        /**
          True labels for `X`.
         */
        y?: ArrayLike;
        /**
          Sample weights.
         */
        sample_weight?: ArrayLike;
    }): Promise<number>;
    /**
      Set output container.
  
      See [Introducing the set\_output API](../../auto_examples/miscellaneous/plot_set_output.html#sphx-glr-auto-examples-miscellaneous-plot-set-output-py) for an example on how to use the API.
     */
    set_output(opts: {
        /**
          Configure output of `transform` and `fit\_transform`.
         */
        transform?: 'default' | 'pandas';
    }): Promise<any>;
    /**
      Return class labels or probabilities for X for each estimator.
     */
    transform(opts: {
        /**
          Training vectors, where `n\_samples` is the number of samples and `n\_features` is the number of features.
         */
        X?: ArrayLike | SparseMatrix[];
    }): Promise<NDArray[]>;
    /**
      Class labels.
     */
    get classes_(): Promise<NDArray>;
    /**
      The elements of the `estimators` parameter, having been fitted on the training data. If an estimator has been set to `'drop'`, it will not appear in `estimators\_`. When `cv="prefit"`, `estimators\_` is set to `estimators` and is not fitted again.
     */
    get estimators_(): Promise<any>;
    /**
      Attribute to access any fitted sub-estimators by name.
     */
    get named_estimators_(): Promise<any>;
    /**
      Names of features seen during [fit](../../glossary.html#term-fit). Only defined if the underlying estimators expose such an attribute when fit.
     */
    get feature_names_in_(): Promise<NDArray>;
    /**
      The classifier which predicts given the output of `estimators\_`.
     */
    get final_estimator_(): Promise<any>;
    /**
      The method used by each base estimator.
     */
    get stack_method_(): Promise<any>;
}
//# sourceMappingURL=StackingClassifier.d.ts.map