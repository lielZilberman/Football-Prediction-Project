import { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types';
/**
  An AdaBoost regressor.

  An AdaBoost \[1\] regressor is a meta-estimator that begins by fitting a regressor on the original dataset and then fits additional copies of the regressor on the same dataset but where the weights of instances are adjusted according to the error of the current prediction. As such, subsequent regressors focus more on difficult cases.

  This class implements the algorithm known as AdaBoost.R2 \[2\].

  Read more in the [User Guide](../ensemble.html#adaboost).

  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html)
 */
export declare class AdaBoostRegressor {
    id: string;
    opts: any;
    _py: PythonBridge;
    _isInitialized: boolean;
    _isDisposed: boolean;
    constructor(opts?: {
        /**
          The base estimator from which the boosted ensemble is built. If `undefined`, then the base estimator is [`DecisionTreeRegressor`](sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor "sklearn.tree.DecisionTreeRegressor") initialized with `max\_depth=3`.
         */
        estimator?: any;
        /**
          The maximum number of estimators at which boosting is terminated. In case of perfect fit, the learning procedure is stopped early. Values must be in the range `\[1, inf)`.
    
          @defaultValue `50`
         */
        n_estimators?: number;
        /**
          Weight applied to each regressor at each boosting iteration. A higher learning rate increases the contribution of each regressor. There is a trade-off between the `learning\_rate` and `n\_estimators` parameters. Values must be in the range `(0.0, inf)`.
    
          @defaultValue `1`
         */
        learning_rate?: number;
        /**
          The loss function to use when updating the weights after each boosting iteration.
    
          @defaultValue `'linear'`
         */
        loss?: 'linear' | 'square' | 'exponential';
        /**
          Controls the random seed given at each `estimator` at each boosting iteration. Thus, it is only used when `estimator` exposes a `random\_state`. In addition, it controls the bootstrap of the weights used to train the `estimator` at each boosting iteration. Pass an int for reproducible output across multiple function calls. See [Glossary](../../glossary.html#term-random_state).
         */
        random_state?: number;
        /**
          The base estimator from which the boosted ensemble is built. If `undefined`, then the base estimator is [`DecisionTreeRegressor`](sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor "sklearn.tree.DecisionTreeRegressor") initialized with `max\_depth=3`.
         */
        base_estimator?: any;
    });
    get py(): PythonBridge;
    set py(pythonBridge: PythonBridge);
    /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
    init(py: PythonBridge): Promise<void>;
    /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
    dispose(): Promise<void>;
    /**
      Build a boosted classifier/regressor from the training set (X, y).
     */
    fit(opts: {
        /**
          The training input samples. Sparse matrix can be CSC, CSR, COO, DOK, or LIL. COO, DOK, and LIL are converted to CSR.
         */
        X?: ArrayLike | SparseMatrix[];
        /**
          The target values.
         */
        y?: ArrayLike;
        /**
          Sample weights. If `undefined`, the sample weights are initialized to 1 / n\_samples.
         */
        sample_weight?: ArrayLike;
    }): Promise<any>;
    /**
      Predict regression value for X.
  
      The predicted regression value of an input sample is computed as the weighted median prediction of the regressors in the ensemble.
     */
    predict(opts: {
        /**
          The training input samples. Sparse matrix can be CSC, CSR, COO, DOK, or LIL. COO, DOK, and LIL are converted to CSR.
         */
        X?: ArrayLike | SparseMatrix[];
    }): Promise<NDArray>;
    /**
      Return the coefficient of determination of the prediction.
  
      The coefficient of determination \\(R^2\\) is defined as \\((1 - \\frac{u}{v})\\), where \\(u\\) is the residual sum of squares `((y\_true \- y\_pred)\*\* 2).sum()` and \\(v\\) is the total sum of squares `((y\_true \- y\_true.mean()) \*\* 2).sum()`. The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of `y`, disregarding the input features, would get a \\(R^2\\) score of 0.0.
     */
    score(opts: {
        /**
          Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape `(n\_samples, n\_samples\_fitted)`, where `n\_samples\_fitted` is the number of samples used in the fitting for the estimator.
         */
        X?: ArrayLike[];
        /**
          True values for `X`.
         */
        y?: ArrayLike;
        /**
          Sample weights.
         */
        sample_weight?: ArrayLike;
    }): Promise<number>;
    /**
      Return staged predictions for X.
  
      The predicted regression value of an input sample is computed as the weighted median prediction of the regressors in the ensemble.
  
      This generator method yields the ensemble prediction after each iteration of boosting and therefore allows monitoring, such as to determine the prediction on a test set after each boost.
     */
    staged_predict(opts: {
        /**
          The training input samples.
         */
        X?: ArrayLike | SparseMatrix[];
    }): Promise<any[]>;
    /**
      Return staged scores for X, y.
  
      This generator method yields the ensemble score after each iteration of boosting and therefore allows monitoring, such as to determine the score on a test set after each boost.
     */
    staged_score(opts: {
        /**
          The training input samples. Sparse matrix can be CSC, CSR, COO, DOK, or LIL. COO, DOK, and LIL are converted to CSR.
         */
        X?: ArrayLike | SparseMatrix[];
        /**
          Labels for X.
         */
        y?: ArrayLike;
        /**
          Sample weights.
         */
        sample_weight?: ArrayLike;
    }): Promise<number>;
    /**
      The base estimator from which the ensemble is grown.
     */
    get estimator_(): Promise<any>;
    /**
      The collection of fitted sub-estimators.
     */
    get estimators_(): Promise<any>;
    /**
      Weights for each estimator in the boosted ensemble.
     */
    get estimator_weights_(): Promise<any>;
    /**
      Regression error for each estimator in the boosted ensemble.
     */
    get estimator_errors_(): Promise<any>;
    /**
      Number of features seen during [fit](../../glossary.html#term-fit).
     */
    get n_features_in_(): Promise<number>;
    /**
      Names of features seen during [fit](../../glossary.html#term-fit). Defined only when `X` has feature names that are all strings.
     */
    get feature_names_in_(): Promise<NDArray>;
}
//# sourceMappingURL=AdaBoostRegressor.d.ts.map