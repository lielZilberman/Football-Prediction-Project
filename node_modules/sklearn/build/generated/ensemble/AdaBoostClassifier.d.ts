import { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types';
/**
  An AdaBoost classifier.

  An AdaBoost \[1\] classifier is a meta-estimator that begins by fitting a classifier on the original dataset and then fits additional copies of the classifier on the same dataset but where the weights of incorrectly classified instances are adjusted such that subsequent classifiers focus more on difficult cases.

  This class implements the algorithm known as AdaBoost-SAMME \[2\].

  Read more in the [User Guide](../ensemble.html#adaboost).

  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html)
 */
export declare class AdaBoostClassifier {
    id: string;
    opts: any;
    _py: PythonBridge;
    _isInitialized: boolean;
    _isDisposed: boolean;
    constructor(opts?: {
        /**
          The base estimator from which the boosted ensemble is built. Support for sample weighting is required, as well as proper `classes\_` and `n\_classes\_` attributes. If `undefined`, then the base estimator is [`DecisionTreeClassifier`](sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier "sklearn.tree.DecisionTreeClassifier") initialized with `max\_depth=1`.
         */
        estimator?: any;
        /**
          The maximum number of estimators at which boosting is terminated. In case of perfect fit, the learning procedure is stopped early. Values must be in the range `\[1, inf)`.
    
          @defaultValue `50`
         */
        n_estimators?: number;
        /**
          Weight applied to each classifier at each boosting iteration. A higher learning rate increases the contribution of each classifier. There is a trade-off between the `learning\_rate` and `n\_estimators` parameters. Values must be in the range `(0.0, inf)`.
    
          @defaultValue `1`
         */
        learning_rate?: number;
        /**
          If ‘SAMME.R’ then use the SAMME.R real boosting algorithm. `estimator` must support calculation of class probabilities. If ‘SAMME’ then use the SAMME discrete boosting algorithm. The SAMME.R algorithm typically converges faster than SAMME, achieving a lower test error with fewer boosting iterations.
    
          @defaultValue `'SAMME.R'`
         */
        algorithm?: 'SAMME' | 'SAMME.R';
        /**
          Controls the random seed given at each `estimator` at each boosting iteration. Thus, it is only used when `estimator` exposes a `random\_state`. Pass an int for reproducible output across multiple function calls. See [Glossary](../../glossary.html#term-random_state).
         */
        random_state?: number;
        /**
          The base estimator from which the boosted ensemble is built. Support for sample weighting is required, as well as proper `classes\_` and `n\_classes\_` attributes. If `undefined`, then the base estimator is [`DecisionTreeClassifier`](sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier "sklearn.tree.DecisionTreeClassifier") initialized with `max\_depth=1`.
         */
        base_estimator?: any;
    });
    get py(): PythonBridge;
    set py(pythonBridge: PythonBridge);
    /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
    init(py: PythonBridge): Promise<void>;
    /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
    dispose(): Promise<void>;
    /**
      Compute the decision function of `X`.
     */
    decision_function(opts: {
        /**
          The training input samples. Sparse matrix can be CSC, CSR, COO, DOK, or LIL. COO, DOK, and LIL are converted to CSR.
         */
        X?: ArrayLike | SparseMatrix[];
    }): Promise<any>;
    /**
      Build a boosted classifier/regressor from the training set (X, y).
     */
    fit(opts: {
        /**
          The training input samples. Sparse matrix can be CSC, CSR, COO, DOK, or LIL. COO, DOK, and LIL are converted to CSR.
         */
        X?: ArrayLike | SparseMatrix[];
        /**
          The target values.
         */
        y?: ArrayLike;
        /**
          Sample weights. If `undefined`, the sample weights are initialized to 1 / n\_samples.
         */
        sample_weight?: ArrayLike;
    }): Promise<any>;
    /**
      Predict classes for X.
  
      The predicted class of an input sample is computed as the weighted mean prediction of the classifiers in the ensemble.
     */
    predict(opts: {
        /**
          The training input samples. Sparse matrix can be CSC, CSR, COO, DOK, or LIL. COO, DOK, and LIL are converted to CSR.
         */
        X?: ArrayLike | SparseMatrix[];
    }): Promise<NDArray>;
    /**
      Predict class log-probabilities for X.
  
      The predicted class log-probabilities of an input sample is computed as the weighted mean predicted class log-probabilities of the classifiers in the ensemble.
     */
    predict_log_proba(opts: {
        /**
          The training input samples. Sparse matrix can be CSC, CSR, COO, DOK, or LIL. COO, DOK, and LIL are converted to CSR.
         */
        X?: ArrayLike | SparseMatrix[];
    }): Promise<NDArray[]>;
    /**
      Predict class probabilities for X.
  
      The predicted class probabilities of an input sample is computed as the weighted mean predicted class probabilities of the classifiers in the ensemble.
     */
    predict_proba(opts: {
        /**
          The training input samples. Sparse matrix can be CSC, CSR, COO, DOK, or LIL. COO, DOK, and LIL are converted to CSR.
         */
        X?: ArrayLike | SparseMatrix[];
    }): Promise<NDArray[]>;
    /**
      Return the mean accuracy on the given test data and labels.
  
      In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.
     */
    score(opts: {
        /**
          Test samples.
         */
        X?: ArrayLike[];
        /**
          True labels for `X`.
         */
        y?: ArrayLike;
        /**
          Sample weights.
         */
        sample_weight?: ArrayLike;
    }): Promise<number>;
    /**
      Compute decision function of `X` for each boosting iteration.
  
      This method allows monitoring (i.e. determine error on testing set) after each boosting iteration.
     */
    staged_decision_function(opts: {
        /**
          The training input samples. Sparse matrix can be CSC, CSR, COO, DOK, or LIL. COO, DOK, and LIL are converted to CSR.
         */
        X?: ArrayLike | SparseMatrix[];
    }): Promise<any[]>;
    /**
      Return staged predictions for X.
  
      The predicted class of an input sample is computed as the weighted mean prediction of the classifiers in the ensemble.
  
      This generator method yields the ensemble prediction after each iteration of boosting and therefore allows monitoring, such as to determine the prediction on a test set after each boost.
     */
    staged_predict(opts: {
        /**
          The input samples. Sparse matrix can be CSC, CSR, COO, DOK, or LIL. COO, DOK, and LIL are converted to CSR.
         */
        X?: ArrayLike[];
    }): Promise<any[]>;
    /**
      Predict class probabilities for X.
  
      The predicted class probabilities of an input sample is computed as the weighted mean predicted class probabilities of the classifiers in the ensemble.
  
      This generator method yields the ensemble predicted class probabilities after each iteration of boosting and therefore allows monitoring, such as to determine the predicted class probabilities on a test set after each boost.
     */
    staged_predict_proba(opts: {
        /**
          The training input samples. Sparse matrix can be CSC, CSR, COO, DOK, or LIL. COO, DOK, and LIL are converted to CSR.
         */
        X?: ArrayLike | SparseMatrix[];
    }): Promise<any[]>;
    /**
      Return staged scores for X, y.
  
      This generator method yields the ensemble score after each iteration of boosting and therefore allows monitoring, such as to determine the score on a test set after each boost.
     */
    staged_score(opts: {
        /**
          The training input samples. Sparse matrix can be CSC, CSR, COO, DOK, or LIL. COO, DOK, and LIL are converted to CSR.
         */
        X?: ArrayLike | SparseMatrix[];
        /**
          Labels for X.
         */
        y?: ArrayLike;
        /**
          Sample weights.
         */
        sample_weight?: ArrayLike;
    }): Promise<number>;
    /**
      The base estimator from which the ensemble is grown.
     */
    get estimator_(): Promise<any>;
    /**
      The collection of fitted sub-estimators.
     */
    get estimators_(): Promise<any>;
    /**
      The classes labels.
     */
    get classes_(): Promise<NDArray>;
    /**
      The number of classes.
     */
    get n_classes_(): Promise<number>;
    /**
      Weights for each estimator in the boosted ensemble.
     */
    get estimator_weights_(): Promise<any>;
    /**
      Classification error for each estimator in the boosted ensemble.
     */
    get estimator_errors_(): Promise<any>;
    /**
      Number of features seen during [fit](../../glossary.html#term-fit).
     */
    get n_features_in_(): Promise<number>;
    /**
      Names of features seen during [fit](../../glossary.html#term-fit). Defined only when `X` has feature names that are all strings.
     */
    get feature_names_in_(): Promise<NDArray>;
}
//# sourceMappingURL=AdaBoostClassifier.d.ts.map