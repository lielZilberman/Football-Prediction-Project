import { PythonBridge, NDArray, ArrayLike } from '@/sklearn/types';
/**
  Isotonic regression model.

  Read more in the [User Guide](../isotonic.html#isotonic).

  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.isotonic.IsotonicRegression.html)
 */
export declare class IsotonicRegression {
    id: string;
    opts: any;
    _py: PythonBridge;
    _isInitialized: boolean;
    _isDisposed: boolean;
    constructor(opts?: {
        /**
          Lower bound on the lowest predicted value (the minimum value may still be higher). If not set, defaults to -inf.
         */
        y_min?: number;
        /**
          Upper bound on the highest predicted value (the maximum may still be lower). If not set, defaults to +inf.
         */
        y_max?: number;
        /**
          Determines whether the predictions should be constrained to increase or decrease with `X`. ‘auto’ will decide based on the Spearman correlation estimate’s sign.
    
          @defaultValue `true`
         */
        increasing?: boolean | 'auto';
        /**
          Handles how `X` values outside of the training domain are handled during prediction.
    
          @defaultValue `'nan'`
         */
        out_of_bounds?: 'nan' | 'clip' | 'raise';
    });
    get py(): PythonBridge;
    set py(pythonBridge: PythonBridge);
    /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
    init(py: PythonBridge): Promise<void>;
    /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
    dispose(): Promise<void>;
    /**
      Fit the model using X, y as training data.
     */
    fit(opts: {
        /**
          Training data.
         */
        X?: ArrayLike | number;
        /**
          Training target.
         */
        y?: ArrayLike;
        /**
          Weights. If set to `undefined`, all weights will be set to 1 (equal weights).
         */
        sample_weight?: ArrayLike;
    }): Promise<any>;
    /**
      Fit to data, then transform it.
  
      Fits transformer to `X` and `y` with optional parameters `fit\_params` and returns a transformed version of `X`.
     */
    fit_transform(opts: {
        /**
          Input samples.
         */
        X?: ArrayLike[];
        /**
          Target values (`undefined` for unsupervised transformations).
         */
        y?: ArrayLike;
        /**
          Additional fit parameters.
         */
        fit_params?: any;
    }): Promise<any[]>;
    /**
      Get output feature names for transformation.
     */
    get_feature_names_out(opts: {
        /**
          Ignored.
         */
        input_features?: any;
    }): Promise<any>;
    /**
      Predict new data by linear interpolation.
     */
    predict(opts: {
        /**
          Data to transform.
         */
        T?: ArrayLike | number;
    }): Promise<NDArray>;
    /**
      Return the coefficient of determination of the prediction.
  
      The coefficient of determination \\(R^2\\) is defined as \\((1 - \\frac{u}{v})\\), where \\(u\\) is the residual sum of squares `((y\_true \- y\_pred)\*\* 2).sum()` and \\(v\\) is the total sum of squares `((y\_true \- y\_true.mean()) \*\* 2).sum()`. The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of `y`, disregarding the input features, would get a \\(R^2\\) score of 0.0.
     */
    score(opts: {
        /**
          Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape `(n\_samples, n\_samples\_fitted)`, where `n\_samples\_fitted` is the number of samples used in the fitting for the estimator.
         */
        X?: ArrayLike[];
        /**
          True values for `X`.
         */
        y?: ArrayLike;
        /**
          Sample weights.
         */
        sample_weight?: ArrayLike;
    }): Promise<number>;
    /**
      Set output container.
  
      See [Introducing the set\_output API](../../auto_examples/miscellaneous/plot_set_output.html#sphx-glr-auto-examples-miscellaneous-plot-set-output-py) for an example on how to use the API.
     */
    set_output(opts: {
        /**
          Configure output of `transform` and `fit\_transform`.
         */
        transform?: 'default' | 'pandas';
    }): Promise<any>;
    /**
      Transform new data by linear interpolation.
     */
    transform(opts: {
        /**
          Data to transform.
         */
        T?: ArrayLike | number;
    }): Promise<NDArray>;
    /**
      Minimum value of input array `X\_` for left bound.
     */
    get X_min_(): Promise<number>;
    /**
      Maximum value of input array `X\_` for right bound.
     */
    get X_max_(): Promise<number>;
    /**
      Unique ascending `X` values used to interpolate the y = f(X) monotonic function.
     */
    get X_thresholds_(): Promise<NDArray>;
    /**
      De-duplicated `y` values suitable to interpolate the y = f(X) monotonic function.
     */
    get y_thresholds_(): Promise<NDArray>;
    /**
      The stepwise interpolating function that covers the input domain `X`.
     */
    get f_(): Promise<any>;
    /**
      Inferred value for `increasing`.
     */
    get increasing_(): Promise<boolean>;
}
//# sourceMappingURL=IsotonicRegression.d.ts.map