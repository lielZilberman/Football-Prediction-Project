import { PythonBridge, NDArray, ArrayLike } from '@/sklearn/types';
/**
  Multivariate imputer that estimates each feature from all the others.

  A strategy for imputing missing values by modeling each feature with missing values as a function of other features in a round-robin fashion.

  Read more in the [User Guide](../impute.html#iterative-imputer).

  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.impute.IterativeImputer.html)
 */
export declare class IterativeImputer {
    id: string;
    opts: any;
    _py: PythonBridge;
    _isInitialized: boolean;
    _isDisposed: boolean;
    constructor(opts?: {
        /**
          The estimator to use at each step of the round-robin imputation. If `sample\_posterior=True`, the estimator must support `return\_std` in its `predict` method.
         */
        estimator?: any;
        /**
          The placeholder for the missing values. All occurrences of `missing\_values` will be imputed. For pandas’ dataframes with nullable integer dtypes with missing values, `missing\_values` should be set to `np.nan`, since `pd.NA` will be converted to `np.nan`.
         */
        missing_values?: number;
        /**
          Whether to sample from the (Gaussian) predictive posterior of the fitted estimator for each imputation. Estimator must support `return\_std` in its `predict` method if set to `true`. Set to `true` if using `IterativeImputer` for multiple imputations.
    
          @defaultValue `false`
         */
        sample_posterior?: boolean;
        /**
          Maximum number of imputation rounds to perform before returning the imputations computed during the final round. A round is a single imputation of each feature with missing values. The stopping criterion is met once `max(abs(X\_t \- X\_{t-1}))/max(abs(X\[known\_vals\])) < tol`, where `X\_t` is `X` at iteration `t`. Note that early stopping is only applied if `sample\_posterior=False`.
    
          @defaultValue `10`
         */
        max_iter?: number;
        /**
          Tolerance of the stopping condition.
    
          @defaultValue `0.001`
         */
        tol?: number;
        /**
          Number of other features to use to estimate the missing values of each feature column. Nearness between features is measured using the absolute correlation coefficient between each feature pair (after initial imputation). To ensure coverage of features throughout the imputation process, the neighbor features are not necessarily nearest, but are drawn with probability proportional to correlation for each imputed target feature. Can provide significant speed-up when the number of features is huge. If `undefined`, all features will be used.
         */
        n_nearest_features?: number;
        /**
          Which strategy to use to initialize the missing values. Same as the `strategy` parameter in [`SimpleImputer`](sklearn.impute.SimpleImputer.html#sklearn.impute.SimpleImputer "sklearn.impute.SimpleImputer").
    
          @defaultValue `'mean'`
         */
        initial_strategy?: 'mean' | 'median' | 'most_frequent' | 'constant';
        /**
          The order in which the features will be imputed. Possible values:
    
          @defaultValue `'ascending'`
         */
        imputation_order?: 'ascending' | 'descending' | 'roman' | 'arabic' | 'random';
        /**
          If `true` then features with missing values during [`transform`](#sklearn.impute.IterativeImputer.transform "sklearn.impute.IterativeImputer.transform") which did not have any missing values during [`fit`](#sklearn.impute.IterativeImputer.fit "sklearn.impute.IterativeImputer.fit") will be imputed with the initial imputation method only. Set to `true` if you have many features with no missing values at both [`fit`](#sklearn.impute.IterativeImputer.fit "sklearn.impute.IterativeImputer.fit") and [`transform`](#sklearn.impute.IterativeImputer.transform "sklearn.impute.IterativeImputer.transform") time to save compute.
    
          @defaultValue `false`
         */
        skip_complete?: boolean;
        /**
          Minimum possible imputed value. Broadcast to shape `(n\_features,)` if scalar. If array-like, expects shape `(n\_features,)`, one min value for each feature. The default is `\-np.inf`.
         */
        min_value?: number | ArrayLike;
        /**
          Maximum possible imputed value. Broadcast to shape `(n\_features,)` if scalar. If array-like, expects shape `(n\_features,)`, one max value for each feature. The default is `np.inf`.
         */
        max_value?: number | ArrayLike;
        /**
          Verbosity flag, controls the debug messages that are issued as functions are evaluated. The higher, the more verbose. Can be 0, 1, or 2.
    
          @defaultValue `0`
         */
        verbose?: number;
        /**
          The seed of the pseudo random number generator to use. Randomizes selection of estimator features if `n\_nearest\_features` is not `undefined`, the `imputation\_order` if `random`, and the sampling from posterior if `sample\_posterior=True`. Use an integer for determinism. See [the Glossary](../../glossary.html#term-random_state).
         */
        random_state?: number;
        /**
          If `true`, a [`MissingIndicator`](sklearn.impute.MissingIndicator.html#sklearn.impute.MissingIndicator "sklearn.impute.MissingIndicator") transform will stack onto output of the imputer’s transform. This allows a predictive estimator to account for missingness despite imputation. If a feature has no missing values at fit/train time, the feature won’t appear on the missing indicator even if there are missing values at transform/test time.
    
          @defaultValue `false`
         */
        add_indicator?: boolean;
        /**
          If `true`, features that consist exclusively of missing values when `fit` is called are returned in results when `transform` is called. The imputed value is always `0` except when `initial\_strategy="constant"` in which case `fill\_value` will be used instead.
    
          @defaultValue `false`
         */
        keep_empty_features?: boolean;
    });
    get py(): PythonBridge;
    set py(pythonBridge: PythonBridge);
    /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
    init(py: PythonBridge): Promise<void>;
    /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
    dispose(): Promise<void>;
    /**
      Fit the imputer on `X` and return self.
     */
    fit(opts: {
        /**
          Input data, where `n\_samples` is the number of samples and `n\_features` is the number of features.
         */
        X?: ArrayLike;
        /**
          Not used, present for API consistency by convention.
         */
        y?: any;
    }): Promise<any>;
    /**
      Fit the imputer on `X` and return the transformed `X`.
     */
    fit_transform(opts: {
        /**
          Input data, where `n\_samples` is the number of samples and `n\_features` is the number of features.
         */
        X?: ArrayLike;
        /**
          Not used, present for API consistency by convention.
         */
        y?: any;
    }): Promise<ArrayLike>;
    /**
      Get output feature names for transformation.
     */
    get_feature_names_out(opts: {
        /**
          Input features.
         */
        input_features?: any;
    }): Promise<any>;
    /**
      Set output container.
  
      See [Introducing the set\_output API](../../auto_examples/miscellaneous/plot_set_output.html#sphx-glr-auto-examples-miscellaneous-plot-set-output-py) for an example on how to use the API.
     */
    set_output(opts: {
        /**
          Configure output of `transform` and `fit\_transform`.
         */
        transform?: 'default' | 'pandas';
    }): Promise<any>;
    /**
      Impute all missing values in `X`.
  
      Note that this is stochastic, and that if `random\_state` is not fixed, repeated calls, or permuted input, results will differ.
     */
    transform(opts: {
        /**
          The input data to complete.
         */
        X?: ArrayLike[];
    }): Promise<ArrayLike>;
    /**
      Imputer used to initialize the missing values.
     */
    get initial_imputer_(): Promise<any>;
    /**
      Each tuple has `(feat\_idx, neighbor\_feat\_idx, estimator)`, where `feat\_idx` is the current feature to be imputed, `neighbor\_feat\_idx` is the array of other features used to impute the current feature, and `estimator` is the trained estimator used for the imputation. Length is `self.n\_features\_with\_missing\_ \* self.n\_iter\_`.
     */
    get imputation_sequence_(): Promise<any>;
    /**
      Number of iteration rounds that occurred. Will be less than `self.max\_iter` if early stopping criterion was reached.
     */
    get n_iter_(): Promise<number>;
    /**
      Number of features seen during [fit](../../glossary.html#term-fit).
     */
    get n_features_in_(): Promise<number>;
    /**
      Names of features seen during [fit](../../glossary.html#term-fit). Defined only when `X` has feature names that are all strings.
     */
    get feature_names_in_(): Promise<NDArray>;
    /**
      Number of features with missing values.
     */
    get n_features_with_missing_(): Promise<number>;
    /**
      Indicator used to add binary indicators for missing values. `undefined` if `add\_indicator=False`.
     */
    get indicator_(): Promise<any>;
    /**
      RandomState instance that is generated either from a seed, the random number generator or by `np.random`.
     */
    get random_state_(): Promise<any>;
}
//# sourceMappingURL=IterativeImputer.d.ts.map