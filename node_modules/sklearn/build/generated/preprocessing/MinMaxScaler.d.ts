import { PythonBridge, NDArray, ArrayLike } from '@/sklearn/types';
/**
  Transform features by scaling each feature to a given range.

  This estimator scales and translates each feature individually such that it is in the given range on the training set, e.g. between zero and one.

  The transformation is given by:

  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)
 */
export declare class MinMaxScaler {
    id: string;
    opts: any;
    _py: PythonBridge;
    _isInitialized: boolean;
    _isDisposed: boolean;
    constructor(opts?: {
        /**
          Desired range of transformed data.
         */
        feature_range?: any;
        /**
          Set to `false` to perform inplace row normalization and avoid a copy (if the input is already a numpy array).
    
          @defaultValue `true`
         */
        copy?: boolean;
        /**
          Set to `true` to clip transformed values of held-out data to provided `feature range`.
    
          @defaultValue `false`
         */
        clip?: boolean;
    });
    get py(): PythonBridge;
    set py(pythonBridge: PythonBridge);
    /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
    init(py: PythonBridge): Promise<void>;
    /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
    dispose(): Promise<void>;
    /**
      Compute the minimum and maximum to be used for later scaling.
     */
    fit(opts: {
        /**
          The data used to compute the per-feature minimum and maximum used for later scaling along the features axis.
         */
        X?: ArrayLike[];
        /**
          Ignored.
         */
        y?: any;
    }): Promise<any>;
    /**
      Fit to data, then transform it.
  
      Fits transformer to `X` and `y` with optional parameters `fit\_params` and returns a transformed version of `X`.
     */
    fit_transform(opts: {
        /**
          Input samples.
         */
        X?: ArrayLike[];
        /**
          Target values (`undefined` for unsupervised transformations).
         */
        y?: ArrayLike;
        /**
          Additional fit parameters.
         */
        fit_params?: any;
    }): Promise<any[]>;
    /**
      Get output feature names for transformation.
     */
    get_feature_names_out(opts: {
        /**
          Input features.
         */
        input_features?: any;
    }): Promise<any>;
    /**
      Undo the scaling of X according to feature\_range.
     */
    inverse_transform(opts: {
        /**
          Input data that will be transformed. It cannot be sparse.
         */
        X?: ArrayLike[];
    }): Promise<NDArray[]>;
    /**
      Online computation of min and max on X for later scaling.
  
      All of X is processed as a single batch. This is intended for cases when [`fit`](#sklearn.preprocessing.MinMaxScaler.fit "sklearn.preprocessing.MinMaxScaler.fit") is not feasible due to very large number of `n\_samples` or because X is read from a continuous stream.
     */
    partial_fit(opts: {
        /**
          The data used to compute the mean and standard deviation used for later scaling along the features axis.
         */
        X?: ArrayLike[];
        /**
          Ignored.
         */
        y?: any;
    }): Promise<any>;
    /**
      Set output container.
  
      See [Introducing the set\_output API](../../auto_examples/miscellaneous/plot_set_output.html#sphx-glr-auto-examples-miscellaneous-plot-set-output-py) for an example on how to use the API.
     */
    set_output(opts: {
        /**
          Configure output of `transform` and `fit\_transform`.
         */
        transform?: 'default' | 'pandas';
    }): Promise<any>;
    /**
      Scale features of X according to feature\_range.
     */
    transform(opts: {
        /**
          Input data that will be transformed.
         */
        X?: ArrayLike[];
    }): Promise<NDArray[]>;
    /**
      Per feature adjustment for minimum. Equivalent to `min \- X.min(axis=0) \* self.scale\_`
     */
    get min_(): Promise<NDArray>;
    /**
      Per feature relative scaling of the data. Equivalent to `(max \- min) / (X.max(axis=0) \- X.min(axis=0))`
     */
    get scale_(): Promise<NDArray>;
    /**
      Per feature minimum seen in the data
     */
    get data_min_(): Promise<NDArray>;
    /**
      Per feature maximum seen in the data
     */
    get data_max_(): Promise<NDArray>;
    /**
      Per feature range `(data\_max\_ \- data\_min\_)` seen in the data
     */
    get data_range_(): Promise<NDArray>;
    /**
      Number of features seen during [fit](../../glossary.html#term-fit).
     */
    get n_features_in_(): Promise<number>;
    /**
      The number of samples processed by the estimator. It will be reset on new calls to fit, but increments across `partial\_fit` calls.
     */
    get n_samples_seen_(): Promise<number>;
    /**
      Names of features seen during [fit](../../glossary.html#term-fit). Defined only when `X` has feature names that are all strings.
     */
    get feature_names_in_(): Promise<NDArray>;
}
//# sourceMappingURL=MinMaxScaler.d.ts.map