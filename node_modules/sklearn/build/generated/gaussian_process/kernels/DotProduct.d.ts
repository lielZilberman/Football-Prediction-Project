import { PythonBridge, NDArray } from '@/sklearn/types';
/**
  Dot-Product kernel.

  The DotProduct kernel is non-stationary and can be obtained from linear regression by putting \\(N(0, 1)\\) priors on the coefficients of \\(x\_d (d = 1, . . . , D)\\) and a prior of \\(N(0, \\sigma\_0^2)\\) on the bias. The DotProduct kernel is invariant to a rotation of the coordinates about the origin, but not translations. It is parameterized by a parameter sigma\_0 \\(\\sigma\\) which controls the inhomogenity of the kernel. For \\(\\sigma\_0^2 =0\\), the kernel is called the homogeneous linear kernel, otherwise it is inhomogeneous. The kernel is given by

  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.DotProduct.html)
 */
export declare class DotProduct {
    id: string;
    opts: any;
    _py: PythonBridge;
    _isInitialized: boolean;
    _isDisposed: boolean;
    constructor(opts?: {
        /**
          Parameter controlling the inhomogenity of the kernel. If sigma\_0=0, the kernel is homogeneous.
    
          @defaultValue `1`
         */
        sigma_0?: any;
        /**
          The lower and upper bound on ‘sigma\_0’. If set to “fixed”, ‘sigma\_0’ cannot be changed during hyperparameter tuning.
         */
        sigma_0_bounds?: 'fixed';
    });
    get py(): PythonBridge;
    set py(pythonBridge: PythonBridge);
    /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
    init(py: PythonBridge): Promise<void>;
    /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
    dispose(): Promise<void>;
    /**
      Return the kernel k(X, Y) and optionally its gradient.
     */
    __call__(opts: {
        /**
          Left argument of the returned kernel k(X, Y)
         */
        X?: NDArray[];
        /**
          Right argument of the returned kernel k(X, Y). If `undefined`, k(X, X) if evaluated instead.
         */
        Y?: NDArray[];
        /**
          Determines whether the gradient with respect to the log of the kernel hyperparameter is computed. Only supported when Y is `undefined`.
    
          @defaultValue `false`
         */
        eval_gradient?: boolean;
    }): Promise<NDArray[]>;
    /**
      Returns a clone of self with given hyperparameters theta.
     */
    clone_with_theta(opts: {
        /**
          The hyperparameters
         */
        theta?: NDArray;
    }): Promise<any>;
    /**
      Returns the diagonal of the kernel k(X, X).
  
      The result of this method is identical to np.diag(self(X)); however, it can be evaluated more efficiently since only the diagonal is evaluated.
     */
    diag(opts: {
        /**
          Left argument of the returned kernel k(X, Y).
         */
        X?: NDArray[];
    }): Promise<NDArray>;
    /**
      Returns whether the kernel is stationary.
     */
    is_stationary(opts: {}): Promise<any>;
    get hyperparameter_sigma_0(): Promise<any>;
}
//# sourceMappingURL=DotProduct.d.ts.map