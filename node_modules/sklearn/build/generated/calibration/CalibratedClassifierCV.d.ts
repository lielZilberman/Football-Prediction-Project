import { PythonBridge, NDArray, ArrayLike } from '@/sklearn/types';
/**
  Probability calibration with isotonic regression or logistic regression.

  This class uses cross-validation to both estimate the parameters of a classifier and subsequently calibrate a classifier. With default `ensemble=True`, for each cv split it fits a copy of the base estimator to the training subset, and calibrates it using the testing subset. For prediction, predicted probabilities are averaged across these individual calibrated classifiers. When `ensemble=False`, cross-validation is used to obtain unbiased predictions, via [`cross\_val\_predict`](sklearn.model_selection.cross_val_predict.html#sklearn.model_selection.cross_val_predict "sklearn.model_selection.cross_val_predict"), which are then used for calibration. For prediction, the base estimator, trained using all the data, is used. This is the method implemented when `probabilities=True` for [`sklearn.svm`](../classes.html#module-sklearn.svm "sklearn.svm") estimators.

  Already fitted classifiers can be calibrated via the parameter `cv="prefit"`. In this case, no cross-validation is used and all provided data is used for calibration. The user has to take care manually that data for model fitting and calibration are disjoint.

  The calibration is based on the [decision\_function](../../glossary.html#term-decision_function) method of the `estimator` if it exists, else on [predict\_proba](../../glossary.html#term-predict_proba).

  Read more in the [User Guide](../calibration.html#calibration).

  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.calibration.CalibratedClassifierCV.html)
 */
export declare class CalibratedClassifierCV {
    id: string;
    opts: any;
    _py: PythonBridge;
    _isInitialized: boolean;
    _isDisposed: boolean;
    constructor(opts?: {
        /**
          The classifier whose output need to be calibrated to provide more accurate `predict\_proba` outputs. The default classifier is a [`LinearSVC`](sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC "sklearn.svm.LinearSVC").
         */
        estimator?: any;
        /**
          The method to use for calibration. Can be ‘sigmoid’ which corresponds to Platt’s method (i.e. a logistic regression model) or ‘isotonic’ which is a non-parametric approach. It is not advised to use isotonic calibration with too few calibration samples `(<<1000)` since it tends to overfit.
    
          @defaultValue `'sigmoid'`
         */
        method?: 'sigmoid' | 'isotonic';
        /**
          Determines the cross-validation splitting strategy. Possible inputs for cv are:
         */
        cv?: number | 'prefit';
        /**
          Number of jobs to run in parallel. `undefined` means 1 unless in a [`joblib.parallel\_backend`](https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend "(in joblib v1.3.0.dev0)") context. `\-1` means using all processors.
    
          Base estimator clones are fitted in parallel across cross-validation iterations. Therefore parallelism happens only when `cv != "prefit"`.
    
          See [Glossary](../../glossary.html#term-n_jobs) for more details.
         */
        n_jobs?: number;
        /**
          Determines how the calibrator is fitted when `cv` is not `'prefit'`. Ignored if `cv='prefit'`.
    
          If `true`, the `estimator` is fitted using training data, and calibrated using testing data, for each `cv` fold. The final estimator is an ensemble of `n\_cv` fitted classifier and calibrator pairs, where `n\_cv` is the number of cross-validation folds. The output is the average predicted probabilities of all pairs.
    
          If `false`, `cv` is used to compute unbiased predictions, via [`cross\_val\_predict`](sklearn.model_selection.cross_val_predict.html#sklearn.model_selection.cross_val_predict "sklearn.model_selection.cross_val_predict"), which are then used for calibration. At prediction time, the classifier used is the `estimator` trained on all the data. Note that this method is also internally implemented in [`sklearn.svm`](../classes.html#module-sklearn.svm "sklearn.svm") estimators with the `probabilities=True` parameter.
    
          @defaultValue `true`
         */
        ensemble?: boolean;
        /**
          This parameter is deprecated. Use `estimator` instead.
         */
        base_estimator?: any;
    });
    get py(): PythonBridge;
    set py(pythonBridge: PythonBridge);
    /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
    init(py: PythonBridge): Promise<void>;
    /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
    dispose(): Promise<void>;
    /**
      Fit the calibrated model.
     */
    fit(opts: {
        /**
          Training data.
         */
        X?: ArrayLike[];
        /**
          Target values.
         */
        y?: ArrayLike;
        /**
          Sample weights. If `undefined`, then samples are equally weighted.
         */
        sample_weight?: ArrayLike;
        /**
          Parameters to pass to the `fit` method of the underlying classifier.
         */
        fit_params?: any;
    }): Promise<any>;
    /**
      Predict the target of new samples.
  
      The predicted class is the class that has the highest probability, and can thus be different from the prediction of the uncalibrated classifier.
     */
    predict(opts: {
        /**
          The samples, as accepted by `estimator.predict`.
         */
        X?: ArrayLike[];
    }): Promise<NDArray>;
    /**
      Calibrated probabilities of classification.
  
      This function returns calibrated probabilities of classification according to each class on an array of test vectors X.
     */
    predict_proba(opts: {
        /**
          The samples, as accepted by `estimator.predict\_proba`.
         */
        X?: ArrayLike[];
    }): Promise<NDArray[]>;
    /**
      Return the mean accuracy on the given test data and labels.
  
      In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.
     */
    score(opts: {
        /**
          Test samples.
         */
        X?: ArrayLike[];
        /**
          True labels for `X`.
         */
        y?: ArrayLike;
        /**
          Sample weights.
         */
        sample_weight?: ArrayLike;
    }): Promise<number>;
    /**
      The class labels.
     */
    get classes_(): Promise<NDArray>;
    /**
      Number of features seen during [fit](../../glossary.html#term-fit). Only defined if the underlying estimator exposes such an attribute when fit.
     */
    get n_features_in_(): Promise<number>;
    /**
      Names of features seen during [fit](../../glossary.html#term-fit). Only defined if the underlying estimator exposes such an attribute when fit.
     */
    get feature_names_in_(): Promise<NDArray>;
    /**
      The list of classifier and calibrator pairs.
     */
    get calibrated_classifiers_(): Promise<number>;
}
//# sourceMappingURL=CalibratedClassifierCV.d.ts.map