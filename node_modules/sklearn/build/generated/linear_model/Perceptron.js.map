{"version":3,"sources":["../../../src/generated/linear_model/Perceptron.ts"],"sourcesContent":["/* eslint-disable */\n/* NOTE: This file is auto-generated. Do not edit it directly. */\n\nimport crypto from 'node:crypto'\n\nimport { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types'\n\n/**\n  Linear perceptron classifier.\n\n  Read more in the [User Guide](../linear_model.html#perceptron).\n\n  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html)\n */\nexport class Perceptron {\n  id: string\n  opts: any\n\n  _py: PythonBridge\n  _isInitialized: boolean = false\n  _isDisposed: boolean = false\n\n  constructor(opts?: {\n    /**\n      The penalty (aka regularization term) to be used.\n     */\n    penalty?: 'l2' | 'l1' | 'elasticnet'\n\n    /**\n      Constant that multiplies the regularization term if regularization is used.\n\n      @defaultValue `0.0001`\n     */\n    alpha?: number\n\n    /**\n      The Elastic Net mixing parameter, with `0 <= l1\\_ratio <= 1`. `l1\\_ratio=0` corresponds to L2 penalty, `l1\\_ratio=1` to L1. Only used if `penalty='elasticnet'`.\n\n      @defaultValue `0.15`\n     */\n    l1_ratio?: number\n\n    /**\n      Whether the intercept should be estimated or not. If `false`, the data is assumed to be already centered.\n\n      @defaultValue `true`\n     */\n    fit_intercept?: boolean\n\n    /**\n      The maximum number of passes over the training data (aka epochs). It only impacts the behavior in the `fit` method, and not the [`partial\\_fit`](#sklearn.linear_model.Perceptron.partial_fit \"sklearn.linear_model.Perceptron.partial_fit\") method.\n\n      @defaultValue `1000`\n     */\n    max_iter?: number\n\n    /**\n      The stopping criterion. If it is not `undefined`, the iterations will stop when (loss > previous\\_loss - tol).\n\n      @defaultValue `0.001`\n     */\n    tol?: number\n\n    /**\n      Whether or not the training data should be shuffled after each epoch.\n\n      @defaultValue `true`\n     */\n    shuffle?: boolean\n\n    /**\n      The verbosity level.\n\n      @defaultValue `0`\n     */\n    verbose?: number\n\n    /**\n      Constant by which the updates are multiplied.\n\n      @defaultValue `1`\n     */\n    eta0?: number\n\n    /**\n      The number of CPUs to use to do the OVA (One Versus All, for multi-class problems) computation. `undefined` means 1 unless in a [`joblib.parallel\\_backend`](https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend \"(in joblib v1.3.0.dev0)\") context. `\\-1` means using all processors. See [Glossary](../../glossary.html#term-n_jobs) for more details.\n     */\n    n_jobs?: number\n\n    /**\n      Used to shuffle the training data, when `shuffle` is set to `true`. Pass an int for reproducible output across multiple function calls. See [Glossary](../../glossary.html#term-random_state).\n\n      @defaultValue `0`\n     */\n    random_state?: number\n\n    /**\n      Whether to use early stopping to terminate training when validation. score is not improving. If set to `true`, it will automatically set aside a stratified fraction of training data as validation and terminate training when validation score is not improving by at least tol for n\\_iter\\_no\\_change consecutive epochs.\n\n      @defaultValue `false`\n     */\n    early_stopping?: boolean\n\n    /**\n      The proportion of training data to set aside as validation set for early stopping. Must be between 0 and 1. Only used if early\\_stopping is `true`.\n\n      @defaultValue `0.1`\n     */\n    validation_fraction?: number\n\n    /**\n      Number of iterations with no improvement to wait before early stopping.\n\n      @defaultValue `5`\n     */\n    n_iter_no_change?: number\n\n    /**\n      Preset for the class\\_weight fit parameter.\n\n      Weights associated with classes. If not given, all classes are supposed to have weight one.\n\n      The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as `n\\_samples / (n\\_classes \\* np.bincount(y))`.\n     */\n    class_weight?: any | 'balanced'\n\n    /**\n      When set to `true`, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. See [the Glossary](../../glossary.html#term-warm_start).\n\n      @defaultValue `false`\n     */\n    warm_start?: boolean\n  }) {\n    this.id = `Perceptron${crypto.randomUUID().split('-')[0]}`\n    this.opts = opts || {}\n  }\n\n  get py(): PythonBridge {\n    return this._py\n  }\n\n  set py(pythonBridge: PythonBridge) {\n    this._py = pythonBridge\n  }\n\n  /**\n    Initializes the underlying Python resources.\n\n    This instance is not usable until the `Promise` returned by `init()` resolves.\n   */\n  async init(py: PythonBridge): Promise<void> {\n    if (this._isDisposed) {\n      throw new Error('This Perceptron instance has already been disposed')\n    }\n\n    if (this._isInitialized) {\n      return\n    }\n\n    if (!py) {\n      throw new Error('Perceptron.init requires a PythonBridge instance')\n    }\n\n    this._py = py\n\n    await this._py.ex`\nimport numpy as np\nfrom sklearn.linear_model import Perceptron\ntry: bridgePerceptron\nexcept NameError: bridgePerceptron = {}\n`\n\n    // set up constructor params\n    await this._py.ex`ctor_Perceptron = {'penalty': ${\n      this.opts['penalty'] ?? undefined\n    }, 'alpha': ${this.opts['alpha'] ?? undefined}, 'l1_ratio': ${\n      this.opts['l1_ratio'] ?? undefined\n    }, 'fit_intercept': ${\n      this.opts['fit_intercept'] ?? undefined\n    }, 'max_iter': ${this.opts['max_iter'] ?? undefined}, 'tol': ${\n      this.opts['tol'] ?? undefined\n    }, 'shuffle': ${this.opts['shuffle'] ?? undefined}, 'verbose': ${\n      this.opts['verbose'] ?? undefined\n    }, 'eta0': ${this.opts['eta0'] ?? undefined}, 'n_jobs': ${\n      this.opts['n_jobs'] ?? undefined\n    }, 'random_state': ${\n      this.opts['random_state'] ?? undefined\n    }, 'early_stopping': ${\n      this.opts['early_stopping'] ?? undefined\n    }, 'validation_fraction': ${\n      this.opts['validation_fraction'] ?? undefined\n    }, 'n_iter_no_change': ${\n      this.opts['n_iter_no_change'] ?? undefined\n    }, 'class_weight': ${\n      this.opts['class_weight'] ?? undefined\n    }, 'warm_start': ${this.opts['warm_start'] ?? undefined}}\n\nctor_Perceptron = {k: v for k, v in ctor_Perceptron.items() if v is not None}`\n\n    await this._py\n      .ex`bridgePerceptron[${this.id}] = Perceptron(**ctor_Perceptron)`\n\n    this._isInitialized = true\n  }\n\n  /**\n    Disposes of the underlying Python resources.\n\n    Once `dispose()` is called, the instance is no longer usable.\n   */\n  async dispose() {\n    if (this._isDisposed) {\n      return\n    }\n\n    if (!this._isInitialized) {\n      return\n    }\n\n    await this._py.ex`del bridgePerceptron[${this.id}]`\n\n    this._isDisposed = true\n  }\n\n  /**\n    Predict confidence scores for samples.\n\n    The confidence score for a sample is proportional to the signed distance of that sample to the hyperplane.\n   */\n  async decision_function(opts: {\n    /**\n      The data matrix for which we want to get the confidence scores.\n     */\n    X?: ArrayLike | SparseMatrix[]\n  }): Promise<NDArray> {\n    if (this._isDisposed) {\n      throw new Error('This Perceptron instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('Perceptron must call init() before decision_function()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_Perceptron_decision_function = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None}\n\npms_Perceptron_decision_function = {k: v for k, v in pms_Perceptron_decision_function.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_Perceptron_decision_function = bridgePerceptron[${this.id}].decision_function(**pms_Perceptron_decision_function)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_Perceptron_decision_function.tolist() if hasattr(res_Perceptron_decision_function, 'tolist') else res_Perceptron_decision_function`\n  }\n\n  /**\n    Convert coefficient matrix to dense array format.\n\n    Converts the `coef\\_` member (back) to a numpy.ndarray. This is the default format of `coef\\_` and is required for fitting, so calling this method is only required on models that have previously been sparsified; otherwise, it is a no-op.\n   */\n  async densify(opts: {}): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This Perceptron instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('Perceptron must call init() before densify()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_Perceptron_densify = {}\n\npms_Perceptron_densify = {k: v for k, v in pms_Perceptron_densify.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_Perceptron_densify = bridgePerceptron[${this.id}].densify(**pms_Perceptron_densify)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_Perceptron_densify.tolist() if hasattr(res_Perceptron_densify, 'tolist') else res_Perceptron_densify`\n  }\n\n  /**\n    Fit linear model with Stochastic Gradient Descent.\n   */\n  async fit(opts: {\n    /**\n      Training data.\n     */\n    X?: ArrayLike | SparseMatrix\n\n    /**\n      Target values.\n     */\n    y?: NDArray\n\n    /**\n      The initial coefficients to warm-start the optimization.\n     */\n    coef_init?: NDArray[]\n\n    /**\n      The initial intercept to warm-start the optimization.\n     */\n    intercept_init?: NDArray\n\n    /**\n      Weights applied to individual samples. If not provided, uniform weights are assumed. These weights will be multiplied with class\\_weight (passed through the constructor) if class\\_weight is specified.\n     */\n    sample_weight?: ArrayLike\n  }): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This Perceptron instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('Perceptron must call init() before fit()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_Perceptron_fit = {'X': ${\n      opts['X'] ?? undefined\n    }, 'y': np.array(${opts['y'] ?? undefined}) if ${\n      opts['y'] !== undefined\n    } else None, 'coef_init': np.array(${opts['coef_init'] ?? undefined}) if ${\n      opts['coef_init'] !== undefined\n    } else None, 'intercept_init': np.array(${\n      opts['intercept_init'] ?? undefined\n    }) if ${opts['intercept_init'] !== undefined} else None, 'sample_weight': ${\n      opts['sample_weight'] ?? undefined\n    }}\n\npms_Perceptron_fit = {k: v for k, v in pms_Perceptron_fit.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_Perceptron_fit = bridgePerceptron[${this.id}].fit(**pms_Perceptron_fit)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_Perceptron_fit.tolist() if hasattr(res_Perceptron_fit, 'tolist') else res_Perceptron_fit`\n  }\n\n  /**\n    Perform one epoch of stochastic gradient descent on given samples.\n\n    Internally, this method uses `max\\_iter \\= 1`. Therefore, it is not guaranteed that a minimum of the cost function is reached after calling it once. Matters such as objective convergence, early stopping, and learning rate adjustments should be handled by the user.\n   */\n  async partial_fit(opts: {\n    /**\n      Subset of the training data.\n     */\n    X?: ArrayLike | SparseMatrix\n\n    /**\n      Subset of the target values.\n     */\n    y?: NDArray\n\n    /**\n      Classes across all calls to partial\\_fit. Can be obtained by via `np.unique(y\\_all)`, where y\\_all is the target vector of the entire dataset. This argument is required for the first call to partial\\_fit and can be omitted in the subsequent calls. Note that y doesn’t need to contain all labels in `classes`.\n     */\n    classes?: NDArray\n\n    /**\n      Weights applied to individual samples. If not provided, uniform weights are assumed.\n     */\n    sample_weight?: ArrayLike\n  }): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This Perceptron instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('Perceptron must call init() before partial_fit()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_Perceptron_partial_fit = {'X': ${\n      opts['X'] ?? undefined\n    }, 'y': np.array(${opts['y'] ?? undefined}) if ${\n      opts['y'] !== undefined\n    } else None, 'classes': np.array(${opts['classes'] ?? undefined}) if ${\n      opts['classes'] !== undefined\n    } else None, 'sample_weight': ${opts['sample_weight'] ?? undefined}}\n\npms_Perceptron_partial_fit = {k: v for k, v in pms_Perceptron_partial_fit.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_Perceptron_partial_fit = bridgePerceptron[${this.id}].partial_fit(**pms_Perceptron_partial_fit)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_Perceptron_partial_fit.tolist() if hasattr(res_Perceptron_partial_fit, 'tolist') else res_Perceptron_partial_fit`\n  }\n\n  /**\n    Predict class labels for samples in X.\n   */\n  async predict(opts: {\n    /**\n      The data matrix for which we want to get the predictions.\n     */\n    X?: ArrayLike | SparseMatrix[]\n  }): Promise<NDArray> {\n    if (this._isDisposed) {\n      throw new Error('This Perceptron instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('Perceptron must call init() before predict()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_Perceptron_predict = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None}\n\npms_Perceptron_predict = {k: v for k, v in pms_Perceptron_predict.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_Perceptron_predict = bridgePerceptron[${this.id}].predict(**pms_Perceptron_predict)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_Perceptron_predict.tolist() if hasattr(res_Perceptron_predict, 'tolist') else res_Perceptron_predict`\n  }\n\n  /**\n    Return the mean accuracy on the given test data and labels.\n\n    In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.\n   */\n  async score(opts: {\n    /**\n      Test samples.\n     */\n    X?: ArrayLike[]\n\n    /**\n      True labels for `X`.\n     */\n    y?: ArrayLike\n\n    /**\n      Sample weights.\n     */\n    sample_weight?: ArrayLike\n  }): Promise<number> {\n    if (this._isDisposed) {\n      throw new Error('This Perceptron instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('Perceptron must call init() before score()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_Perceptron_score = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None, 'y': np.array(${\n      opts['y'] ?? undefined\n    }) if ${opts['y'] !== undefined} else None, 'sample_weight': np.array(${\n      opts['sample_weight'] ?? undefined\n    }) if ${opts['sample_weight'] !== undefined} else None}\n\npms_Perceptron_score = {k: v for k, v in pms_Perceptron_score.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_Perceptron_score = bridgePerceptron[${this.id}].score(**pms_Perceptron_score)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_Perceptron_score.tolist() if hasattr(res_Perceptron_score, 'tolist') else res_Perceptron_score`\n  }\n\n  /**\n    Convert coefficient matrix to sparse format.\n\n    Converts the `coef\\_` member to a scipy.sparse matrix, which for L1-regularized models can be much more memory- and storage-efficient than the usual numpy.ndarray representation.\n\n    The `intercept\\_` member is not converted.\n   */\n  async sparsify(opts: {}): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This Perceptron instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('Perceptron must call init() before sparsify()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_Perceptron_sparsify = {}\n\npms_Perceptron_sparsify = {k: v for k, v in pms_Perceptron_sparsify.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_Perceptron_sparsify = bridgePerceptron[${this.id}].sparsify(**pms_Perceptron_sparsify)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_Perceptron_sparsify.tolist() if hasattr(res_Perceptron_sparsify, 'tolist') else res_Perceptron_sparsify`\n  }\n\n  /**\n    The unique classes labels.\n   */\n  get classes_(): Promise<NDArray> {\n    if (this._isDisposed) {\n      throw new Error('This Perceptron instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('Perceptron must call init() before accessing classes_')\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_Perceptron_classes_ = bridgePerceptron[${this.id}].classes_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_Perceptron_classes_.tolist() if hasattr(attr_Perceptron_classes_, 'tolist') else attr_Perceptron_classes_`\n    })()\n  }\n\n  /**\n    Weights assigned to the features.\n   */\n  get coef_(): Promise<NDArray[][]> {\n    if (this._isDisposed) {\n      throw new Error('This Perceptron instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('Perceptron must call init() before accessing coef_')\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_Perceptron_coef_ = bridgePerceptron[${this.id}].coef_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_Perceptron_coef_.tolist() if hasattr(attr_Perceptron_coef_, 'tolist') else attr_Perceptron_coef_`\n    })()\n  }\n\n  /**\n    Constants in decision function.\n   */\n  get intercept_(): Promise<NDArray[]> {\n    if (this._isDisposed) {\n      throw new Error('This Perceptron instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('Perceptron must call init() before accessing intercept_')\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_Perceptron_intercept_ = bridgePerceptron[${this.id}].intercept_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_Perceptron_intercept_.tolist() if hasattr(attr_Perceptron_intercept_, 'tolist') else attr_Perceptron_intercept_`\n    })()\n  }\n\n  /**\n    The function that determines the loss, or difference between the output of the algorithm and the target values.\n   */\n  get loss_function_(): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This Perceptron instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'Perceptron must call init() before accessing loss_function_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_Perceptron_loss_function_ = bridgePerceptron[${this.id}].loss_function_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_Perceptron_loss_function_.tolist() if hasattr(attr_Perceptron_loss_function_, 'tolist') else attr_Perceptron_loss_function_`\n    })()\n  }\n\n  /**\n    Number of features seen during [fit](../../glossary.html#term-fit).\n   */\n  get n_features_in_(): Promise<number> {\n    if (this._isDisposed) {\n      throw new Error('This Perceptron instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'Perceptron must call init() before accessing n_features_in_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_Perceptron_n_features_in_ = bridgePerceptron[${this.id}].n_features_in_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_Perceptron_n_features_in_.tolist() if hasattr(attr_Perceptron_n_features_in_, 'tolist') else attr_Perceptron_n_features_in_`\n    })()\n  }\n\n  /**\n    Names of features seen during [fit](../../glossary.html#term-fit). Defined only when `X` has feature names that are all strings.\n   */\n  get feature_names_in_(): Promise<NDArray> {\n    if (this._isDisposed) {\n      throw new Error('This Perceptron instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'Perceptron must call init() before accessing feature_names_in_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_Perceptron_feature_names_in_ = bridgePerceptron[${this.id}].feature_names_in_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_Perceptron_feature_names_in_.tolist() if hasattr(attr_Perceptron_feature_names_in_, 'tolist') else attr_Perceptron_feature_names_in_`\n    })()\n  }\n\n  /**\n    The actual number of iterations to reach the stopping criterion. For multiclass fits, it is the maximum over every binary fit.\n   */\n  get n_iter_(): Promise<number> {\n    if (this._isDisposed) {\n      throw new Error('This Perceptron instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('Perceptron must call init() before accessing n_iter_')\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_Perceptron_n_iter_ = bridgePerceptron[${this.id}].n_iter_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_Perceptron_n_iter_.tolist() if hasattr(attr_Perceptron_n_iter_, 'tolist') else attr_Perceptron_n_iter_`\n    })()\n  }\n\n  /**\n    Number of weight updates performed during training. Same as `(n\\_iter\\_ \\* n\\_samples + 1)`.\n   */\n  get t_(): Promise<number> {\n    if (this._isDisposed) {\n      throw new Error('This Perceptron instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('Perceptron must call init() before accessing t_')\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py.ex`attr_Perceptron_t_ = bridgePerceptron[${this.id}].t_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_Perceptron_t_.tolist() if hasattr(attr_Perceptron_t_, 'tolist') else attr_Perceptron_t_`\n    })()\n  }\n}\n"],"mappings":";AAGA,OAAO,YAAY;AAWZ,IAAM,aAAN,MAAiB;AAAA,EAQtB,YAAY,MA8GT;AAjHH,0BAA0B;AAC1B,uBAAuB;AAiHrB,SAAK,KAAK,aAAa,OAAO,WAAW,EAAE,MAAM,GAAG,EAAE,CAAC;AACvD,SAAK,OAAO,QAAQ,CAAC;AAAA,EACvB;AAAA,EAEA,IAAI,KAAmB;AACrB,WAAO,KAAK;AAAA,EACd;AAAA,EAEA,IAAI,GAAG,cAA4B;AACjC,SAAK,MAAM;AAAA,EACb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,KAAK,IAAiC;AAC1C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,oDAAoD;AAAA,IACtE;AAEA,QAAI,KAAK,gBAAgB;AACvB;AAAA,IACF;AAEA,QAAI,CAAC,IAAI;AACP,YAAM,IAAI,MAAM,kDAAkD;AAAA,IACpE;AAEA,SAAK,MAAM;AAEX,UAAM,KAAK,IAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAQf,UAAM,KAAK,IAAI,mCACb,KAAK,KAAK,SAAS,KAAK,oBACZ,KAAK,KAAK,OAAO,KAAK,uBAClC,KAAK,KAAK,UAAU,KAAK,4BAEzB,KAAK,KAAK,eAAe,KAAK,uBACf,KAAK,KAAK,UAAU,KAAK,kBACxC,KAAK,KAAK,KAAK,KAAK,sBACN,KAAK,KAAK,SAAS,KAAK,sBACtC,KAAK,KAAK,SAAS,KAAK,mBACb,KAAK,KAAK,MAAM,KAAK,qBAChC,KAAK,KAAK,QAAQ,KAAK,2BAEvB,KAAK,KAAK,cAAc,KAAK,6BAE7B,KAAK,KAAK,gBAAgB,KAAK,kCAE/B,KAAK,KAAK,qBAAqB,KAAK,+BAEpC,KAAK,KAAK,kBAAkB,KAAK,2BAEjC,KAAK,KAAK,cAAc,KAAK,yBACZ,KAAK,KAAK,YAAY,KAAK;AAAA;AAAA;AAI9C,UAAM,KAAK,IACR,sBAAsB,KAAK;AAE9B,SAAK,iBAAiB;AAAA,EACxB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,UAAU;AACd,QAAI,KAAK,aAAa;AACpB;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB;AAAA,IACF;AAEA,UAAM,KAAK,IAAI,0BAA0B,KAAK;AAE9C,SAAK,cAAc;AAAA,EACrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,kBAAkB,MAKH;AACnB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,oDAAoD;AAAA,IACtE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAGA,UAAM,KAAK,IAAI,uDACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM;AAAA;AAAA;AAKtB,UAAM,KAAK,IACR,yDAAyD,KAAK;AAGjE,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,QAAQ,MAAwB;AACpC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,oDAAoD;AAAA,IACtE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,8CAA8C;AAAA,IAChE;AAGA,UAAM,KAAK,IAAI;AAAA;AAAA;AAKf,UAAM,KAAK,IACR,+CAA+C,KAAK;AAGvD,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,IAAI,MAyBO;AACf,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,oDAAoD;AAAA,IACtE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,0CAA0C;AAAA,IAC5D;AAGA,UAAM,KAAK,IAAI,gCACb,KAAK,GAAG,KAAK,yBACI,KAAK,GAAG,KAAK,cAC9B,KAAK,GAAG,MAAM,2CACqB,KAAK,WAAW,KAAK,cACxD,KAAK,WAAW,MAAM,gDAEtB,KAAK,gBAAgB,KAAK,cACpB,KAAK,gBAAgB,MAAM,sCACjC,KAAK,eAAe,KAAK;AAAA;AAAA;AAM3B,UAAM,KAAK,IACR,2CAA2C,KAAK;AAGnD,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,YAAY,MAoBD;AACf,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,oDAAoD;AAAA,IACtE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,kDAAkD;AAAA,IACpE;AAGA,UAAM,KAAK,IAAI,wCACb,KAAK,GAAG,KAAK,yBACI,KAAK,GAAG,KAAK,cAC9B,KAAK,GAAG,MAAM,yCACmB,KAAK,SAAS,KAAK,cACpD,KAAK,SAAS,MAAM,sCACU,KAAK,eAAe,KAAK;AAAA;AAAA;AAKzD,UAAM,KAAK,IACR,mDAAmD,KAAK;AAG3D,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,QAAQ,MAKO;AACnB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,oDAAoD;AAAA,IACtE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,8CAA8C;AAAA,IAChE;AAGA,UAAM,KAAK,IAAI,6CACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM;AAAA;AAAA;AAKtB,UAAM,KAAK,IACR,+CAA+C,KAAK;AAGvD,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,MAAM,MAeQ;AAClB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,oDAAoD;AAAA,IACtE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,4CAA4C;AAAA,IAC9D;AAGA,UAAM,KAAK,IAAI,2CACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,mCACpB,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,+CACpB,KAAK,eAAe,KAAK,cACnB,KAAK,eAAe,MAAM;AAAA;AAAA;AAKlC,UAAM,KAAK,IACR,6CAA6C,KAAK;AAGrD,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASA,MAAM,SAAS,MAAwB;AACrC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,oDAAoD;AAAA,IACtE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,+CAA+C;AAAA,IACjE;AAGA,UAAM,KAAK,IAAI;AAAA;AAAA;AAKf,UAAM,KAAK,IACR,gDAAgD,KAAK;AAGxD,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,WAA6B;AAC/B,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,oDAAoD;AAAA,IACtE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,uDAAuD;AAAA,IACzE;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,iDAAiD,KAAK;AAGzD,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,QAA8B;AAChC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,oDAAoD;AAAA,IACtE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,oDAAoD;AAAA,IACtE;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,8CAA8C,KAAK;AAGtD,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,aAAiC;AACnC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,oDAAoD;AAAA,IACtE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,yDAAyD;AAAA,IAC3E;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,mDAAmD,KAAK;AAG3D,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,iBAA+B;AACjC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,oDAAoD;AAAA,IACtE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,uDAAuD,KAAK;AAG/D,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,iBAAkC;AACpC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,oDAAoD;AAAA,IACtE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,uDAAuD,KAAK;AAG/D,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,oBAAsC;AACxC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,oDAAoD;AAAA,IACtE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,0DAA0D,KAAK;AAGlE,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,UAA2B;AAC7B,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,oDAAoD;AAAA,IACtE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,sDAAsD;AAAA,IACxE;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,gDAAgD,KAAK;AAGxD,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,KAAsB;AACxB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,oDAAoD;AAAA,IACtE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,iDAAiD;AAAA,IACnE;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IAAI,2CAA2C,KAAK;AAG/D,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AACF;","names":[]}