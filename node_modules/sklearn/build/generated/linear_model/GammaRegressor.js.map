{"version":3,"sources":["../../../src/generated/linear_model/GammaRegressor.ts"],"sourcesContent":["/* eslint-disable */\n/* NOTE: This file is auto-generated. Do not edit it directly. */\n\nimport crypto from 'node:crypto'\n\nimport { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types'\n\n/**\n  Generalized Linear Model with a Gamma distribution.\n\n  This regressor uses the ‘log’ link function.\n\n  Read more in the [User Guide](../linear_model.html#generalized-linear-models).\n\n  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.GammaRegressor.html)\n */\nexport class GammaRegressor {\n  id: string\n  opts: any\n\n  _py: PythonBridge\n  _isInitialized: boolean = false\n  _isDisposed: boolean = false\n\n  constructor(opts?: {\n    /**\n      Constant that multiplies the L2 penalty term and determines the regularization strength. `alpha \\= 0` is equivalent to unpenalized GLMs. In this case, the design matrix `X` must have full column rank (no collinearities). Values of `alpha` must be in the range `\\[0.0, inf)`.\n\n      @defaultValue `1`\n     */\n    alpha?: number\n\n    /**\n      Specifies if a constant (a.k.a. bias or intercept) should be added to the linear predictor `X @ coef\\_ + intercept\\_`.\n\n      @defaultValue `true`\n     */\n    fit_intercept?: boolean\n\n    /**\n      Algorithm to use in the optimization problem:\n\n      @defaultValue `'lbfgs'`\n     */\n    solver?: 'lbfgs' | 'newton-cholesky'\n\n    /**\n      The maximal number of iterations for the solver. Values must be in the range `\\[1, inf)`.\n\n      @defaultValue `100`\n     */\n    max_iter?: number\n\n    /**\n      Stopping criterion. For the lbfgs solver, the iteration will stop when `max{|g\\_j|, j \\= 1, ..., d} <= tol` where `g\\_j` is the j-th component of the gradient (derivative) of the objective function. Values must be in the range `(0.0, inf)`.\n\n      @defaultValue `0.0001`\n     */\n    tol?: number\n\n    /**\n      If set to `true`, reuse the solution of the previous call to `fit` as initialization for `coef\\_` and `intercept\\_`.\n\n      @defaultValue `false`\n     */\n    warm_start?: boolean\n\n    /**\n      For the lbfgs solver set verbose to any positive number for verbosity. Values must be in the range `\\[0, inf)`.\n\n      @defaultValue `0`\n     */\n    verbose?: number\n  }) {\n    this.id = `GammaRegressor${crypto.randomUUID().split('-')[0]}`\n    this.opts = opts || {}\n  }\n\n  get py(): PythonBridge {\n    return this._py\n  }\n\n  set py(pythonBridge: PythonBridge) {\n    this._py = pythonBridge\n  }\n\n  /**\n    Initializes the underlying Python resources.\n\n    This instance is not usable until the `Promise` returned by `init()` resolves.\n   */\n  async init(py: PythonBridge): Promise<void> {\n    if (this._isDisposed) {\n      throw new Error('This GammaRegressor instance has already been disposed')\n    }\n\n    if (this._isInitialized) {\n      return\n    }\n\n    if (!py) {\n      throw new Error('GammaRegressor.init requires a PythonBridge instance')\n    }\n\n    this._py = py\n\n    await this._py.ex`\nimport numpy as np\nfrom sklearn.linear_model import GammaRegressor\ntry: bridgeGammaRegressor\nexcept NameError: bridgeGammaRegressor = {}\n`\n\n    // set up constructor params\n    await this._py.ex`ctor_GammaRegressor = {'alpha': ${\n      this.opts['alpha'] ?? undefined\n    }, 'fit_intercept': ${this.opts['fit_intercept'] ?? undefined}, 'solver': ${\n      this.opts['solver'] ?? undefined\n    }, 'max_iter': ${this.opts['max_iter'] ?? undefined}, 'tol': ${\n      this.opts['tol'] ?? undefined\n    }, 'warm_start': ${this.opts['warm_start'] ?? undefined}, 'verbose': ${\n      this.opts['verbose'] ?? undefined\n    }}\n\nctor_GammaRegressor = {k: v for k, v in ctor_GammaRegressor.items() if v is not None}`\n\n    await this._py\n      .ex`bridgeGammaRegressor[${this.id}] = GammaRegressor(**ctor_GammaRegressor)`\n\n    this._isInitialized = true\n  }\n\n  /**\n    Disposes of the underlying Python resources.\n\n    Once `dispose()` is called, the instance is no longer usable.\n   */\n  async dispose() {\n    if (this._isDisposed) {\n      return\n    }\n\n    if (!this._isInitialized) {\n      return\n    }\n\n    await this._py.ex`del bridgeGammaRegressor[${this.id}]`\n\n    this._isDisposed = true\n  }\n\n  /**\n    Fit a Generalized Linear Model.\n   */\n  async fit(opts: {\n    /**\n      Training data.\n     */\n    X?: ArrayLike | SparseMatrix[]\n\n    /**\n      Target values.\n     */\n    y?: ArrayLike\n\n    /**\n      Sample weights.\n     */\n    sample_weight?: ArrayLike\n  }): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This GammaRegressor instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('GammaRegressor must call init() before fit()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_GammaRegressor_fit = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None, 'y': np.array(${\n      opts['y'] ?? undefined\n    }) if ${opts['y'] !== undefined} else None, 'sample_weight': np.array(${\n      opts['sample_weight'] ?? undefined\n    }) if ${opts['sample_weight'] !== undefined} else None}\n\npms_GammaRegressor_fit = {k: v for k, v in pms_GammaRegressor_fit.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_GammaRegressor_fit = bridgeGammaRegressor[${this.id}].fit(**pms_GammaRegressor_fit)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_GammaRegressor_fit.tolist() if hasattr(res_GammaRegressor_fit, 'tolist') else res_GammaRegressor_fit`\n  }\n\n  /**\n    Predict using GLM with feature matrix X.\n   */\n  async predict(opts: {\n    /**\n      Samples.\n     */\n    X?: ArrayLike | SparseMatrix[]\n  }): Promise<any[]> {\n    if (this._isDisposed) {\n      throw new Error('This GammaRegressor instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('GammaRegressor must call init() before predict()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_GammaRegressor_predict = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None}\n\npms_GammaRegressor_predict = {k: v for k, v in pms_GammaRegressor_predict.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_GammaRegressor_predict = bridgeGammaRegressor[${this.id}].predict(**pms_GammaRegressor_predict)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_GammaRegressor_predict.tolist() if hasattr(res_GammaRegressor_predict, 'tolist') else res_GammaRegressor_predict`\n  }\n\n  /**\n    Compute D^2, the percentage of deviance explained.\n\n    D^2 is a generalization of the coefficient of determination R^2. R^2 uses squared error and D^2 uses the deviance of this GLM, see the [User Guide](../model_evaluation.html#regression-metrics).\n\n    D^2 is defined as \\\\(D^2 = 1-\\\\frac{D(y\\_{true},y\\_{pred})}{D\\_{null}}\\\\), \\\\(D\\_{null}\\\\) is the null deviance, i.e. the deviance of a model with intercept alone, which corresponds to \\\\(y\\_{pred} = \\\\bar{y}\\\\). The mean \\\\(\\\\bar{y}\\\\) is averaged by sample\\_weight. Best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse).\n   */\n  async score(opts: {\n    /**\n      Test samples.\n     */\n    X?: ArrayLike | SparseMatrix[]\n\n    /**\n      True values of target.\n     */\n    y?: ArrayLike\n\n    /**\n      Sample weights.\n     */\n    sample_weight?: ArrayLike\n  }): Promise<number> {\n    if (this._isDisposed) {\n      throw new Error('This GammaRegressor instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('GammaRegressor must call init() before score()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_GammaRegressor_score = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None, 'y': np.array(${\n      opts['y'] ?? undefined\n    }) if ${opts['y'] !== undefined} else None, 'sample_weight': np.array(${\n      opts['sample_weight'] ?? undefined\n    }) if ${opts['sample_weight'] !== undefined} else None}\n\npms_GammaRegressor_score = {k: v for k, v in pms_GammaRegressor_score.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_GammaRegressor_score = bridgeGammaRegressor[${this.id}].score(**pms_GammaRegressor_score)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_GammaRegressor_score.tolist() if hasattr(res_GammaRegressor_score, 'tolist') else res_GammaRegressor_score`\n  }\n\n  /**\n    Estimated coefficients for the linear predictor (`X @ coef\\_ + intercept\\_`) in the GLM.\n   */\n  get coef_(): Promise<any[]> {\n    if (this._isDisposed) {\n      throw new Error('This GammaRegressor instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('GammaRegressor must call init() before accessing coef_')\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_GammaRegressor_coef_ = bridgeGammaRegressor[${this.id}].coef_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_GammaRegressor_coef_.tolist() if hasattr(attr_GammaRegressor_coef_, 'tolist') else attr_GammaRegressor_coef_`\n    })()\n  }\n\n  /**\n    Intercept (a.k.a. bias) added to linear predictor.\n   */\n  get intercept_(): Promise<number> {\n    if (this._isDisposed) {\n      throw new Error('This GammaRegressor instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'GammaRegressor must call init() before accessing intercept_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_GammaRegressor_intercept_ = bridgeGammaRegressor[${this.id}].intercept_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_GammaRegressor_intercept_.tolist() if hasattr(attr_GammaRegressor_intercept_, 'tolist') else attr_GammaRegressor_intercept_`\n    })()\n  }\n\n  /**\n    Number of features seen during [fit](../../glossary.html#term-fit).\n   */\n  get n_features_in_(): Promise<number> {\n    if (this._isDisposed) {\n      throw new Error('This GammaRegressor instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'GammaRegressor must call init() before accessing n_features_in_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_GammaRegressor_n_features_in_ = bridgeGammaRegressor[${this.id}].n_features_in_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_GammaRegressor_n_features_in_.tolist() if hasattr(attr_GammaRegressor_n_features_in_, 'tolist') else attr_GammaRegressor_n_features_in_`\n    })()\n  }\n\n  /**\n    Actual number of iterations used in the solver.\n   */\n  get n_iter_(): Promise<number> {\n    if (this._isDisposed) {\n      throw new Error('This GammaRegressor instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'GammaRegressor must call init() before accessing n_iter_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_GammaRegressor_n_iter_ = bridgeGammaRegressor[${this.id}].n_iter_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_GammaRegressor_n_iter_.tolist() if hasattr(attr_GammaRegressor_n_iter_, 'tolist') else attr_GammaRegressor_n_iter_`\n    })()\n  }\n\n  /**\n    Names of features seen during [fit](../../glossary.html#term-fit). Defined only when `X` has feature names that are all strings.\n   */\n  get feature_names_in_(): Promise<NDArray> {\n    if (this._isDisposed) {\n      throw new Error('This GammaRegressor instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'GammaRegressor must call init() before accessing feature_names_in_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_GammaRegressor_feature_names_in_ = bridgeGammaRegressor[${this.id}].feature_names_in_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_GammaRegressor_feature_names_in_.tolist() if hasattr(attr_GammaRegressor_feature_names_in_, 'tolist') else attr_GammaRegressor_feature_names_in_`\n    })()\n  }\n}\n"],"mappings":";AAGA,OAAO,YAAY;AAaZ,IAAM,iBAAN,MAAqB;AAAA,EAQ1B,YAAY,MAiDT;AApDH,0BAA0B;AAC1B,uBAAuB;AAoDrB,SAAK,KAAK,iBAAiB,OAAO,WAAW,EAAE,MAAM,GAAG,EAAE,CAAC;AAC3D,SAAK,OAAO,QAAQ,CAAC;AAAA,EACvB;AAAA,EAEA,IAAI,KAAmB;AACrB,WAAO,KAAK;AAAA,EACd;AAAA,EAEA,IAAI,GAAG,cAA4B;AACjC,SAAK,MAAM;AAAA,EACb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,KAAK,IAAiC;AAC1C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,KAAK,gBAAgB;AACvB;AAAA,IACF;AAEA,QAAI,CAAC,IAAI;AACP,YAAM,IAAI,MAAM,sDAAsD;AAAA,IACxE;AAEA,SAAK,MAAM;AAEX,UAAM,KAAK,IAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAQf,UAAM,KAAK,IAAI,qCACb,KAAK,KAAK,OAAO,KAAK,4BACF,KAAK,KAAK,eAAe,KAAK,qBAClD,KAAK,KAAK,QAAQ,KAAK,uBACR,KAAK,KAAK,UAAU,KAAK,kBACxC,KAAK,KAAK,KAAK,KAAK,yBACH,KAAK,KAAK,YAAY,KAAK,sBAC5C,KAAK,KAAK,SAAS,KAAK;AAAA;AAAA;AAK1B,UAAM,KAAK,IACR,0BAA0B,KAAK;AAElC,SAAK,iBAAiB;AAAA,EACxB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,UAAU;AACd,QAAI,KAAK,aAAa;AACpB;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB;AAAA,IACF;AAEA,UAAM,KAAK,IAAI,8BAA8B,KAAK;AAElD,SAAK,cAAc;AAAA,EACrB;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,IAAI,MAeO;AACf,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,8CAA8C;AAAA,IAChE;AAGA,UAAM,KAAK,IAAI,6CACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,mCACpB,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,+CACpB,KAAK,eAAe,KAAK,cACnB,KAAK,eAAe,MAAM;AAAA;AAAA;AAKlC,UAAM,KAAK,IACR,mDAAmD,KAAK;AAG3D,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,QAAQ,MAKK;AACjB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,kDAAkD;AAAA,IACpE;AAGA,UAAM,KAAK,IAAI,iDACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM;AAAA;AAAA;AAKtB,UAAM,KAAK,IACR,uDAAuD,KAAK;AAG/D,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASA,MAAM,MAAM,MAeQ;AAClB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,gDAAgD;AAAA,IAClE;AAGA,UAAM,KAAK,IAAI,+CACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,mCACpB,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,+CACpB,KAAK,eAAe,KAAK,cACnB,KAAK,eAAe,MAAM;AAAA;AAAA;AAKlC,UAAM,KAAK,IACR,qDAAqD,KAAK;AAG7D,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,QAAwB;AAC1B,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,sDAAsD,KAAK;AAG9D,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,aAA8B;AAChC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,2DAA2D,KAAK;AAGnE,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,iBAAkC;AACpC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,+DAA+D,KAAK;AAGvE,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,UAA2B;AAC7B,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,wDAAwD,KAAK;AAGhE,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,oBAAsC;AACxC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,kEAAkE,KAAK;AAG1E,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AACF;","names":[]}