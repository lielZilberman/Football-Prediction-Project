// src/generated/linear_model/SGDClassifier.ts
import crypto from "node:crypto";
var SGDClassifier = class {
  constructor(opts) {
    this._isInitialized = false;
    this._isDisposed = false;
    this.id = `SGDClassifier${crypto.randomUUID().split("-")[0]}`;
    this.opts = opts || {};
  }
  get py() {
    return this._py;
  }
  set py(pythonBridge) {
    this._py = pythonBridge;
  }
  /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
  async init(py) {
    if (this._isDisposed) {
      throw new Error("This SGDClassifier instance has already been disposed");
    }
    if (this._isInitialized) {
      return;
    }
    if (!py) {
      throw new Error("SGDClassifier.init requires a PythonBridge instance");
    }
    this._py = py;
    await this._py.ex`
import numpy as np
from sklearn.linear_model import SGDClassifier
try: bridgeSGDClassifier
except NameError: bridgeSGDClassifier = {}
`;
    await this._py.ex`ctor_SGDClassifier = {'loss': ${this.opts["loss"] ?? void 0}, 'penalty': ${this.opts["penalty"] ?? void 0}, 'alpha': ${this.opts["alpha"] ?? void 0}, 'l1_ratio': ${this.opts["l1_ratio"] ?? void 0}, 'fit_intercept': ${this.opts["fit_intercept"] ?? void 0}, 'max_iter': ${this.opts["max_iter"] ?? void 0}, 'tol': ${this.opts["tol"] ?? void 0}, 'shuffle': ${this.opts["shuffle"] ?? void 0}, 'verbose': ${this.opts["verbose"] ?? void 0}, 'epsilon': ${this.opts["epsilon"] ?? void 0}, 'n_jobs': ${this.opts["n_jobs"] ?? void 0}, 'random_state': ${this.opts["random_state"] ?? void 0}, 'learning_rate': ${this.opts["learning_rate"] ?? void 0}, 'eta0': ${this.opts["eta0"] ?? void 0}, 'power_t': ${this.opts["power_t"] ?? void 0}, 'early_stopping': ${this.opts["early_stopping"] ?? void 0}, 'validation_fraction': ${this.opts["validation_fraction"] ?? void 0}, 'n_iter_no_change': ${this.opts["n_iter_no_change"] ?? void 0}, 'class_weight': ${this.opts["class_weight"] ?? void 0}, 'warm_start': ${this.opts["warm_start"] ?? void 0}, 'average': ${this.opts["average"] ?? void 0}}

ctor_SGDClassifier = {k: v for k, v in ctor_SGDClassifier.items() if v is not None}`;
    await this._py.ex`bridgeSGDClassifier[${this.id}] = SGDClassifier(**ctor_SGDClassifier)`;
    this._isInitialized = true;
  }
  /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
  async dispose() {
    if (this._isDisposed) {
      return;
    }
    if (!this._isInitialized) {
      return;
    }
    await this._py.ex`del bridgeSGDClassifier[${this.id}]`;
    this._isDisposed = true;
  }
  /**
      Predict confidence scores for samples.
  
      The confidence score for a sample is proportional to the signed distance of that sample to the hyperplane.
     */
  async decision_function(opts) {
    if (this._isDisposed) {
      throw new Error("This SGDClassifier instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "SGDClassifier must call init() before decision_function()"
      );
    }
    await this._py.ex`pms_SGDClassifier_decision_function = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_SGDClassifier_decision_function = {k: v for k, v in pms_SGDClassifier_decision_function.items() if v is not None}`;
    await this._py.ex`res_SGDClassifier_decision_function = bridgeSGDClassifier[${this.id}].decision_function(**pms_SGDClassifier_decision_function)`;
    return this._py`res_SGDClassifier_decision_function.tolist() if hasattr(res_SGDClassifier_decision_function, 'tolist') else res_SGDClassifier_decision_function`;
  }
  /**
      Convert coefficient matrix to dense array format.
  
      Converts the `coef\_` member (back) to a numpy.ndarray. This is the default format of `coef\_` and is required for fitting, so calling this method is only required on models that have previously been sparsified; otherwise, it is a no-op.
     */
  async densify(opts) {
    if (this._isDisposed) {
      throw new Error("This SGDClassifier instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("SGDClassifier must call init() before densify()");
    }
    await this._py.ex`pms_SGDClassifier_densify = {}

pms_SGDClassifier_densify = {k: v for k, v in pms_SGDClassifier_densify.items() if v is not None}`;
    await this._py.ex`res_SGDClassifier_densify = bridgeSGDClassifier[${this.id}].densify(**pms_SGDClassifier_densify)`;
    return this._py`res_SGDClassifier_densify.tolist() if hasattr(res_SGDClassifier_densify, 'tolist') else res_SGDClassifier_densify`;
  }
  /**
    Fit linear model with Stochastic Gradient Descent.
   */
  async fit(opts) {
    if (this._isDisposed) {
      throw new Error("This SGDClassifier instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("SGDClassifier must call init() before fit()");
    }
    await this._py.ex`pms_SGDClassifier_fit = {'X': ${opts["X"] ?? void 0}, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'coef_init': np.array(${opts["coef_init"] ?? void 0}) if ${opts["coef_init"] !== void 0} else None, 'intercept_init': np.array(${opts["intercept_init"] ?? void 0}) if ${opts["intercept_init"] !== void 0} else None, 'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_SGDClassifier_fit = {k: v for k, v in pms_SGDClassifier_fit.items() if v is not None}`;
    await this._py.ex`res_SGDClassifier_fit = bridgeSGDClassifier[${this.id}].fit(**pms_SGDClassifier_fit)`;
    return this._py`res_SGDClassifier_fit.tolist() if hasattr(res_SGDClassifier_fit, 'tolist') else res_SGDClassifier_fit`;
  }
  /**
      Perform one epoch of stochastic gradient descent on given samples.
  
      Internally, this method uses `max\_iter \= 1`. Therefore, it is not guaranteed that a minimum of the cost function is reached after calling it once. Matters such as objective convergence, early stopping, and learning rate adjustments should be handled by the user.
     */
  async partial_fit(opts) {
    if (this._isDisposed) {
      throw new Error("This SGDClassifier instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("SGDClassifier must call init() before partial_fit()");
    }
    await this._py.ex`pms_SGDClassifier_partial_fit = {'X': ${opts["X"] ?? void 0}, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'classes': np.array(${opts["classes"] ?? void 0}) if ${opts["classes"] !== void 0} else None, 'sample_weight': ${opts["sample_weight"] ?? void 0}}

pms_SGDClassifier_partial_fit = {k: v for k, v in pms_SGDClassifier_partial_fit.items() if v is not None}`;
    await this._py.ex`res_SGDClassifier_partial_fit = bridgeSGDClassifier[${this.id}].partial_fit(**pms_SGDClassifier_partial_fit)`;
    return this._py`res_SGDClassifier_partial_fit.tolist() if hasattr(res_SGDClassifier_partial_fit, 'tolist') else res_SGDClassifier_partial_fit`;
  }
  /**
    Predict class labels for samples in X.
   */
  async predict(opts) {
    if (this._isDisposed) {
      throw new Error("This SGDClassifier instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("SGDClassifier must call init() before predict()");
    }
    await this._py.ex`pms_SGDClassifier_predict = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_SGDClassifier_predict = {k: v for k, v in pms_SGDClassifier_predict.items() if v is not None}`;
    await this._py.ex`res_SGDClassifier_predict = bridgeSGDClassifier[${this.id}].predict(**pms_SGDClassifier_predict)`;
    return this._py`res_SGDClassifier_predict.tolist() if hasattr(res_SGDClassifier_predict, 'tolist') else res_SGDClassifier_predict`;
  }
  /**
      Log of probability estimates.
  
      This method is only available for log loss and modified Huber loss.
  
      When loss=”modified\_huber”, probability estimates may be hard zeros and ones, so taking the logarithm is not possible.
  
      See `predict\_proba` for details.
     */
  async predict_log_proba(opts) {
    if (this._isDisposed) {
      throw new Error("This SGDClassifier instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "SGDClassifier must call init() before predict_log_proba()"
      );
    }
    await this._py.ex`pms_SGDClassifier_predict_log_proba = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_SGDClassifier_predict_log_proba = {k: v for k, v in pms_SGDClassifier_predict_log_proba.items() if v is not None}`;
    await this._py.ex`res_SGDClassifier_predict_log_proba = bridgeSGDClassifier[${this.id}].predict_log_proba(**pms_SGDClassifier_predict_log_proba)`;
    return this._py`res_SGDClassifier_predict_log_proba.tolist() if hasattr(res_SGDClassifier_predict_log_proba, 'tolist') else res_SGDClassifier_predict_log_proba`;
  }
  /**
      Probability estimates.
  
      This method is only available for log loss and modified Huber loss.
  
      Multiclass probability estimates are derived from binary (one-vs.-rest) estimates by simple normalization, as recommended by Zadrozny and Elkan.
  
      Binary probability estimates for loss=”modified\_huber” are given by (clip(decision\_function(X), -1, 1) + 1) / 2. For other loss functions it is necessary to perform proper probability calibration by wrapping the classifier with [`CalibratedClassifierCV`](sklearn.calibration.CalibratedClassifierCV.html#sklearn.calibration.CalibratedClassifierCV "sklearn.calibration.CalibratedClassifierCV") instead.
     */
  async predict_proba(opts) {
    if (this._isDisposed) {
      throw new Error("This SGDClassifier instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("SGDClassifier must call init() before predict_proba()");
    }
    await this._py.ex`pms_SGDClassifier_predict_proba = {'X': ${opts["X"] ?? void 0}}

pms_SGDClassifier_predict_proba = {k: v for k, v in pms_SGDClassifier_predict_proba.items() if v is not None}`;
    await this._py.ex`res_SGDClassifier_predict_proba = bridgeSGDClassifier[${this.id}].predict_proba(**pms_SGDClassifier_predict_proba)`;
    return this._py`res_SGDClassifier_predict_proba.tolist() if hasattr(res_SGDClassifier_predict_proba, 'tolist') else res_SGDClassifier_predict_proba`;
  }
  /**
      Return the mean accuracy on the given test data and labels.
  
      In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.
     */
  async score(opts) {
    if (this._isDisposed) {
      throw new Error("This SGDClassifier instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("SGDClassifier must call init() before score()");
    }
    await this._py.ex`pms_SGDClassifier_score = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'sample_weight': np.array(${opts["sample_weight"] ?? void 0}) if ${opts["sample_weight"] !== void 0} else None}

pms_SGDClassifier_score = {k: v for k, v in pms_SGDClassifier_score.items() if v is not None}`;
    await this._py.ex`res_SGDClassifier_score = bridgeSGDClassifier[${this.id}].score(**pms_SGDClassifier_score)`;
    return this._py`res_SGDClassifier_score.tolist() if hasattr(res_SGDClassifier_score, 'tolist') else res_SGDClassifier_score`;
  }
  /**
      Convert coefficient matrix to sparse format.
  
      Converts the `coef\_` member to a scipy.sparse matrix, which for L1-regularized models can be much more memory- and storage-efficient than the usual numpy.ndarray representation.
  
      The `intercept\_` member is not converted.
     */
  async sparsify(opts) {
    if (this._isDisposed) {
      throw new Error("This SGDClassifier instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("SGDClassifier must call init() before sparsify()");
    }
    await this._py.ex`pms_SGDClassifier_sparsify = {}

pms_SGDClassifier_sparsify = {k: v for k, v in pms_SGDClassifier_sparsify.items() if v is not None}`;
    await this._py.ex`res_SGDClassifier_sparsify = bridgeSGDClassifier[${this.id}].sparsify(**pms_SGDClassifier_sparsify)`;
    return this._py`res_SGDClassifier_sparsify.tolist() if hasattr(res_SGDClassifier_sparsify, 'tolist') else res_SGDClassifier_sparsify`;
  }
  /**
    Weights assigned to the features.
   */
  get coef_() {
    if (this._isDisposed) {
      throw new Error("This SGDClassifier instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("SGDClassifier must call init() before accessing coef_");
    }
    return (async () => {
      await this._py.ex`attr_SGDClassifier_coef_ = bridgeSGDClassifier[${this.id}].coef_`;
      return this._py`attr_SGDClassifier_coef_.tolist() if hasattr(attr_SGDClassifier_coef_, 'tolist') else attr_SGDClassifier_coef_`;
    })();
  }
  /**
    Constants in decision function.
   */
  get intercept_() {
    if (this._isDisposed) {
      throw new Error("This SGDClassifier instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "SGDClassifier must call init() before accessing intercept_"
      );
    }
    return (async () => {
      await this._py.ex`attr_SGDClassifier_intercept_ = bridgeSGDClassifier[${this.id}].intercept_`;
      return this._py`attr_SGDClassifier_intercept_.tolist() if hasattr(attr_SGDClassifier_intercept_, 'tolist') else attr_SGDClassifier_intercept_`;
    })();
  }
  /**
    The actual number of iterations before reaching the stopping criterion. For multiclass fits, it is the maximum over every binary fit.
   */
  get n_iter_() {
    if (this._isDisposed) {
      throw new Error("This SGDClassifier instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("SGDClassifier must call init() before accessing n_iter_");
    }
    return (async () => {
      await this._py.ex`attr_SGDClassifier_n_iter_ = bridgeSGDClassifier[${this.id}].n_iter_`;
      return this._py`attr_SGDClassifier_n_iter_.tolist() if hasattr(attr_SGDClassifier_n_iter_, 'tolist') else attr_SGDClassifier_n_iter_`;
    })();
  }
  get loss_function_() {
    if (this._isDisposed) {
      throw new Error("This SGDClassifier instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "SGDClassifier must call init() before accessing loss_function_"
      );
    }
    return (async () => {
      await this._py.ex`attr_SGDClassifier_loss_function_ = bridgeSGDClassifier[${this.id}].loss_function_`;
      return this._py`attr_SGDClassifier_loss_function_.tolist() if hasattr(attr_SGDClassifier_loss_function_, 'tolist') else attr_SGDClassifier_loss_function_`;
    })();
  }
  get classes_() {
    if (this._isDisposed) {
      throw new Error("This SGDClassifier instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "SGDClassifier must call init() before accessing classes_"
      );
    }
    return (async () => {
      await this._py.ex`attr_SGDClassifier_classes_ = bridgeSGDClassifier[${this.id}].classes_`;
      return this._py`attr_SGDClassifier_classes_.tolist() if hasattr(attr_SGDClassifier_classes_, 'tolist') else attr_SGDClassifier_classes_`;
    })();
  }
  /**
    Number of weight updates performed during training. Same as `(n\_iter\_ \* n\_samples + 1)`.
   */
  get t_() {
    if (this._isDisposed) {
      throw new Error("This SGDClassifier instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("SGDClassifier must call init() before accessing t_");
    }
    return (async () => {
      await this._py.ex`attr_SGDClassifier_t_ = bridgeSGDClassifier[${this.id}].t_`;
      return this._py`attr_SGDClassifier_t_.tolist() if hasattr(attr_SGDClassifier_t_, 'tolist') else attr_SGDClassifier_t_`;
    })();
  }
  /**
    Number of features seen during [fit](../../glossary.html#term-fit).
   */
  get n_features_in_() {
    if (this._isDisposed) {
      throw new Error("This SGDClassifier instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "SGDClassifier must call init() before accessing n_features_in_"
      );
    }
    return (async () => {
      await this._py.ex`attr_SGDClassifier_n_features_in_ = bridgeSGDClassifier[${this.id}].n_features_in_`;
      return this._py`attr_SGDClassifier_n_features_in_.tolist() if hasattr(attr_SGDClassifier_n_features_in_, 'tolist') else attr_SGDClassifier_n_features_in_`;
    })();
  }
  /**
    Names of features seen during [fit](../../glossary.html#term-fit). Defined only when `X` has feature names that are all strings.
   */
  get feature_names_in_() {
    if (this._isDisposed) {
      throw new Error("This SGDClassifier instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "SGDClassifier must call init() before accessing feature_names_in_"
      );
    }
    return (async () => {
      await this._py.ex`attr_SGDClassifier_feature_names_in_ = bridgeSGDClassifier[${this.id}].feature_names_in_`;
      return this._py`attr_SGDClassifier_feature_names_in_.tolist() if hasattr(attr_SGDClassifier_feature_names_in_, 'tolist') else attr_SGDClassifier_feature_names_in_`;
    })();
  }
};
export {
  SGDClassifier
};
//# sourceMappingURL=SGDClassifier.js.map