import { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types';
/**
  Ridge regression with built-in cross-validation.

  See glossary entry for [cross-validation estimator](../../glossary.html#term-cross-validation-estimator).

  By default, it performs efficient Leave-One-Out Cross-Validation.

  Read more in the [User Guide](../linear_model.html#ridge-regression).

  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html)
 */
export declare class RidgeCV {
    id: string;
    opts: any;
    _py: PythonBridge;
    _isInitialized: boolean;
    _isDisposed: boolean;
    constructor(opts?: {
        /**
          Array of alpha values to try. Regularization strength; must be a positive float. Regularization improves the conditioning of the problem and reduces the variance of the estimates. Larger values specify stronger regularization. Alpha corresponds to `1 / (2C)` in other linear models such as [`LogisticRegression`](sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression "sklearn.linear_model.LogisticRegression") or [`LinearSVC`](sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC "sklearn.svm.LinearSVC"). If using Leave-One-Out cross-validation, alphas must be positive.
         */
        alphas?: ArrayLike;
        /**
          Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (i.e. data is expected to be centered).
    
          @defaultValue `true`
         */
        fit_intercept?: boolean;
        /**
          A string (see model evaluation documentation) or a scorer callable object / function with signature `scorer(estimator, X, y)`. If `undefined`, the negative mean squared error if cv is ‘auto’ or `undefined` (i.e. when using leave-one-out cross-validation), and r2 score otherwise.
         */
        scoring?: string;
        /**
          Determines the cross-validation splitting strategy. Possible inputs for cv are:
         */
        cv?: number;
        /**
          Flag indicating which strategy to use when performing Leave-One-Out Cross-Validation. Options are:
    
          @defaultValue `'auto'`
         */
        gcv_mode?: 'auto' | 'svd' | 'eigen';
        /**
          Flag indicating if the cross-validation values corresponding to each alpha should be stored in the `cv\_values\_` attribute (see below). This flag is only compatible with `cv=None` (i.e. using Leave-One-Out Cross-Validation).
    
          @defaultValue `false`
         */
        store_cv_values?: boolean;
        /**
          Flag indicating whether to optimize the alpha value (picked from the `alphas` parameter list) for each target separately (for multi-output settings: multiple prediction targets). When set to `true`, after fitting, the `alpha\_` attribute will contain a value for each target. When set to `false`, a single alpha is used for all targets.
    
          @defaultValue `false`
         */
        alpha_per_target?: boolean;
    });
    get py(): PythonBridge;
    set py(pythonBridge: PythonBridge);
    /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
    init(py: PythonBridge): Promise<void>;
    /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
    dispose(): Promise<void>;
    /**
      Fit Ridge regression model with cv.
     */
    fit(opts: {
        /**
          Training data. If using GCV, will be cast to float64 if necessary.
         */
        X?: NDArray[];
        /**
          Target values. Will be cast to X’s dtype if necessary.
         */
        y?: NDArray;
        /**
          Individual weights for each sample. If given a float, every sample will have the same weight.
         */
        sample_weight?: number | NDArray;
    }): Promise<any>;
    /**
      Predict using the linear model.
     */
    predict(opts: {
        /**
          Samples.
         */
        X?: ArrayLike | SparseMatrix;
    }): Promise<any>;
    /**
      Return the coefficient of determination of the prediction.
  
      The coefficient of determination \\(R^2\\) is defined as \\((1 - \\frac{u}{v})\\), where \\(u\\) is the residual sum of squares `((y\_true \- y\_pred)\*\* 2).sum()` and \\(v\\) is the total sum of squares `((y\_true \- y\_true.mean()) \*\* 2).sum()`. The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of `y`, disregarding the input features, would get a \\(R^2\\) score of 0.0.
     */
    score(opts: {
        /**
          Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape `(n\_samples, n\_samples\_fitted)`, where `n\_samples\_fitted` is the number of samples used in the fitting for the estimator.
         */
        X?: ArrayLike[];
        /**
          True values for `X`.
         */
        y?: ArrayLike;
        /**
          Sample weights.
         */
        sample_weight?: ArrayLike;
    }): Promise<number>;
    /**
      Cross-validation values for each alpha (only available if `store\_cv\_values=True` and `cv=None`). After `fit()` has been called, this attribute will contain the mean squared errors if `scoring is None` otherwise it will contain standardized per point prediction values.
     */
    get cv_values_(): Promise<NDArray[]>;
    /**
      Weight vector(s).
     */
    get coef_(): Promise<NDArray>;
    /**
      Independent term in decision function. Set to 0.0 if `fit\_intercept \= False`.
     */
    get intercept_(): Promise<number | NDArray>;
    /**
      Estimated regularization parameter, or, if `alpha\_per\_target=True`, the estimated regularization parameter for each target.
     */
    get alpha_(): Promise<number | NDArray>;
    /**
      Score of base estimator with best alpha, or, if `alpha\_per\_target=True`, a score for each target.
     */
    get best_score_(): Promise<number | NDArray>;
    /**
      Number of features seen during [fit](../../glossary.html#term-fit).
     */
    get n_features_in_(): Promise<number>;
    /**
      Names of features seen during [fit](../../glossary.html#term-fit). Defined only when `X` has feature names that are all strings.
     */
    get feature_names_in_(): Promise<NDArray>;
}
//# sourceMappingURL=RidgeCV.d.ts.map