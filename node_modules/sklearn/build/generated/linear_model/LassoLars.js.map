{"version":3,"sources":["../../../src/generated/linear_model/LassoLars.ts"],"sourcesContent":["/* eslint-disable */\n/* NOTE: This file is auto-generated. Do not edit it directly. */\n\nimport crypto from 'node:crypto'\n\nimport { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types'\n\n/**\n  Lasso model fit with Least Angle Regression a.k.a. Lars.\n\n  It is a Linear Model trained with an L1 prior as regularizer.\n\n  The optimization objective for Lasso is:\n\n  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoLars.html)\n */\nexport class LassoLars {\n  id: string\n  opts: any\n\n  _py: PythonBridge\n  _isInitialized: boolean = false\n  _isDisposed: boolean = false\n\n  constructor(opts?: {\n    /**\n      Constant that multiplies the penalty term. Defaults to 1.0. `alpha \\= 0` is equivalent to an ordinary least square, solved by [`LinearRegression`](sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression \"sklearn.linear_model.LinearRegression\"). For numerical reasons, using `alpha \\= 0` with the LassoLars object is not advised and you should prefer the LinearRegression object.\n\n      @defaultValue `1`\n     */\n    alpha?: number\n\n    /**\n      Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (i.e. data is expected to be centered).\n\n      @defaultValue `true`\n     */\n    fit_intercept?: boolean\n\n    /**\n      Sets the verbosity amount.\n\n      @defaultValue `false`\n     */\n    verbose?: boolean | number\n\n    /**\n      This parameter is ignored when `fit\\_intercept` is set to `false`. If `true`, the regressors X will be normalized before regression by subtracting the mean and dividing by the l2-norm. If you wish to standardize, please use [`StandardScaler`](sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler \"sklearn.preprocessing.StandardScaler\") before calling `fit` on an estimator with `normalize=False`.\n\n      @defaultValue `false`\n     */\n    normalize?: boolean\n\n    /**\n      Whether to use a precomputed Gram matrix to speed up calculations. If set to `'auto'` let us decide. The Gram matrix can also be passed as argument.\n\n      @defaultValue `'auto'`\n     */\n    precompute?: boolean | 'auto' | ArrayLike\n\n    /**\n      Maximum number of iterations to perform.\n\n      @defaultValue `500`\n     */\n    max_iter?: number\n\n    /**\n      The machine-precision regularization in the computation of the Cholesky diagonal factors. Increase this for very ill-conditioned systems. Unlike the `tol` parameter in some iterative optimization-based algorithms, this parameter does not control the tolerance of the optimization.\n     */\n    eps?: number\n\n    /**\n      If `true`, X will be copied; else, it may be overwritten.\n\n      @defaultValue `true`\n     */\n    copy_X?: boolean\n\n    /**\n      If `true` the full path is stored in the `coef\\_path\\_` attribute. If you compute the solution for a large problem or many targets, setting `fit\\_path` to `false` will lead to a speedup, especially with a small alpha.\n\n      @defaultValue `true`\n     */\n    fit_path?: boolean\n\n    /**\n      Restrict coefficients to be >= 0. Be aware that you might want to remove fit\\_intercept which is set `true` by default. Under the positive restriction the model coefficients will not converge to the ordinary-least-squares solution for small values of alpha. Only coefficients up to the smallest alpha value (`alphas\\_\\[alphas\\_ > 0.\\].min()` when fit\\_path=`true`) reached by the stepwise Lars-Lasso algorithm are typically in congruence with the solution of the coordinate descent Lasso estimator.\n\n      @defaultValue `false`\n     */\n    positive?: boolean\n\n    /**\n      Upper bound on a uniform noise parameter to be added to the `y` values, to satisfy the modelâ€™s assumption of one-at-a-time computations. Might help with stability.\n     */\n    jitter?: number\n\n    /**\n      Determines random number generation for jittering. Pass an int for reproducible output across multiple function calls. See [Glossary](../../glossary.html#term-random_state). Ignored if `jitter` is `undefined`.\n     */\n    random_state?: number\n  }) {\n    this.id = `LassoLars${crypto.randomUUID().split('-')[0]}`\n    this.opts = opts || {}\n  }\n\n  get py(): PythonBridge {\n    return this._py\n  }\n\n  set py(pythonBridge: PythonBridge) {\n    this._py = pythonBridge\n  }\n\n  /**\n    Initializes the underlying Python resources.\n\n    This instance is not usable until the `Promise` returned by `init()` resolves.\n   */\n  async init(py: PythonBridge): Promise<void> {\n    if (this._isDisposed) {\n      throw new Error('This LassoLars instance has already been disposed')\n    }\n\n    if (this._isInitialized) {\n      return\n    }\n\n    if (!py) {\n      throw new Error('LassoLars.init requires a PythonBridge instance')\n    }\n\n    this._py = py\n\n    await this._py.ex`\nimport numpy as np\nfrom sklearn.linear_model import LassoLars\ntry: bridgeLassoLars\nexcept NameError: bridgeLassoLars = {}\n`\n\n    // set up constructor params\n    await this._py.ex`ctor_LassoLars = {'alpha': ${\n      this.opts['alpha'] ?? undefined\n    }, 'fit_intercept': ${\n      this.opts['fit_intercept'] ?? undefined\n    }, 'verbose': ${this.opts['verbose'] ?? undefined}, 'normalize': ${\n      this.opts['normalize'] ?? undefined\n    }, 'precompute': ${this.opts['precompute'] ?? undefined}, 'max_iter': ${\n      this.opts['max_iter'] ?? undefined\n    }, 'eps': ${this.opts['eps'] ?? undefined}, 'copy_X': ${\n      this.opts['copy_X'] ?? undefined\n    }, 'fit_path': ${this.opts['fit_path'] ?? undefined}, 'positive': ${\n      this.opts['positive'] ?? undefined\n    }, 'jitter': ${this.opts['jitter'] ?? undefined}, 'random_state': ${\n      this.opts['random_state'] ?? undefined\n    }}\n\nctor_LassoLars = {k: v for k, v in ctor_LassoLars.items() if v is not None}`\n\n    await this._py.ex`bridgeLassoLars[${this.id}] = LassoLars(**ctor_LassoLars)`\n\n    this._isInitialized = true\n  }\n\n  /**\n    Disposes of the underlying Python resources.\n\n    Once `dispose()` is called, the instance is no longer usable.\n   */\n  async dispose() {\n    if (this._isDisposed) {\n      return\n    }\n\n    if (!this._isInitialized) {\n      return\n    }\n\n    await this._py.ex`del bridgeLassoLars[${this.id}]`\n\n    this._isDisposed = true\n  }\n\n  /**\n    Fit the model using X, y as training data.\n   */\n  async fit(opts: {\n    /**\n      Training data.\n     */\n    X?: ArrayLike[]\n\n    /**\n      Target values.\n     */\n    y?: ArrayLike\n\n    /**\n      Xy = np.dot(X.T, y) that can be precomputed. It is useful only when the Gram matrix is precomputed.\n     */\n    Xy?: ArrayLike\n  }): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This LassoLars instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('LassoLars must call init() before fit()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_LassoLars_fit = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None, 'y': np.array(${\n      opts['y'] ?? undefined\n    }) if ${opts['y'] !== undefined} else None, 'Xy': np.array(${\n      opts['Xy'] ?? undefined\n    }) if ${opts['Xy'] !== undefined} else None}\n\npms_LassoLars_fit = {k: v for k, v in pms_LassoLars_fit.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_LassoLars_fit = bridgeLassoLars[${this.id}].fit(**pms_LassoLars_fit)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_LassoLars_fit.tolist() if hasattr(res_LassoLars_fit, 'tolist') else res_LassoLars_fit`\n  }\n\n  /**\n    Predict using the linear model.\n   */\n  async predict(opts: {\n    /**\n      Samples.\n     */\n    X?: ArrayLike | SparseMatrix\n  }): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This LassoLars instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('LassoLars must call init() before predict()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_LassoLars_predict = {'X': ${opts['X'] ?? undefined}}\n\npms_LassoLars_predict = {k: v for k, v in pms_LassoLars_predict.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_LassoLars_predict = bridgeLassoLars[${this.id}].predict(**pms_LassoLars_predict)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_LassoLars_predict.tolist() if hasattr(res_LassoLars_predict, 'tolist') else res_LassoLars_predict`\n  }\n\n  /**\n    Return the coefficient of determination of the prediction.\n\n    The coefficient of determination \\\\(R^2\\\\) is defined as \\\\((1 - \\\\frac{u}{v})\\\\), where \\\\(u\\\\) is the residual sum of squares `((y\\_true \\- y\\_pred)\\*\\* 2).sum()` and \\\\(v\\\\) is the total sum of squares `((y\\_true \\- y\\_true.mean()) \\*\\* 2).sum()`. The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of `y`, disregarding the input features, would get a \\\\(R^2\\\\) score of 0.0.\n   */\n  async score(opts: {\n    /**\n      Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape `(n\\_samples, n\\_samples\\_fitted)`, where `n\\_samples\\_fitted` is the number of samples used in the fitting for the estimator.\n     */\n    X?: ArrayLike[]\n\n    /**\n      True values for `X`.\n     */\n    y?: ArrayLike\n\n    /**\n      Sample weights.\n     */\n    sample_weight?: ArrayLike\n  }): Promise<number> {\n    if (this._isDisposed) {\n      throw new Error('This LassoLars instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('LassoLars must call init() before score()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_LassoLars_score = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None, 'y': np.array(${\n      opts['y'] ?? undefined\n    }) if ${opts['y'] !== undefined} else None, 'sample_weight': np.array(${\n      opts['sample_weight'] ?? undefined\n    }) if ${opts['sample_weight'] !== undefined} else None}\n\npms_LassoLars_score = {k: v for k, v in pms_LassoLars_score.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_LassoLars_score = bridgeLassoLars[${this.id}].score(**pms_LassoLars_score)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_LassoLars_score.tolist() if hasattr(res_LassoLars_score, 'tolist') else res_LassoLars_score`\n  }\n\n  /**\n    Maximum of covariances (in absolute value) at each iteration. `n\\_alphas` is either `max\\_iter`, `n\\_features` or the number of nodes in the path with `alpha >= alpha\\_min`, whichever is smaller. If this is a list of array-like, the length of the outer list is `n\\_targets`.\n   */\n  get alphas_(): Promise<ArrayLike> {\n    if (this._isDisposed) {\n      throw new Error('This LassoLars instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('LassoLars must call init() before accessing alphas_')\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_LassoLars_alphas_ = bridgeLassoLars[${this.id}].alphas_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_LassoLars_alphas_.tolist() if hasattr(attr_LassoLars_alphas_, 'tolist') else attr_LassoLars_alphas_`\n    })()\n  }\n\n  /**\n    Indices of active variables at the end of the path. If this is a list of list, the length of the outer list is `n\\_targets`.\n   */\n  get active_(): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This LassoLars instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('LassoLars must call init() before accessing active_')\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_LassoLars_active_ = bridgeLassoLars[${this.id}].active_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_LassoLars_active_.tolist() if hasattr(attr_LassoLars_active_, 'tolist') else attr_LassoLars_active_`\n    })()\n  }\n\n  /**\n    If a list is passed itâ€™s expected to be one of n\\_targets such arrays. The varying values of the coefficients along the path. It is not present if the `fit\\_path` parameter is `false`. If this is a list of array-like, the length of the outer list is `n\\_targets`.\n   */\n  get coef_path_(): Promise<ArrayLike[]> {\n    if (this._isDisposed) {\n      throw new Error('This LassoLars instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('LassoLars must call init() before accessing coef_path_')\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_LassoLars_coef_path_ = bridgeLassoLars[${this.id}].coef_path_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_LassoLars_coef_path_.tolist() if hasattr(attr_LassoLars_coef_path_, 'tolist') else attr_LassoLars_coef_path_`\n    })()\n  }\n\n  /**\n    Parameter vector (w in the formulation formula).\n   */\n  get coef_(): Promise<ArrayLike> {\n    if (this._isDisposed) {\n      throw new Error('This LassoLars instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('LassoLars must call init() before accessing coef_')\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_LassoLars_coef_ = bridgeLassoLars[${this.id}].coef_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_LassoLars_coef_.tolist() if hasattr(attr_LassoLars_coef_, 'tolist') else attr_LassoLars_coef_`\n    })()\n  }\n\n  /**\n    Independent term in decision function.\n   */\n  get intercept_(): Promise<number | ArrayLike> {\n    if (this._isDisposed) {\n      throw new Error('This LassoLars instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('LassoLars must call init() before accessing intercept_')\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_LassoLars_intercept_ = bridgeLassoLars[${this.id}].intercept_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_LassoLars_intercept_.tolist() if hasattr(attr_LassoLars_intercept_, 'tolist') else attr_LassoLars_intercept_`\n    })()\n  }\n\n  /**\n    The number of iterations taken by lars\\_path to find the grid of alphas for each target.\n   */\n  get n_iter_(): Promise<ArrayLike | number> {\n    if (this._isDisposed) {\n      throw new Error('This LassoLars instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('LassoLars must call init() before accessing n_iter_')\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_LassoLars_n_iter_ = bridgeLassoLars[${this.id}].n_iter_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_LassoLars_n_iter_.tolist() if hasattr(attr_LassoLars_n_iter_, 'tolist') else attr_LassoLars_n_iter_`\n    })()\n  }\n\n  /**\n    Number of features seen during [fit](../../glossary.html#term-fit).\n   */\n  get n_features_in_(): Promise<number> {\n    if (this._isDisposed) {\n      throw new Error('This LassoLars instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'LassoLars must call init() before accessing n_features_in_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_LassoLars_n_features_in_ = bridgeLassoLars[${this.id}].n_features_in_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_LassoLars_n_features_in_.tolist() if hasattr(attr_LassoLars_n_features_in_, 'tolist') else attr_LassoLars_n_features_in_`\n    })()\n  }\n\n  /**\n    Names of features seen during [fit](../../glossary.html#term-fit). Defined only when `X` has feature names that are all strings.\n   */\n  get feature_names_in_(): Promise<NDArray> {\n    if (this._isDisposed) {\n      throw new Error('This LassoLars instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'LassoLars must call init() before accessing feature_names_in_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_LassoLars_feature_names_in_ = bridgeLassoLars[${this.id}].feature_names_in_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_LassoLars_feature_names_in_.tolist() if hasattr(attr_LassoLars_feature_names_in_, 'tolist') else attr_LassoLars_feature_names_in_`\n    })()\n  }\n}\n"],"mappings":";AAGA,OAAO,YAAY;AAaZ,IAAM,YAAN,MAAgB;AAAA,EAQrB,YAAY,MA8ET;AAjFH,0BAA0B;AAC1B,uBAAuB;AAiFrB,SAAK,KAAK,YAAY,OAAO,WAAW,EAAE,MAAM,GAAG,EAAE,CAAC;AACtD,SAAK,OAAO,QAAQ,CAAC;AAAA,EACvB;AAAA,EAEA,IAAI,KAAmB;AACrB,WAAO,KAAK;AAAA,EACd;AAAA,EAEA,IAAI,GAAG,cAA4B;AACjC,SAAK,MAAM;AAAA,EACb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,KAAK,IAAiC;AAC1C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,mDAAmD;AAAA,IACrE;AAEA,QAAI,KAAK,gBAAgB;AACvB;AAAA,IACF;AAEA,QAAI,CAAC,IAAI;AACP,YAAM,IAAI,MAAM,iDAAiD;AAAA,IACnE;AAEA,SAAK,MAAM;AAEX,UAAM,KAAK,IAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAQf,UAAM,KAAK,IAAI,gCACb,KAAK,KAAK,OAAO,KAAK,4BAEtB,KAAK,KAAK,eAAe,KAAK,sBAChB,KAAK,KAAK,SAAS,KAAK,wBACtC,KAAK,KAAK,WAAW,KAAK,yBACT,KAAK,KAAK,YAAY,KAAK,uBAC5C,KAAK,KAAK,UAAU,KAAK,kBACf,KAAK,KAAK,KAAK,KAAK,qBAC9B,KAAK,KAAK,QAAQ,KAAK,uBACR,KAAK,KAAK,UAAU,KAAK,uBACxC,KAAK,KAAK,UAAU,KAAK,qBACZ,KAAK,KAAK,QAAQ,KAAK,2BACpC,KAAK,KAAK,cAAc,KAAK;AAAA;AAAA;AAK/B,UAAM,KAAK,IAAI,qBAAqB,KAAK;AAEzC,SAAK,iBAAiB;AAAA,EACxB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,UAAU;AACd,QAAI,KAAK,aAAa;AACpB;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB;AAAA,IACF;AAEA,UAAM,KAAK,IAAI,yBAAyB,KAAK;AAE7C,SAAK,cAAc;AAAA,EACrB;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,IAAI,MAeO;AACf,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,mDAAmD;AAAA,IACrE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,yCAAyC;AAAA,IAC3D;AAGA,UAAM,KAAK,IAAI,wCACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,mCACpB,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,oCACpB,KAAK,IAAI,KAAK,cACR,KAAK,IAAI,MAAM;AAAA;AAAA;AAKvB,UAAM,KAAK,IACR,yCAAyC,KAAK;AAGjD,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,QAAQ,MAKG;AACf,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,mDAAmD;AAAA,IACrE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,6CAA6C;AAAA,IAC/D;AAGA,UAAM,KAAK,IAAI,mCAAmC,KAAK,GAAG,KAAK;AAAA;AAAA;AAK/D,UAAM,KAAK,IACR,6CAA6C,KAAK;AAGrD,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,MAAM,MAeQ;AAClB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,mDAAmD;AAAA,IACrE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,2CAA2C;AAAA,IAC7D;AAGA,UAAM,KAAK,IAAI,0CACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,mCACpB,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,+CACpB,KAAK,eAAe,KAAK,cACnB,KAAK,eAAe,MAAM;AAAA;AAAA;AAKlC,UAAM,KAAK,IACR,2CAA2C,KAAK;AAGnD,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,UAA8B;AAChC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,mDAAmD;AAAA,IACrE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,qDAAqD;AAAA,IACvE;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,8CAA8C,KAAK;AAGtD,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,UAAwB;AAC1B,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,mDAAmD;AAAA,IACrE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,qDAAqD;AAAA,IACvE;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,8CAA8C,KAAK;AAGtD,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,aAAmC;AACrC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,mDAAmD;AAAA,IACrE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,iDAAiD,KAAK;AAGzD,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,QAA4B;AAC9B,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,mDAAmD;AAAA,IACrE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,mDAAmD;AAAA,IACrE;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,4CAA4C,KAAK;AAGpD,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,aAA0C;AAC5C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,mDAAmD;AAAA,IACrE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,iDAAiD,KAAK;AAGzD,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,UAAuC;AACzC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,mDAAmD;AAAA,IACrE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,qDAAqD;AAAA,IACvE;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,8CAA8C,KAAK;AAGtD,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,iBAAkC;AACpC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,mDAAmD;AAAA,IACrE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,qDAAqD,KAAK;AAG7D,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,oBAAsC;AACxC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,mDAAmD;AAAA,IACrE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,wDAAwD,KAAK;AAGhE,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AACF;","names":[]}