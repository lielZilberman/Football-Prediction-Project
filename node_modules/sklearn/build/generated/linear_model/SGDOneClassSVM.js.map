{"version":3,"sources":["../../../src/generated/linear_model/SGDOneClassSVM.ts"],"sourcesContent":["/* eslint-disable */\n/* NOTE: This file is auto-generated. Do not edit it directly. */\n\nimport crypto from 'node:crypto'\n\nimport { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types'\n\n/**\n  Solves linear One-Class SVM using Stochastic Gradient Descent.\n\n  This implementation is meant to be used with a kernel approximation technique (e.g. `sklearn.kernel\\_approximation.Nystroem`) to obtain results similar to `sklearn.svm.OneClassSVM` which uses a Gaussian kernel by default.\n\n  Read more in the [User Guide](../sgd.html#sgd-online-one-class-svm).\n\n  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDOneClassSVM.html)\n */\nexport class SGDOneClassSVM {\n  id: string\n  opts: any\n\n  _py: PythonBridge\n  _isInitialized: boolean = false\n  _isDisposed: boolean = false\n\n  constructor(opts?: {\n    /**\n      The nu parameter of the One Class SVM: an upper bound on the fraction of training errors and a lower bound of the fraction of support vectors. Should be in the interval (0, 1\\]. By default 0.5 will be taken.\n\n      @defaultValue `0.5`\n     */\n    nu?: number\n\n    /**\n      Whether the intercept should be estimated or not. Defaults to `true`.\n\n      @defaultValue `true`\n     */\n    fit_intercept?: boolean\n\n    /**\n      The maximum number of passes over the training data (aka epochs). It only impacts the behavior in the `fit` method, and not the `partial\\_fit`. Defaults to 1000.\n\n      @defaultValue `1000`\n     */\n    max_iter?: number\n\n    /**\n      The stopping criterion. If it is not `undefined`, the iterations will stop when (loss > previous\\_loss - tol). Defaults to 1e-3.\n\n      @defaultValue `0.001`\n     */\n    tol?: number\n\n    /**\n      Whether or not the training data should be shuffled after each epoch. Defaults to `true`.\n\n      @defaultValue `true`\n     */\n    shuffle?: boolean\n\n    /**\n      The verbosity level.\n\n      @defaultValue `0`\n     */\n    verbose?: number\n\n    /**\n      The seed of the pseudo random number generator to use when shuffling the data. If int, random\\_state is the seed used by the random number generator; If RandomState instance, random\\_state is the random number generator; If `undefined`, the random number generator is the RandomState instance used by `np.random`.\n     */\n    random_state?: number\n\n    /**\n      The learning rate schedule to use with `fit`. (If using `partial\\_fit`, learning rate must be controlled directly).\n\n      @defaultValue `'optimal'`\n     */\n    learning_rate?: 'constant' | 'optimal' | 'invscaling' | 'adaptive'\n\n    /**\n      The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules. The default value is 0.0 as eta0 is not used by the default schedule ‘optimal’.\n\n      @defaultValue `0`\n     */\n    eta0?: number\n\n    /**\n      The exponent for inverse scaling learning rate \\[default 0.5\\].\n\n      @defaultValue `0.5`\n     */\n    power_t?: number\n\n    /**\n      When set to `true`, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. See [the Glossary](../../glossary.html#term-warm_start).\n\n      Repeatedly calling fit or partial\\_fit when warm\\_start is `true` can result in a different solution than when calling fit a single time because of the way the data is shuffled. If a dynamic learning rate is used, the learning rate is adapted depending on the number of samples already seen. Calling `fit` resets this counter, while `partial\\_fit` will result in increasing the existing counter.\n\n      @defaultValue `false`\n     */\n    warm_start?: boolean\n\n    /**\n      When set to `true`, computes the averaged SGD weights and stores the result in the `coef\\_` attribute. If set to an int greater than 1, averaging will begin once the total number of samples seen reaches average. So `average=10` will begin averaging after seeing 10 samples.\n\n      @defaultValue `false`\n     */\n    average?: boolean | number\n  }) {\n    this.id = `SGDOneClassSVM${crypto.randomUUID().split('-')[0]}`\n    this.opts = opts || {}\n  }\n\n  get py(): PythonBridge {\n    return this._py\n  }\n\n  set py(pythonBridge: PythonBridge) {\n    this._py = pythonBridge\n  }\n\n  /**\n    Initializes the underlying Python resources.\n\n    This instance is not usable until the `Promise` returned by `init()` resolves.\n   */\n  async init(py: PythonBridge): Promise<void> {\n    if (this._isDisposed) {\n      throw new Error('This SGDOneClassSVM instance has already been disposed')\n    }\n\n    if (this._isInitialized) {\n      return\n    }\n\n    if (!py) {\n      throw new Error('SGDOneClassSVM.init requires a PythonBridge instance')\n    }\n\n    this._py = py\n\n    await this._py.ex`\nimport numpy as np\nfrom sklearn.linear_model import SGDOneClassSVM\ntry: bridgeSGDOneClassSVM\nexcept NameError: bridgeSGDOneClassSVM = {}\n`\n\n    // set up constructor params\n    await this._py.ex`ctor_SGDOneClassSVM = {'nu': ${\n      this.opts['nu'] ?? undefined\n    }, 'fit_intercept': ${\n      this.opts['fit_intercept'] ?? undefined\n    }, 'max_iter': ${this.opts['max_iter'] ?? undefined}, 'tol': ${\n      this.opts['tol'] ?? undefined\n    }, 'shuffle': ${this.opts['shuffle'] ?? undefined}, 'verbose': ${\n      this.opts['verbose'] ?? undefined\n    }, 'random_state': ${\n      this.opts['random_state'] ?? undefined\n    }, 'learning_rate': ${this.opts['learning_rate'] ?? undefined}, 'eta0': ${\n      this.opts['eta0'] ?? undefined\n    }, 'power_t': ${this.opts['power_t'] ?? undefined}, 'warm_start': ${\n      this.opts['warm_start'] ?? undefined\n    }, 'average': ${this.opts['average'] ?? undefined}}\n\nctor_SGDOneClassSVM = {k: v for k, v in ctor_SGDOneClassSVM.items() if v is not None}`\n\n    await this._py\n      .ex`bridgeSGDOneClassSVM[${this.id}] = SGDOneClassSVM(**ctor_SGDOneClassSVM)`\n\n    this._isInitialized = true\n  }\n\n  /**\n    Disposes of the underlying Python resources.\n\n    Once `dispose()` is called, the instance is no longer usable.\n   */\n  async dispose() {\n    if (this._isDisposed) {\n      return\n    }\n\n    if (!this._isInitialized) {\n      return\n    }\n\n    await this._py.ex`del bridgeSGDOneClassSVM[${this.id}]`\n\n    this._isDisposed = true\n  }\n\n  /**\n    Signed distance to the separating hyperplane.\n\n    Signed distance is positive for an inlier and negative for an outlier.\n   */\n  async decision_function(opts: {\n    /**\n      Testing data.\n     */\n    X?: ArrayLike | SparseMatrix\n  }): Promise<ArrayLike> {\n    if (this._isDisposed) {\n      throw new Error('This SGDOneClassSVM instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'SGDOneClassSVM must call init() before decision_function()'\n      )\n    }\n\n    // set up method params\n    await this._py.ex`pms_SGDOneClassSVM_decision_function = {'X': ${\n      opts['X'] ?? undefined\n    }}\n\npms_SGDOneClassSVM_decision_function = {k: v for k, v in pms_SGDOneClassSVM_decision_function.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_SGDOneClassSVM_decision_function = bridgeSGDOneClassSVM[${this.id}].decision_function(**pms_SGDOneClassSVM_decision_function)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_SGDOneClassSVM_decision_function.tolist() if hasattr(res_SGDOneClassSVM_decision_function, 'tolist') else res_SGDOneClassSVM_decision_function`\n  }\n\n  /**\n    Convert coefficient matrix to dense array format.\n\n    Converts the `coef\\_` member (back) to a numpy.ndarray. This is the default format of `coef\\_` and is required for fitting, so calling this method is only required on models that have previously been sparsified; otherwise, it is a no-op.\n   */\n  async densify(opts: {}): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This SGDOneClassSVM instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('SGDOneClassSVM must call init() before densify()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_SGDOneClassSVM_densify = {}\n\npms_SGDOneClassSVM_densify = {k: v for k, v in pms_SGDOneClassSVM_densify.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_SGDOneClassSVM_densify = bridgeSGDOneClassSVM[${this.id}].densify(**pms_SGDOneClassSVM_densify)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_SGDOneClassSVM_densify.tolist() if hasattr(res_SGDOneClassSVM_densify, 'tolist') else res_SGDOneClassSVM_densify`\n  }\n\n  /**\n    Fit linear One-Class SVM with Stochastic Gradient Descent.\n\n    This solves an equivalent optimization problem of the One-Class SVM primal optimization problem and returns a weight vector w and an offset rho such that the decision function is given by <w, x> - rho.\n   */\n  async fit(opts: {\n    /**\n      Training data.\n     */\n    X?: ArrayLike | SparseMatrix\n\n    /**\n      Not used, present for API consistency by convention.\n     */\n    y?: any\n\n    /**\n      The initial coefficients to warm-start the optimization.\n     */\n    coef_init?: any\n\n    /**\n      The initial offset to warm-start the optimization.\n     */\n    offset_init?: any\n\n    /**\n      Weights applied to individual samples. If not provided, uniform weights are assumed. These weights will be multiplied with class\\_weight (passed through the constructor) if class\\_weight is specified.\n     */\n    sample_weight?: ArrayLike\n  }): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This SGDOneClassSVM instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('SGDOneClassSVM must call init() before fit()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_SGDOneClassSVM_fit = {'X': ${\n      opts['X'] ?? undefined\n    }, 'y': ${opts['y'] ?? undefined}, 'coef_init': ${\n      opts['coef_init'] ?? undefined\n    }, 'offset_init': ${opts['offset_init'] ?? undefined}, 'sample_weight': ${\n      opts['sample_weight'] ?? undefined\n    }}\n\npms_SGDOneClassSVM_fit = {k: v for k, v in pms_SGDOneClassSVM_fit.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_SGDOneClassSVM_fit = bridgeSGDOneClassSVM[${this.id}].fit(**pms_SGDOneClassSVM_fit)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_SGDOneClassSVM_fit.tolist() if hasattr(res_SGDOneClassSVM_fit, 'tolist') else res_SGDOneClassSVM_fit`\n  }\n\n  /**\n    Perform fit on X and returns labels for X.\n\n    Returns -1 for outliers and 1 for inliers.\n   */\n  async fit_predict(opts: {\n    /**\n      The input samples.\n     */\n    X?: ArrayLike | SparseMatrix[]\n\n    /**\n      Not used, present for API consistency by convention.\n     */\n    y?: any\n  }): Promise<NDArray> {\n    if (this._isDisposed) {\n      throw new Error('This SGDOneClassSVM instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('SGDOneClassSVM must call init() before fit_predict()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_SGDOneClassSVM_fit_predict = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None, 'y': ${opts['y'] ?? undefined}}\n\npms_SGDOneClassSVM_fit_predict = {k: v for k, v in pms_SGDOneClassSVM_fit_predict.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_SGDOneClassSVM_fit_predict = bridgeSGDOneClassSVM[${this.id}].fit_predict(**pms_SGDOneClassSVM_fit_predict)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_SGDOneClassSVM_fit_predict.tolist() if hasattr(res_SGDOneClassSVM_fit_predict, 'tolist') else res_SGDOneClassSVM_fit_predict`\n  }\n\n  /**\n    Fit linear One-Class SVM with Stochastic Gradient Descent.\n   */\n  async partial_fit(opts: {\n    /**\n      Subset of the training data.\n     */\n    X?: ArrayLike | SparseMatrix\n\n    /**\n      Not used, present for API consistency by convention.\n     */\n    y?: any\n\n    /**\n      Weights applied to individual samples. If not provided, uniform weights are assumed.\n     */\n    sample_weight?: ArrayLike\n  }): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This SGDOneClassSVM instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('SGDOneClassSVM must call init() before partial_fit()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_SGDOneClassSVM_partial_fit = {'X': ${\n      opts['X'] ?? undefined\n    }, 'y': ${opts['y'] ?? undefined}, 'sample_weight': ${\n      opts['sample_weight'] ?? undefined\n    }}\n\npms_SGDOneClassSVM_partial_fit = {k: v for k, v in pms_SGDOneClassSVM_partial_fit.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_SGDOneClassSVM_partial_fit = bridgeSGDOneClassSVM[${this.id}].partial_fit(**pms_SGDOneClassSVM_partial_fit)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_SGDOneClassSVM_partial_fit.tolist() if hasattr(res_SGDOneClassSVM_partial_fit, 'tolist') else res_SGDOneClassSVM_partial_fit`\n  }\n\n  /**\n    Return labels (1 inlier, -1 outlier) of the samples.\n   */\n  async predict(opts: {\n    /**\n      Testing data.\n     */\n    X?: ArrayLike | SparseMatrix\n  }): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This SGDOneClassSVM instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('SGDOneClassSVM must call init() before predict()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_SGDOneClassSVM_predict = {'X': ${\n      opts['X'] ?? undefined\n    }}\n\npms_SGDOneClassSVM_predict = {k: v for k, v in pms_SGDOneClassSVM_predict.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_SGDOneClassSVM_predict = bridgeSGDOneClassSVM[${this.id}].predict(**pms_SGDOneClassSVM_predict)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_SGDOneClassSVM_predict.tolist() if hasattr(res_SGDOneClassSVM_predict, 'tolist') else res_SGDOneClassSVM_predict`\n  }\n\n  /**\n    Raw scoring function of the samples.\n   */\n  async score_samples(opts: {\n    /**\n      Testing data.\n     */\n    X?: ArrayLike | SparseMatrix\n  }): Promise<ArrayLike> {\n    if (this._isDisposed) {\n      throw new Error('This SGDOneClassSVM instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('SGDOneClassSVM must call init() before score_samples()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_SGDOneClassSVM_score_samples = {'X': ${\n      opts['X'] ?? undefined\n    }}\n\npms_SGDOneClassSVM_score_samples = {k: v for k, v in pms_SGDOneClassSVM_score_samples.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_SGDOneClassSVM_score_samples = bridgeSGDOneClassSVM[${this.id}].score_samples(**pms_SGDOneClassSVM_score_samples)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_SGDOneClassSVM_score_samples.tolist() if hasattr(res_SGDOneClassSVM_score_samples, 'tolist') else res_SGDOneClassSVM_score_samples`\n  }\n\n  /**\n    Convert coefficient matrix to sparse format.\n\n    Converts the `coef\\_` member to a scipy.sparse matrix, which for L1-regularized models can be much more memory- and storage-efficient than the usual numpy.ndarray representation.\n\n    The `intercept\\_` member is not converted.\n   */\n  async sparsify(opts: {}): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This SGDOneClassSVM instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('SGDOneClassSVM must call init() before sparsify()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_SGDOneClassSVM_sparsify = {}\n\npms_SGDOneClassSVM_sparsify = {k: v for k, v in pms_SGDOneClassSVM_sparsify.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_SGDOneClassSVM_sparsify = bridgeSGDOneClassSVM[${this.id}].sparsify(**pms_SGDOneClassSVM_sparsify)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_SGDOneClassSVM_sparsify.tolist() if hasattr(res_SGDOneClassSVM_sparsify, 'tolist') else res_SGDOneClassSVM_sparsify`\n  }\n\n  /**\n    Weights assigned to the features.\n   */\n  get coef_(): Promise<NDArray[]> {\n    if (this._isDisposed) {\n      throw new Error('This SGDOneClassSVM instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('SGDOneClassSVM must call init() before accessing coef_')\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_SGDOneClassSVM_coef_ = bridgeSGDOneClassSVM[${this.id}].coef_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_SGDOneClassSVM_coef_.tolist() if hasattr(attr_SGDOneClassSVM_coef_, 'tolist') else attr_SGDOneClassSVM_coef_`\n    })()\n  }\n\n  /**\n    Offset used to define the decision function from the raw scores. We have the relation: decision\\_function = score\\_samples - offset.\n   */\n  get offset_(): Promise<NDArray> {\n    if (this._isDisposed) {\n      throw new Error('This SGDOneClassSVM instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'SGDOneClassSVM must call init() before accessing offset_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_SGDOneClassSVM_offset_ = bridgeSGDOneClassSVM[${this.id}].offset_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_SGDOneClassSVM_offset_.tolist() if hasattr(attr_SGDOneClassSVM_offset_, 'tolist') else attr_SGDOneClassSVM_offset_`\n    })()\n  }\n\n  /**\n    The actual number of iterations to reach the stopping criterion.\n   */\n  get n_iter_(): Promise<number> {\n    if (this._isDisposed) {\n      throw new Error('This SGDOneClassSVM instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'SGDOneClassSVM must call init() before accessing n_iter_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_SGDOneClassSVM_n_iter_ = bridgeSGDOneClassSVM[${this.id}].n_iter_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_SGDOneClassSVM_n_iter_.tolist() if hasattr(attr_SGDOneClassSVM_n_iter_, 'tolist') else attr_SGDOneClassSVM_n_iter_`\n    })()\n  }\n\n  /**\n    Number of weight updates performed during training. Same as `(n\\_iter\\_ \\* n\\_samples + 1)`.\n   */\n  get t_(): Promise<number> {\n    if (this._isDisposed) {\n      throw new Error('This SGDOneClassSVM instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('SGDOneClassSVM must call init() before accessing t_')\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_SGDOneClassSVM_t_ = bridgeSGDOneClassSVM[${this.id}].t_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_SGDOneClassSVM_t_.tolist() if hasattr(attr_SGDOneClassSVM_t_, 'tolist') else attr_SGDOneClassSVM_t_`\n    })()\n  }\n\n  get loss_function_(): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This SGDOneClassSVM instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'SGDOneClassSVM must call init() before accessing loss_function_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_SGDOneClassSVM_loss_function_ = bridgeSGDOneClassSVM[${this.id}].loss_function_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_SGDOneClassSVM_loss_function_.tolist() if hasattr(attr_SGDOneClassSVM_loss_function_, 'tolist') else attr_SGDOneClassSVM_loss_function_`\n    })()\n  }\n\n  /**\n    Number of features seen during [fit](../../glossary.html#term-fit).\n   */\n  get n_features_in_(): Promise<number> {\n    if (this._isDisposed) {\n      throw new Error('This SGDOneClassSVM instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'SGDOneClassSVM must call init() before accessing n_features_in_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_SGDOneClassSVM_n_features_in_ = bridgeSGDOneClassSVM[${this.id}].n_features_in_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_SGDOneClassSVM_n_features_in_.tolist() if hasattr(attr_SGDOneClassSVM_n_features_in_, 'tolist') else attr_SGDOneClassSVM_n_features_in_`\n    })()\n  }\n\n  /**\n    Names of features seen during [fit](../../glossary.html#term-fit). Defined only when `X` has feature names that are all strings.\n   */\n  get feature_names_in_(): Promise<NDArray> {\n    if (this._isDisposed) {\n      throw new Error('This SGDOneClassSVM instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'SGDOneClassSVM must call init() before accessing feature_names_in_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_SGDOneClassSVM_feature_names_in_ = bridgeSGDOneClassSVM[${this.id}].feature_names_in_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_SGDOneClassSVM_feature_names_in_.tolist() if hasattr(attr_SGDOneClassSVM_feature_names_in_, 'tolist') else attr_SGDOneClassSVM_feature_names_in_`\n    })()\n  }\n}\n"],"mappings":";AAGA,OAAO,YAAY;AAaZ,IAAM,iBAAN,MAAqB;AAAA,EAQ1B,YAAY,MAoFT;AAvFH,0BAA0B;AAC1B,uBAAuB;AAuFrB,SAAK,KAAK,iBAAiB,OAAO,WAAW,EAAE,MAAM,GAAG,EAAE,CAAC;AAC3D,SAAK,OAAO,QAAQ,CAAC;AAAA,EACvB;AAAA,EAEA,IAAI,KAAmB;AACrB,WAAO,KAAK;AAAA,EACd;AAAA,EAEA,IAAI,GAAG,cAA4B;AACjC,SAAK,MAAM;AAAA,EACb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,KAAK,IAAiC;AAC1C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,KAAK,gBAAgB;AACvB;AAAA,IACF;AAEA,QAAI,CAAC,IAAI;AACP,YAAM,IAAI,MAAM,sDAAsD;AAAA,IACxE;AAEA,SAAK,MAAM;AAEX,UAAM,KAAK,IAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAQf,UAAM,KAAK,IAAI,kCACb,KAAK,KAAK,IAAI,KAAK,4BAEnB,KAAK,KAAK,eAAe,KAAK,uBACf,KAAK,KAAK,UAAU,KAAK,kBACxC,KAAK,KAAK,KAAK,KAAK,sBACN,KAAK,KAAK,SAAS,KAAK,sBACtC,KAAK,KAAK,SAAS,KAAK,2BAExB,KAAK,KAAK,cAAc,KAAK,4BACT,KAAK,KAAK,eAAe,KAAK,mBAClD,KAAK,KAAK,MAAM,KAAK,sBACP,KAAK,KAAK,SAAS,KAAK,yBACtC,KAAK,KAAK,YAAY,KAAK,sBACb,KAAK,KAAK,SAAS,KAAK;AAAA;AAAA;AAIxC,UAAM,KAAK,IACR,0BAA0B,KAAK;AAElC,SAAK,iBAAiB;AAAA,EACxB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,UAAU;AACd,QAAI,KAAK,aAAa;AACpB;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB;AAAA,IACF;AAEA,UAAM,KAAK,IAAI,8BAA8B,KAAK;AAElD,SAAK,cAAc;AAAA,EACrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,kBAAkB,MAKD;AACrB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAGA,UAAM,KAAK,IAAI,kDACb,KAAK,GAAG,KAAK;AAAA;AAAA;AAMf,UAAM,KAAK,IACR,iEAAiE,KAAK;AAGzE,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,QAAQ,MAAwB;AACpC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,kDAAkD;AAAA,IACpE;AAGA,UAAM,KAAK,IAAI;AAAA;AAAA;AAKf,UAAM,KAAK,IACR,uDAAuD,KAAK;AAG/D,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,IAAI,MAyBO;AACf,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,8CAA8C;AAAA,IAChE;AAGA,UAAM,KAAK,IAAI,oCACb,KAAK,GAAG,KAAK,gBACL,KAAK,GAAG,KAAK,wBACrB,KAAK,WAAW,KAAK,0BACH,KAAK,aAAa,KAAK,4BACzC,KAAK,eAAe,KAAK;AAAA;AAAA;AAM3B,UAAM,KAAK,IACR,mDAAmD,KAAK;AAG3D,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,YAAY,MAUG;AACnB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,sDAAsD;AAAA,IACxE;AAGA,UAAM,KAAK,IAAI,qDACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,0BAA6B,KAAK,GAAG,KAAK;AAAA;AAAA;AAKhE,UAAM,KAAK,IACR,2DAA2D,KAAK;AAGnE,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,YAAY,MAeD;AACf,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,sDAAsD;AAAA,IACxE;AAGA,UAAM,KAAK,IAAI,4CACb,KAAK,GAAG,KAAK,gBACL,KAAK,GAAG,KAAK,4BACrB,KAAK,eAAe,KAAK;AAAA;AAAA;AAM3B,UAAM,KAAK,IACR,2DAA2D,KAAK;AAGnE,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,QAAQ,MAKG;AACf,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,kDAAkD;AAAA,IACpE;AAGA,UAAM,KAAK,IAAI,wCACb,KAAK,GAAG,KAAK;AAAA;AAAA;AAMf,UAAM,KAAK,IACR,uDAAuD,KAAK;AAG/D,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,cAAc,MAKG;AACrB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAGA,UAAM,KAAK,IAAI,8CACb,KAAK,GAAG,KAAK;AAAA;AAAA;AAMf,UAAM,KAAK,IACR,6DAA6D,KAAK;AAGrE,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASA,MAAM,SAAS,MAAwB;AACrC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,mDAAmD;AAAA,IACrE;AAGA,UAAM,KAAK,IAAI;AAAA;AAAA;AAKf,UAAM,KAAK,IACR,wDAAwD,KAAK;AAGhE,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,QAA4B;AAC9B,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,sDAAsD,KAAK;AAG9D,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,UAA4B;AAC9B,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,wDAAwD,KAAK;AAGhE,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,UAA2B;AAC7B,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,wDAAwD,KAAK;AAGhE,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,KAAsB;AACxB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,qDAAqD;AAAA,IACvE;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,mDAAmD,KAAK;AAG3D,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA,EAEA,IAAI,iBAA+B;AACjC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,+DAA+D,KAAK;AAGvE,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,iBAAkC;AACpC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,+DAA+D,KAAK;AAGvE,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,oBAAsC;AACxC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,kEAAkE,KAAK;AAG1E,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AACF;","names":[]}