{"version":3,"sources":["../../../src/generated/linear_model/LogisticRegression.ts"],"sourcesContent":["/* eslint-disable */\n/* NOTE: This file is auto-generated. Do not edit it directly. */\n\nimport crypto from 'node:crypto'\n\nimport { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types'\n\n/**\n  Logistic Regression (aka logit, MaxEnt) classifier.\n\n  In the multiclass case, the training algorithm uses the one-vs-rest (OvR) scheme if the ‘multi\\_class’ option is set to ‘ovr’, and uses the cross-entropy loss if the ‘multi\\_class’ option is set to ‘multinomial’. (Currently the ‘multinomial’ option is supported only by the ‘lbfgs’, ‘sag’, ‘saga’ and ‘newton-cg’ solvers.)\n\n  This class implements regularized logistic regression using the ‘liblinear’ library, ‘newton-cg’, ‘sag’, ‘saga’ and ‘lbfgs’ solvers. **Note that regularization is applied by default**. It can handle both dense and sparse input. Use C-ordered arrays or CSR matrices containing 64-bit floats for optimal performance; any other input format will be converted (and copied).\n\n  The ‘newton-cg’, ‘sag’, and ‘lbfgs’ solvers support only L2 regularization with primal formulation, or no regularization. The ‘liblinear’ solver supports both L1 and L2 regularization, with a dual formulation only for the L2 penalty. The Elastic-Net regularization is only supported by the ‘saga’ solver.\n\n  Read more in the [User Guide](../linear_model.html#logistic-regression).\n\n  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n */\nexport class LogisticRegression {\n  id: string\n  opts: any\n\n  _py: PythonBridge\n  _isInitialized: boolean = false\n  _isDisposed: boolean = false\n\n  constructor(opts?: {\n    /**\n      Specify the norm of the penalty:\n\n      @defaultValue `'l2'`\n     */\n    penalty?: 'l1' | 'l2' | 'elasticnet'\n\n    /**\n      Dual or primal formulation. Dual formulation is only implemented for l2 penalty with liblinear solver. Prefer dual=`false` when n\\_samples > n\\_features.\n\n      @defaultValue `false`\n     */\n    dual?: boolean\n\n    /**\n      Tolerance for stopping criteria.\n\n      @defaultValue `0.0001`\n     */\n    tol?: number\n\n    /**\n      Inverse of regularization strength; must be a positive float. Like in support vector machines, smaller values specify stronger regularization.\n\n      @defaultValue `1`\n     */\n    C?: number\n\n    /**\n      Specifies if a constant (a.k.a. bias or intercept) should be added to the decision function.\n\n      @defaultValue `true`\n     */\n    fit_intercept?: boolean\n\n    /**\n      Useful only when the solver ‘liblinear’ is used and self.fit\\_intercept is set to `true`. In this case, x becomes \\[x, self.intercept\\_scaling\\], i.e. a “synthetic” feature with constant value equal to intercept\\_scaling is appended to the instance vector. The intercept becomes `intercept\\_scaling \\* synthetic\\_feature\\_weight`.\n\n      Note! the synthetic feature weight is subject to l1/l2 regularization as all other features. To lessen the effect of regularization on synthetic feature weight (and therefore on the intercept) intercept\\_scaling has to be increased.\n\n      @defaultValue `1`\n     */\n    intercept_scaling?: number\n\n    /**\n      Weights associated with classes in the form `{class\\_label: weight}`. If not given, all classes are supposed to have weight one.\n\n      The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as `n\\_samples / (n\\_classes \\* np.bincount(y))`.\n\n      Note that these weights will be multiplied with sample\\_weight (passed through the fit method) if sample\\_weight is specified.\n     */\n    class_weight?: any | 'balanced'\n\n    /**\n      Used when `solver` == ‘sag’, ‘saga’ or ‘liblinear’ to shuffle the data. See [Glossary](../../glossary.html#term-random_state) for details.\n     */\n    random_state?: number\n\n    /**\n      Algorithm to use in the optimization problem. Default is ‘lbfgs’. To choose a solver, you might want to consider the following aspects:\n\n      @defaultValue `'lbfgs'`\n     */\n    solver?:\n      | 'lbfgs'\n      | 'liblinear'\n      | 'newton-cg'\n      | 'newton-cholesky'\n      | 'sag'\n      | 'saga'\n\n    /**\n      Maximum number of iterations taken for the solvers to converge.\n\n      @defaultValue `100`\n     */\n    max_iter?: number\n\n    /**\n      If the option chosen is ‘ovr’, then a binary problem is fit for each label. For ‘multinomial’ the loss minimised is the multinomial loss fit across the entire probability distribution, *even when the data is binary*. ‘multinomial’ is unavailable when solver=’liblinear’. ‘auto’ selects ‘ovr’ if the data is binary, or if solver=’liblinear’, and otherwise selects ‘multinomial’.\n\n      @defaultValue `'auto'`\n     */\n    multi_class?: 'auto' | 'ovr' | 'multinomial'\n\n    /**\n      For the liblinear and lbfgs solvers set verbose to any positive number for verbosity.\n\n      @defaultValue `0`\n     */\n    verbose?: number\n\n    /**\n      When set to `true`, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. Useless for liblinear solver. See [the Glossary](../../glossary.html#term-warm_start).\n\n      @defaultValue `false`\n     */\n    warm_start?: boolean\n\n    /**\n      Number of CPU cores used when parallelizing over classes if multi\\_class=’ovr’”. This parameter is ignored when the `solver` is set to ‘liblinear’ regardless of whether ‘multi\\_class’ is specified or not. `undefined` means 1 unless in a [`joblib.parallel\\_backend`](https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend \"(in joblib v1.3.0.dev0)\") context. `\\-1` means using all processors. See [Glossary](../../glossary.html#term-n_jobs) for more details.\n     */\n    n_jobs?: number\n\n    /**\n      The Elastic-Net mixing parameter, with `0 <= l1\\_ratio <= 1`. Only used if `penalty='elasticnet'`. Setting `l1\\_ratio=0` is equivalent to using `penalty='l2'`, while setting `l1\\_ratio=1` is equivalent to using `penalty='l1'`. For `0 < l1\\_ratio <1`, the penalty is a combination of L1 and L2.\n     */\n    l1_ratio?: number\n  }) {\n    this.id = `LogisticRegression${crypto.randomUUID().split('-')[0]}`\n    this.opts = opts || {}\n  }\n\n  get py(): PythonBridge {\n    return this._py\n  }\n\n  set py(pythonBridge: PythonBridge) {\n    this._py = pythonBridge\n  }\n\n  /**\n    Initializes the underlying Python resources.\n\n    This instance is not usable until the `Promise` returned by `init()` resolves.\n   */\n  async init(py: PythonBridge): Promise<void> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This LogisticRegression instance has already been disposed'\n      )\n    }\n\n    if (this._isInitialized) {\n      return\n    }\n\n    if (!py) {\n      throw new Error(\n        'LogisticRegression.init requires a PythonBridge instance'\n      )\n    }\n\n    this._py = py\n\n    await this._py.ex`\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\ntry: bridgeLogisticRegression\nexcept NameError: bridgeLogisticRegression = {}\n`\n\n    // set up constructor params\n    await this._py.ex`ctor_LogisticRegression = {'penalty': ${\n      this.opts['penalty'] ?? undefined\n    }, 'dual': ${this.opts['dual'] ?? undefined}, 'tol': ${\n      this.opts['tol'] ?? undefined\n    }, 'C': ${this.opts['C'] ?? undefined}, 'fit_intercept': ${\n      this.opts['fit_intercept'] ?? undefined\n    }, 'intercept_scaling': ${\n      this.opts['intercept_scaling'] ?? undefined\n    }, 'class_weight': ${\n      this.opts['class_weight'] ?? undefined\n    }, 'random_state': ${this.opts['random_state'] ?? undefined}, 'solver': ${\n      this.opts['solver'] ?? undefined\n    }, 'max_iter': ${this.opts['max_iter'] ?? undefined}, 'multi_class': ${\n      this.opts['multi_class'] ?? undefined\n    }, 'verbose': ${this.opts['verbose'] ?? undefined}, 'warm_start': ${\n      this.opts['warm_start'] ?? undefined\n    }, 'n_jobs': ${this.opts['n_jobs'] ?? undefined}, 'l1_ratio': ${\n      this.opts['l1_ratio'] ?? undefined\n    }}\n\nctor_LogisticRegression = {k: v for k, v in ctor_LogisticRegression.items() if v is not None}`\n\n    await this._py\n      .ex`bridgeLogisticRegression[${this.id}] = LogisticRegression(**ctor_LogisticRegression)`\n\n    this._isInitialized = true\n  }\n\n  /**\n    Disposes of the underlying Python resources.\n\n    Once `dispose()` is called, the instance is no longer usable.\n   */\n  async dispose() {\n    if (this._isDisposed) {\n      return\n    }\n\n    if (!this._isInitialized) {\n      return\n    }\n\n    await this._py.ex`del bridgeLogisticRegression[${this.id}]`\n\n    this._isDisposed = true\n  }\n\n  /**\n    Predict confidence scores for samples.\n\n    The confidence score for a sample is proportional to the signed distance of that sample to the hyperplane.\n   */\n  async decision_function(opts: {\n    /**\n      The data matrix for which we want to get the confidence scores.\n     */\n    X?: ArrayLike | SparseMatrix[]\n  }): Promise<NDArray> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This LogisticRegression instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'LogisticRegression must call init() before decision_function()'\n      )\n    }\n\n    // set up method params\n    await this._py\n      .ex`pms_LogisticRegression_decision_function = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None}\n\npms_LogisticRegression_decision_function = {k: v for k, v in pms_LogisticRegression_decision_function.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_LogisticRegression_decision_function = bridgeLogisticRegression[${this.id}].decision_function(**pms_LogisticRegression_decision_function)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_LogisticRegression_decision_function.tolist() if hasattr(res_LogisticRegression_decision_function, 'tolist') else res_LogisticRegression_decision_function`\n  }\n\n  /**\n    Convert coefficient matrix to dense array format.\n\n    Converts the `coef\\_` member (back) to a numpy.ndarray. This is the default format of `coef\\_` and is required for fitting, so calling this method is only required on models that have previously been sparsified; otherwise, it is a no-op.\n   */\n  async densify(opts: {}): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This LogisticRegression instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('LogisticRegression must call init() before densify()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_LogisticRegression_densify = {}\n\npms_LogisticRegression_densify = {k: v for k, v in pms_LogisticRegression_densify.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_LogisticRegression_densify = bridgeLogisticRegression[${this.id}].densify(**pms_LogisticRegression_densify)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_LogisticRegression_densify.tolist() if hasattr(res_LogisticRegression_densify, 'tolist') else res_LogisticRegression_densify`\n  }\n\n  /**\n    Fit the model according to the given training data.\n   */\n  async fit(opts: {\n    /**\n      Training vector, where `n\\_samples` is the number of samples and `n\\_features` is the number of features.\n     */\n    X?: ArrayLike | SparseMatrix[]\n\n    /**\n      Target vector relative to X.\n     */\n    y?: ArrayLike\n\n    /**\n      Array of weights that are assigned to individual samples. If not provided, then each sample is given unit weight.\n     */\n    sample_weight?: any\n  }): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This LogisticRegression instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('LogisticRegression must call init() before fit()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_LogisticRegression_fit = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None, 'y': np.array(${\n      opts['y'] ?? undefined\n    }) if ${opts['y'] !== undefined} else None, 'sample_weight': np.array(${\n      opts['sample_weight'] ?? undefined\n    }) if ${opts['sample_weight'] !== undefined} else None}\n\npms_LogisticRegression_fit = {k: v for k, v in pms_LogisticRegression_fit.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_LogisticRegression_fit = bridgeLogisticRegression[${this.id}].fit(**pms_LogisticRegression_fit)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_LogisticRegression_fit.tolist() if hasattr(res_LogisticRegression_fit, 'tolist') else res_LogisticRegression_fit`\n  }\n\n  /**\n    Predict class labels for samples in X.\n   */\n  async predict(opts: {\n    /**\n      The data matrix for which we want to get the predictions.\n     */\n    X?: ArrayLike | SparseMatrix[]\n  }): Promise<NDArray> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This LogisticRegression instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('LogisticRegression must call init() before predict()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_LogisticRegression_predict = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None}\n\npms_LogisticRegression_predict = {k: v for k, v in pms_LogisticRegression_predict.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_LogisticRegression_predict = bridgeLogisticRegression[${this.id}].predict(**pms_LogisticRegression_predict)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_LogisticRegression_predict.tolist() if hasattr(res_LogisticRegression_predict, 'tolist') else res_LogisticRegression_predict`\n  }\n\n  /**\n    Predict logarithm of probability estimates.\n\n    The returned estimates for all classes are ordered by the label of classes.\n   */\n  async predict_log_proba(opts: {\n    /**\n      Vector to be scored, where `n\\_samples` is the number of samples and `n\\_features` is the number of features.\n     */\n    X?: ArrayLike[]\n  }): Promise<ArrayLike[]> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This LogisticRegression instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'LogisticRegression must call init() before predict_log_proba()'\n      )\n    }\n\n    // set up method params\n    await this._py\n      .ex`pms_LogisticRegression_predict_log_proba = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None}\n\npms_LogisticRegression_predict_log_proba = {k: v for k, v in pms_LogisticRegression_predict_log_proba.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_LogisticRegression_predict_log_proba = bridgeLogisticRegression[${this.id}].predict_log_proba(**pms_LogisticRegression_predict_log_proba)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_LogisticRegression_predict_log_proba.tolist() if hasattr(res_LogisticRegression_predict_log_proba, 'tolist') else res_LogisticRegression_predict_log_proba`\n  }\n\n  /**\n    Probability estimates.\n\n    The returned estimates for all classes are ordered by the label of classes.\n\n    For a multi\\_class problem, if multi\\_class is set to be “multinomial” the softmax function is used to find the predicted probability of each class. Else use a one-vs-rest approach, i.e calculate the probability of each class assuming it to be positive using the logistic function. and normalize these values across all the classes.\n   */\n  async predict_proba(opts: {\n    /**\n      Vector to be scored, where `n\\_samples` is the number of samples and `n\\_features` is the number of features.\n     */\n    X?: ArrayLike[]\n  }): Promise<ArrayLike[]> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This LogisticRegression instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'LogisticRegression must call init() before predict_proba()'\n      )\n    }\n\n    // set up method params\n    await this._py.ex`pms_LogisticRegression_predict_proba = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None}\n\npms_LogisticRegression_predict_proba = {k: v for k, v in pms_LogisticRegression_predict_proba.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_LogisticRegression_predict_proba = bridgeLogisticRegression[${this.id}].predict_proba(**pms_LogisticRegression_predict_proba)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_LogisticRegression_predict_proba.tolist() if hasattr(res_LogisticRegression_predict_proba, 'tolist') else res_LogisticRegression_predict_proba`\n  }\n\n  /**\n    Return the mean accuracy on the given test data and labels.\n\n    In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.\n   */\n  async score(opts: {\n    /**\n      Test samples.\n     */\n    X?: ArrayLike[]\n\n    /**\n      True labels for `X`.\n     */\n    y?: ArrayLike\n\n    /**\n      Sample weights.\n     */\n    sample_weight?: ArrayLike\n  }): Promise<number> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This LogisticRegression instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('LogisticRegression must call init() before score()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_LogisticRegression_score = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None, 'y': np.array(${\n      opts['y'] ?? undefined\n    }) if ${opts['y'] !== undefined} else None, 'sample_weight': np.array(${\n      opts['sample_weight'] ?? undefined\n    }) if ${opts['sample_weight'] !== undefined} else None}\n\npms_LogisticRegression_score = {k: v for k, v in pms_LogisticRegression_score.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_LogisticRegression_score = bridgeLogisticRegression[${this.id}].score(**pms_LogisticRegression_score)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_LogisticRegression_score.tolist() if hasattr(res_LogisticRegression_score, 'tolist') else res_LogisticRegression_score`\n  }\n\n  /**\n    Convert coefficient matrix to sparse format.\n\n    Converts the `coef\\_` member to a scipy.sparse matrix, which for L1-regularized models can be much more memory- and storage-efficient than the usual numpy.ndarray representation.\n\n    The `intercept\\_` member is not converted.\n   */\n  async sparsify(opts: {}): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This LogisticRegression instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('LogisticRegression must call init() before sparsify()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_LogisticRegression_sparsify = {}\n\npms_LogisticRegression_sparsify = {k: v for k, v in pms_LogisticRegression_sparsify.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_LogisticRegression_sparsify = bridgeLogisticRegression[${this.id}].sparsify(**pms_LogisticRegression_sparsify)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_LogisticRegression_sparsify.tolist() if hasattr(res_LogisticRegression_sparsify, 'tolist') else res_LogisticRegression_sparsify`\n  }\n\n  /**\n    A list of class labels known to the classifier.\n   */\n  get classes_(): Promise<NDArray> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This LogisticRegression instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'LogisticRegression must call init() before accessing classes_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_LogisticRegression_classes_ = bridgeLogisticRegression[${this.id}].classes_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_LogisticRegression_classes_.tolist() if hasattr(attr_LogisticRegression_classes_, 'tolist') else attr_LogisticRegression_classes_`\n    })()\n  }\n\n  /**\n    Coefficient of the features in the decision function.\n\n    `coef\\_` is of shape (1, n\\_features) when the given problem is binary. In particular, when `multi\\_class='multinomial'`, `coef\\_` corresponds to outcome 1 (`true`) and `\\-coef\\_` corresponds to outcome 0 (`false`).\n   */\n  get coef_(): Promise<NDArray[]> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This LogisticRegression instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'LogisticRegression must call init() before accessing coef_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_LogisticRegression_coef_ = bridgeLogisticRegression[${this.id}].coef_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_LogisticRegression_coef_.tolist() if hasattr(attr_LogisticRegression_coef_, 'tolist') else attr_LogisticRegression_coef_`\n    })()\n  }\n\n  /**\n    Intercept (a.k.a. bias) added to the decision function.\n\n    If `fit\\_intercept` is set to `false`, the intercept is set to zero. `intercept\\_` is of shape (1,) when the given problem is binary. In particular, when `multi\\_class='multinomial'`, `intercept\\_` corresponds to outcome 1 (`true`) and `\\-intercept\\_` corresponds to outcome 0 (`false`).\n   */\n  get intercept_(): Promise<NDArray> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This LogisticRegression instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'LogisticRegression must call init() before accessing intercept_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_LogisticRegression_intercept_ = bridgeLogisticRegression[${this.id}].intercept_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_LogisticRegression_intercept_.tolist() if hasattr(attr_LogisticRegression_intercept_, 'tolist') else attr_LogisticRegression_intercept_`\n    })()\n  }\n\n  /**\n    Number of features seen during [fit](../../glossary.html#term-fit).\n   */\n  get n_features_in_(): Promise<number> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This LogisticRegression instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'LogisticRegression must call init() before accessing n_features_in_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_LogisticRegression_n_features_in_ = bridgeLogisticRegression[${this.id}].n_features_in_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_LogisticRegression_n_features_in_.tolist() if hasattr(attr_LogisticRegression_n_features_in_, 'tolist') else attr_LogisticRegression_n_features_in_`\n    })()\n  }\n\n  /**\n    Names of features seen during [fit](../../glossary.html#term-fit). Defined only when `X` has feature names that are all strings.\n   */\n  get feature_names_in_(): Promise<NDArray> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This LogisticRegression instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'LogisticRegression must call init() before accessing feature_names_in_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_LogisticRegression_feature_names_in_ = bridgeLogisticRegression[${this.id}].feature_names_in_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_LogisticRegression_feature_names_in_.tolist() if hasattr(attr_LogisticRegression_feature_names_in_, 'tolist') else attr_LogisticRegression_feature_names_in_`\n    })()\n  }\n\n  /**\n    Actual number of iterations for all classes. If binary or multinomial, it returns only 1 element. For liblinear solver, only the maximum number of iteration across all classes is given.\n   */\n  get n_iter_(): Promise<NDArray> {\n    if (this._isDisposed) {\n      throw new Error(\n        'This LogisticRegression instance has already been disposed'\n      )\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'LogisticRegression must call init() before accessing n_iter_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_LogisticRegression_n_iter_ = bridgeLogisticRegression[${this.id}].n_iter_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_LogisticRegression_n_iter_.tolist() if hasattr(attr_LogisticRegression_n_iter_, 'tolist') else attr_LogisticRegression_n_iter_`\n    })()\n  }\n}\n"],"mappings":";AAGA,OAAO,YAAY;AAiBZ,IAAM,qBAAN,MAAyB;AAAA,EAQ9B,YAAY,MA6GT;AAhHH,0BAA0B;AAC1B,uBAAuB;AAgHrB,SAAK,KAAK,qBAAqB,OAAO,WAAW,EAAE,MAAM,GAAG,EAAE,CAAC;AAC/D,SAAK,OAAO,QAAQ,CAAC;AAAA,EACvB;AAAA,EAEA,IAAI,KAAmB;AACrB,WAAO,KAAK;AAAA,EACd;AAAA,EAEA,IAAI,GAAG,cAA4B;AACjC,SAAK,MAAM;AAAA,EACb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,KAAK,IAAiC;AAC1C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,KAAK,gBAAgB;AACvB;AAAA,IACF;AAEA,QAAI,CAAC,IAAI;AACP,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,SAAK,MAAM;AAEX,UAAM,KAAK,IAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAQf,UAAM,KAAK,IAAI,2CACb,KAAK,KAAK,SAAS,KAAK,mBACb,KAAK,KAAK,MAAM,KAAK,kBAChC,KAAK,KAAK,KAAK,KAAK,gBACZ,KAAK,KAAK,GAAG,KAAK,4BAC1B,KAAK,KAAK,eAAe,KAAK,gCAE9B,KAAK,KAAK,mBAAmB,KAAK,2BAElC,KAAK,KAAK,cAAc,KAAK,2BACV,KAAK,KAAK,cAAc,KAAK,qBAChD,KAAK,KAAK,QAAQ,KAAK,uBACR,KAAK,KAAK,UAAU,KAAK,0BACxC,KAAK,KAAK,aAAa,KAAK,sBACd,KAAK,KAAK,SAAS,KAAK,yBACtC,KAAK,KAAK,YAAY,KAAK,qBACd,KAAK,KAAK,QAAQ,KAAK,uBACpC,KAAK,KAAK,UAAU,KAAK;AAAA;AAAA;AAK3B,UAAM,KAAK,IACR,8BAA8B,KAAK;AAEtC,SAAK,iBAAiB;AAAA,EACxB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,UAAU;AACd,QAAI,KAAK,aAAa;AACpB;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB;AAAA,IACF;AAEA,UAAM,KAAK,IAAI,kCAAkC,KAAK;AAEtD,SAAK,cAAc;AAAA,EACrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,kBAAkB,MAKH;AACnB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAGA,UAAM,KAAK,IACR,+DACD,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM;AAAA;AAAA;AAKtB,UAAM,KAAK,IACR,yEAAyE,KAAK;AAGjF,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,QAAQ,MAAwB;AACpC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,sDAAsD;AAAA,IACxE;AAGA,UAAM,KAAK,IAAI;AAAA;AAAA;AAKf,UAAM,KAAK,IACR,+DAA+D,KAAK;AAGvE,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,IAAI,MAeO;AACf,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,kDAAkD;AAAA,IACpE;AAGA,UAAM,KAAK,IAAI,iDACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,mCACpB,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,+CACpB,KAAK,eAAe,KAAK,cACnB,KAAK,eAAe,MAAM;AAAA;AAAA;AAKlC,UAAM,KAAK,IACR,2DAA2D,KAAK;AAGnE,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,QAAQ,MAKO;AACnB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,sDAAsD;AAAA,IACxE;AAGA,UAAM,KAAK,IAAI,qDACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM;AAAA;AAAA;AAKtB,UAAM,KAAK,IACR,+DAA+D,KAAK;AAGvE,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,kBAAkB,MAKC;AACvB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAGA,UAAM,KAAK,IACR,+DACD,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM;AAAA;AAAA;AAKtB,UAAM,KAAK,IACR,yEAAyE,KAAK;AAGjF,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASA,MAAM,cAAc,MAKK;AACvB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAGA,UAAM,KAAK,IAAI,2DACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM;AAAA;AAAA;AAKtB,UAAM,KAAK,IACR,qEAAqE,KAAK;AAG7E,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,MAAM,MAeQ;AAClB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,oDAAoD;AAAA,IACtE;AAGA,UAAM,KAAK,IAAI,mDACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,mCACpB,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,+CACpB,KAAK,eAAe,KAAK,cACnB,KAAK,eAAe,MAAM;AAAA;AAAA;AAKlC,UAAM,KAAK,IACR,6DAA6D,KAAK;AAGrE,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASA,MAAM,SAAS,MAAwB;AACrC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,uDAAuD;AAAA,IACzE;AAGA,UAAM,KAAK,IAAI;AAAA;AAAA;AAKf,UAAM,KAAK,IACR,gEAAgE,KAAK;AAGxE,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,WAA6B;AAC/B,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,iEAAiE,KAAK;AAGzE,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,IAAI,QAA4B;AAC9B,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,8DAA8D,KAAK;AAGtE,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,IAAI,aAA+B;AACjC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,mEAAmE,KAAK;AAG3E,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,iBAAkC;AACpC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,uEAAuE,KAAK;AAG/E,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,oBAAsC;AACxC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,0EAA0E,KAAK;AAGlF,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,UAA4B;AAC9B,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,gEAAgE,KAAK;AAGxE,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AACF;","names":[]}