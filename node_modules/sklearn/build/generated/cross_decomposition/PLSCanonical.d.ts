import { PythonBridge, NDArray, ArrayLike } from '@/sklearn/types';
/**
  Partial Least Squares transformer and regressor.

  Read more in the [User Guide](../cross_decomposition.html#cross-decomposition).

  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.cross_decomposition.PLSCanonical.html)
 */
export declare class PLSCanonical {
    id: string;
    opts: any;
    _py: PythonBridge;
    _isInitialized: boolean;
    _isDisposed: boolean;
    constructor(opts?: {
        /**
          Number of components to keep. Should be in `\[1, min(n\_samples, n\_features, n\_targets)\]`.
    
          @defaultValue `2`
         */
        n_components?: number;
        /**
          Whether to scale `X` and `Y`.
    
          @defaultValue `true`
         */
        scale?: boolean;
        /**
          The algorithm used to estimate the first singular vectors of the cross-covariance matrix. ‘nipals’ uses the power method while ‘svd’ will compute the whole SVD.
    
          @defaultValue `'nipals'`
         */
        algorithm?: 'nipals' | 'svd';
        /**
          The maximum number of iterations of the power method when `algorithm='nipals'`. Ignored otherwise.
    
          @defaultValue `500`
         */
        max_iter?: number;
        /**
          The tolerance used as convergence criteria in the power method: the algorithm stops whenever the squared norm of `u\_i \- u\_{i-1}` is less than `tol`, where `u` corresponds to the left singular vector.
    
          @defaultValue `0.000001`
         */
        tol?: number;
        /**
          Whether to copy `X` and `Y` in fit before applying centering, and potentially scaling. If `false`, these operations will be done inplace, modifying both arrays.
    
          @defaultValue `true`
         */
        copy?: boolean;
    });
    get py(): PythonBridge;
    set py(pythonBridge: PythonBridge);
    /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
    init(py: PythonBridge): Promise<void>;
    /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
    dispose(): Promise<void>;
    /**
      Fit model to data.
     */
    fit(opts: {
        /**
          Training vectors, where `n\_samples` is the number of samples and `n\_features` is the number of predictors.
         */
        X?: ArrayLike[];
        /**
          Target vectors, where `n\_samples` is the number of samples and `n\_targets` is the number of response variables.
         */
        Y?: ArrayLike;
    }): Promise<any>;
    /**
      Learn and apply the dimension reduction on the train data.
     */
    fit_transform(opts: {
        /**
          Training vectors, where `n\_samples` is the number of samples and `n\_features` is the number of predictors.
         */
        X?: ArrayLike[];
        /**
          Target vectors, where `n\_samples` is the number of samples and `n\_targets` is the number of response variables.
         */
        y?: ArrayLike[];
    }): Promise<NDArray[]>;
    /**
      Get output feature names for transformation.
  
      The feature names out will prefixed by the lowercased class name. For example, if the transformer outputs 3 features, then the feature names out are: `\["class\_name0", "class\_name1", "class\_name2"\]`.
     */
    get_feature_names_out(opts: {
        /**
          Only used to validate feature names with the names seen in [`fit`](#sklearn.cross_decomposition.PLSCanonical.fit "sklearn.cross_decomposition.PLSCanonical.fit").
         */
        input_features?: any;
    }): Promise<any>;
    /**
      Transform data back to its original space.
     */
    inverse_transform(opts: {
        /**
          New data, where `n\_samples` is the number of samples and `n\_components` is the number of pls components.
         */
        X?: ArrayLike[];
        /**
          New target, where `n\_samples` is the number of samples and `n\_components` is the number of pls components.
         */
        Y?: ArrayLike[];
    }): Promise<NDArray[]>;
    /**
      Predict targets of given samples.
     */
    predict(opts: {
        /**
          Samples.
         */
        X?: ArrayLike[];
        /**
          Whether to copy `X` and `Y`, or perform in-place normalization.
    
          @defaultValue `true`
         */
        copy?: boolean;
    }): Promise<NDArray>;
    /**
      Return the coefficient of determination of the prediction.
  
      The coefficient of determination \\(R^2\\) is defined as \\((1 - \\frac{u}{v})\\), where \\(u\\) is the residual sum of squares `((y\_true \- y\_pred)\*\* 2).sum()` and \\(v\\) is the total sum of squares `((y\_true \- y\_true.mean()) \*\* 2).sum()`. The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of `y`, disregarding the input features, would get a \\(R^2\\) score of 0.0.
     */
    score(opts: {
        /**
          Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape `(n\_samples, n\_samples\_fitted)`, where `n\_samples\_fitted` is the number of samples used in the fitting for the estimator.
         */
        X?: ArrayLike[];
        /**
          True values for `X`.
         */
        y?: ArrayLike;
        /**
          Sample weights.
         */
        sample_weight?: ArrayLike;
    }): Promise<number>;
    /**
      Set output container.
  
      See [Introducing the set\_output API](../../auto_examples/miscellaneous/plot_set_output.html#sphx-glr-auto-examples-miscellaneous-plot-set-output-py) for an example on how to use the API.
     */
    set_output(opts: {
        /**
          Configure output of `transform` and `fit\_transform`.
         */
        transform?: 'default' | 'pandas';
    }): Promise<any>;
    /**
      Apply the dimension reduction.
     */
    transform(opts: {
        /**
          Samples to transform.
         */
        X?: ArrayLike[];
        /**
          Target vectors.
         */
        Y?: ArrayLike[];
        /**
          Whether to copy `X` and `Y`, or perform in-place normalization.
    
          @defaultValue `true`
         */
        copy?: boolean;
    }): Promise<any>;
    /**
      The left singular vectors of the cross-covariance matrices of each iteration.
     */
    get x_weights_(): Promise<NDArray[]>;
    /**
      The right singular vectors of the cross-covariance matrices of each iteration.
     */
    get y_weights_(): Promise<NDArray[]>;
    /**
      The loadings of `X`.
     */
    get x_loadings_(): Promise<NDArray[]>;
    /**
      The loadings of `Y`.
     */
    get y_loadings_(): Promise<NDArray[]>;
    /**
      The projection matrix used to transform `X`.
     */
    get x_rotations_(): Promise<NDArray[]>;
    /**
      The projection matrix used to transform `Y`.
     */
    get y_rotations_(): Promise<NDArray[]>;
    /**
      The intercepts of the linear model such that `Y` is approximated as `Y \= X @ coef\_ + intercept\_`.
     */
    get intercept_(): Promise<NDArray>;
    /**
      Number of iterations of the power method, for each component. Empty if `algorithm='svd'`.
     */
    get n_iter_(): Promise<any[]>;
    /**
      Number of features seen during [fit](../../glossary.html#term-fit).
     */
    get n_features_in_(): Promise<number>;
    /**
      Names of features seen during [fit](../../glossary.html#term-fit). Defined only when `X` has feature names that are all strings.
     */
    get feature_names_in_(): Promise<NDArray>;
}
//# sourceMappingURL=PLSCanonical.d.ts.map