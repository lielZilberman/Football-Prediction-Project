import { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types';
/**
  An object for detecting outliers in a Gaussian distributed dataset.

  Read more in the [User Guide](../outlier_detection.html#outlier-detection).

  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.covariance.EllipticEnvelope.html)
 */
export declare class EllipticEnvelope {
    id: string;
    opts: any;
    _py: PythonBridge;
    _isInitialized: boolean;
    _isDisposed: boolean;
    constructor(opts?: {
        /**
          Specify if the estimated precision is stored.
    
          @defaultValue `true`
         */
        store_precision?: boolean;
        /**
          If `true`, the support of robust location and covariance estimates is computed, and a covariance estimate is recomputed from it, without centering the data. Useful to work with data whose mean is significantly equal to zero but is not exactly zero. If `false`, the robust location and covariance are directly computed with the FastMCD algorithm without additional treatment.
    
          @defaultValue `false`
         */
        assume_centered?: boolean;
        /**
          The proportion of points to be included in the support of the raw MCD estimate. If `undefined`, the minimum value of support\_fraction will be used within the algorithm: `\[n\_sample + n\_features + 1\] / 2`. Range is (0, 1).
         */
        support_fraction?: number;
        /**
          The amount of contamination of the data set, i.e. the proportion of outliers in the data set. Range is (0, 0.5\].
    
          @defaultValue `0.1`
         */
        contamination?: number;
        /**
          Determines the pseudo random number generator for shuffling the data. Pass an int for reproducible results across multiple function calls. See [Glossary](../../glossary.html#term-random_state).
         */
        random_state?: number;
    });
    get py(): PythonBridge;
    set py(pythonBridge: PythonBridge);
    /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
    init(py: PythonBridge): Promise<void>;
    /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
    dispose(): Promise<void>;
    /**
      Apply a correction to raw Minimum Covariance Determinant estimates.
  
      Correction using the empirical correction factor suggested by Rousseeuw and Van Driessen in [\[RVD\]](#rbb2ba44703ed-rvd).
     */
    correct_covariance(opts: {
        /**
          The data matrix, with p features and n samples. The data set must be the one which was used to compute the raw estimates.
         */
        data?: ArrayLike[];
    }): Promise<NDArray[]>;
    /**
      Compute the decision function of the given observations.
     */
    decision_function(opts: {
        /**
          The data matrix.
         */
        X?: ArrayLike[];
    }): Promise<NDArray>;
    /**
      Compute the Mean Squared Error between two covariance estimators.
     */
    error_norm(opts: {
        /**
          The covariance to compare with.
         */
        comp_cov?: ArrayLike[];
        /**
          The type of norm used to compute the error. Available error types: - ‘frobenius’ (default): sqrt(tr(A^t.A)) - ‘spectral’: sqrt(max(eigenvalues(A^t.A)) where A is the error `(comp\_cov \- self.covariance\_)`.
    
          @defaultValue `'frobenius'`
         */
        norm?: 'frobenius' | 'spectral';
        /**
          If `true` (default), the squared error norm is divided by n\_features. If `false`, the squared error norm is not rescaled.
    
          @defaultValue `true`
         */
        scaling?: boolean;
        /**
          Whether to compute the squared error norm or the error norm. If `true` (default), the squared error norm is returned. If `false`, the error norm is returned.
    
          @defaultValue `true`
         */
        squared?: boolean;
    }): Promise<number>;
    /**
      Fit the EllipticEnvelope model.
     */
    fit(opts: {
        /**
          Training data.
         */
        X?: ArrayLike[];
        /**
          Not used, present for API consistency by convention.
         */
        y?: any;
    }): Promise<any>;
    /**
      Perform fit on X and returns labels for X.
  
      Returns -1 for outliers and 1 for inliers.
     */
    fit_predict(opts: {
        /**
          The input samples.
         */
        X?: ArrayLike | SparseMatrix[];
        /**
          Not used, present for API consistency by convention.
         */
        y?: any;
    }): Promise<NDArray>;
    /**
      Getter for the precision matrix.
     */
    get_precision(opts: {
        /**
          The precision matrix associated to the current covariance object.
         */
        precision_?: ArrayLike[];
    }): Promise<any>;
    /**
      Compute the squared Mahalanobis distances of given observations.
     */
    mahalanobis(opts: {
        /**
          The observations, the Mahalanobis distances of the which we compute. Observations are assumed to be drawn from the same distribution than the data used in fit.
         */
        X?: ArrayLike[];
    }): Promise<NDArray>;
    /**
      Predict labels (1 inlier, -1 outlier) of X according to fitted model.
     */
    predict(opts: {
        /**
          The data matrix.
         */
        X?: ArrayLike[];
    }): Promise<NDArray>;
    /**
      Re-weight raw Minimum Covariance Determinant estimates.
  
      Re-weight observations using Rousseeuw’s method (equivalent to deleting outlying observations from the data set before computing location and covariance estimates) described in [\[RVDriessen\]](#rd2c89e63f1c9-rvdriessen).
     */
    reweight_covariance(opts: {
        /**
          The data matrix, with p features and n samples. The data set must be the one which was used to compute the raw estimates.
         */
        data?: ArrayLike[];
    }): Promise<NDArray>;
    /**
      Return the mean accuracy on the given test data and labels.
  
      In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.
     */
    score(opts: {
        /**
          Test samples.
         */
        X?: ArrayLike[];
        /**
          True labels for X.
         */
        y?: ArrayLike;
        /**
          Sample weights.
         */
        sample_weight?: ArrayLike;
    }): Promise<number>;
    /**
      Compute the negative Mahalanobis distances.
     */
    score_samples(opts: {
        /**
          The data matrix.
         */
        X?: ArrayLike[];
    }): Promise<ArrayLike>;
    /**
      Estimated robust location.
     */
    get location_(): Promise<NDArray>;
    /**
      Estimated robust covariance matrix.
     */
    get covariance_(): Promise<NDArray[]>;
    /**
      Estimated pseudo inverse matrix. (stored only if store\_precision is `true`)
     */
    get precision_(): Promise<NDArray[]>;
    /**
      A mask of the observations that have been used to compute the robust estimates of location and shape.
     */
    get support_(): Promise<NDArray>;
    /**
      Offset used to define the decision function from the raw scores. We have the relation: `decision\_function \= score\_samples \- offset\_`. The offset depends on the contamination parameter and is defined in such a way we obtain the expected number of outliers (samples with decision function < 0) in training.
     */
    get offset_(): Promise<number>;
    /**
      The raw robust estimated location before correction and re-weighting.
     */
    get raw_location_(): Promise<NDArray>;
    /**
      The raw robust estimated covariance before correction and re-weighting.
     */
    get raw_covariance_(): Promise<NDArray[]>;
    /**
      A mask of the observations that have been used to compute the raw robust estimates of location and shape, before correction and re-weighting.
     */
    get raw_support_(): Promise<NDArray>;
    /**
      Mahalanobis distances of the training set (on which [`fit`](#sklearn.covariance.EllipticEnvelope.fit "sklearn.covariance.EllipticEnvelope.fit") is called) observations.
     */
    get dist_(): Promise<NDArray>;
    /**
      Number of features seen during [fit](../../glossary.html#term-fit).
     */
    get n_features_in_(): Promise<number>;
    /**
      Names of features seen during [fit](../../glossary.html#term-fit). Defined only when `X` has feature names that are all strings.
     */
    get feature_names_in_(): Promise<NDArray>;
}
//# sourceMappingURL=EllipticEnvelope.d.ts.map