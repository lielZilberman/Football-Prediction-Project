{"version":3,"sources":["../../../src/generated/kernel_ridge/KernelRidge.ts"],"sourcesContent":["/* eslint-disable */\n/* NOTE: This file is auto-generated. Do not edit it directly. */\n\nimport crypto from 'node:crypto'\n\nimport { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types'\n\n/**\n  Kernel ridge regression.\n\n  Kernel ridge regression (KRR) combines ridge regression (linear least squares with l2-norm regularization) with the kernel trick. It thus learns a linear function in the space induced by the respective kernel and the data. For non-linear kernels, this corresponds to a non-linear function in the original space.\n\n  The form of the model learned by KRR is identical to support vector regression (SVR). However, different loss functions are used: KRR uses squared error loss while support vector regression uses epsilon-insensitive loss, both combined with l2 regularization. In contrast to SVR, fitting a KRR model can be done in closed-form and is typically faster for medium-sized datasets. On the other hand, the learned model is non-sparse and thus slower than SVR, which learns a sparse model for epsilon > 0, at prediction-time.\n\n  This estimator has built-in support for multi-variate regression (i.e., when y is a 2d-array of shape \\[n\\_samples, n\\_targets\\]).\n\n  Read more in the [User Guide](../kernel_ridge.html#kernel-ridge).\n\n  [Python Reference](https://scikit-learn.org/stable/modules/generated/sklearn.kernel_ridge.KernelRidge.html)\n */\nexport class KernelRidge {\n  id: string\n  opts: any\n\n  _py: PythonBridge\n  _isInitialized: boolean = false\n  _isDisposed: boolean = false\n\n  constructor(opts?: {\n    /**\n      Regularization strength; must be a positive float. Regularization improves the conditioning of the problem and reduces the variance of the estimates. Larger values specify stronger regularization. Alpha corresponds to `1 / (2C)` in other linear models such as [`LogisticRegression`](sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression \"sklearn.linear_model.LogisticRegression\") or [`LinearSVC`](sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC \"sklearn.svm.LinearSVC\"). If an array is passed, penalties are assumed to be specific to the targets. Hence they must correspond in number. See [Ridge regression and classification](../linear_model.html#ridge-regression) for formula.\n\n      @defaultValue `1`\n     */\n    alpha?: number | ArrayLike\n\n    /**\n      Kernel mapping used internally. This parameter is directly passed to `pairwise\\_kernel`. If `kernel` is a string, it must be one of the metrics in `pairwise.PAIRWISE\\_KERNEL\\_FUNCTIONS` or “precomputed”. If `kernel` is “precomputed”, X is assumed to be a kernel matrix. Alternatively, if `kernel` is a callable function, it is called on each pair of instances (rows) and the resulting value recorded. The callable should take two rows from X as input and return the corresponding kernel value as a single number. This means that callables from [`sklearn.metrics.pairwise`](../classes.html#module-sklearn.metrics.pairwise \"sklearn.metrics.pairwise\") are not allowed, as they operate on matrices, not single samples. Use the string identifying the kernel instead.\n\n      @defaultValue `'linear'`\n     */\n    kernel?: string\n\n    /**\n      Gamma parameter for the RBF, laplacian, polynomial, exponential chi2 and sigmoid kernels. Interpretation of the default value is left to the kernel; see the documentation for sklearn.metrics.pairwise. Ignored by other kernels.\n     */\n    gamma?: number\n\n    /**\n      Degree of the polynomial kernel. Ignored by other kernels.\n\n      @defaultValue `3`\n     */\n    degree?: number\n\n    /**\n      Zero coefficient for polynomial and sigmoid kernels. Ignored by other kernels.\n\n      @defaultValue `1`\n     */\n    coef0?: number\n\n    /**\n      Additional parameters (keyword arguments) for kernel function passed as callable object.\n     */\n    kernel_params?: any\n  }) {\n    this.id = `KernelRidge${crypto.randomUUID().split('-')[0]}`\n    this.opts = opts || {}\n  }\n\n  get py(): PythonBridge {\n    return this._py\n  }\n\n  set py(pythonBridge: PythonBridge) {\n    this._py = pythonBridge\n  }\n\n  /**\n    Initializes the underlying Python resources.\n\n    This instance is not usable until the `Promise` returned by `init()` resolves.\n   */\n  async init(py: PythonBridge): Promise<void> {\n    if (this._isDisposed) {\n      throw new Error('This KernelRidge instance has already been disposed')\n    }\n\n    if (this._isInitialized) {\n      return\n    }\n\n    if (!py) {\n      throw new Error('KernelRidge.init requires a PythonBridge instance')\n    }\n\n    this._py = py\n\n    await this._py.ex`\nimport numpy as np\nfrom sklearn.kernel_ridge import KernelRidge\ntry: bridgeKernelRidge\nexcept NameError: bridgeKernelRidge = {}\n`\n\n    // set up constructor params\n    await this._py.ex`ctor_KernelRidge = {'alpha': np.array(${\n      this.opts['alpha'] ?? undefined\n    }) if ${this.opts['alpha'] !== undefined} else None, 'kernel': ${\n      this.opts['kernel'] ?? undefined\n    }, 'gamma': ${this.opts['gamma'] ?? undefined}, 'degree': ${\n      this.opts['degree'] ?? undefined\n    }, 'coef0': ${this.opts['coef0'] ?? undefined}, 'kernel_params': ${\n      this.opts['kernel_params'] ?? undefined\n    }}\n\nctor_KernelRidge = {k: v for k, v in ctor_KernelRidge.items() if v is not None}`\n\n    await this._py\n      .ex`bridgeKernelRidge[${this.id}] = KernelRidge(**ctor_KernelRidge)`\n\n    this._isInitialized = true\n  }\n\n  /**\n    Disposes of the underlying Python resources.\n\n    Once `dispose()` is called, the instance is no longer usable.\n   */\n  async dispose() {\n    if (this._isDisposed) {\n      return\n    }\n\n    if (!this._isInitialized) {\n      return\n    }\n\n    await this._py.ex`del bridgeKernelRidge[${this.id}]`\n\n    this._isDisposed = true\n  }\n\n  /**\n    Fit Kernel Ridge regression model.\n   */\n  async fit(opts: {\n    /**\n      Training data. If kernel == “precomputed” this is instead a precomputed kernel matrix, of shape (n\\_samples, n\\_samples).\n     */\n    X?: ArrayLike | SparseMatrix[]\n\n    /**\n      Target values.\n     */\n    y?: ArrayLike\n\n    /**\n      Individual weights for each sample, ignored if `undefined` is passed.\n     */\n    sample_weight?: number | ArrayLike\n  }): Promise<any> {\n    if (this._isDisposed) {\n      throw new Error('This KernelRidge instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('KernelRidge must call init() before fit()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_KernelRidge_fit = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None, 'y': np.array(${\n      opts['y'] ?? undefined\n    }) if ${opts['y'] !== undefined} else None, 'sample_weight': np.array(${\n      opts['sample_weight'] ?? undefined\n    }) if ${opts['sample_weight'] !== undefined} else None}\n\npms_KernelRidge_fit = {k: v for k, v in pms_KernelRidge_fit.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_KernelRidge_fit = bridgeKernelRidge[${this.id}].fit(**pms_KernelRidge_fit)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_KernelRidge_fit.tolist() if hasattr(res_KernelRidge_fit, 'tolist') else res_KernelRidge_fit`\n  }\n\n  /**\n    Predict using the kernel ridge model.\n   */\n  async predict(opts: {\n    /**\n      Samples. If kernel == “precomputed” this is instead a precomputed kernel matrix, shape = \\[n\\_samples, n\\_samples\\_fitted\\], where n\\_samples\\_fitted is the number of samples used in the fitting for this estimator.\n     */\n    X?: ArrayLike | SparseMatrix[]\n  }): Promise<NDArray> {\n    if (this._isDisposed) {\n      throw new Error('This KernelRidge instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('KernelRidge must call init() before predict()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_KernelRidge_predict = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None}\n\npms_KernelRidge_predict = {k: v for k, v in pms_KernelRidge_predict.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_KernelRidge_predict = bridgeKernelRidge[${this.id}].predict(**pms_KernelRidge_predict)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_KernelRidge_predict.tolist() if hasattr(res_KernelRidge_predict, 'tolist') else res_KernelRidge_predict`\n  }\n\n  /**\n    Return the coefficient of determination of the prediction.\n\n    The coefficient of determination \\\\(R^2\\\\) is defined as \\\\((1 - \\\\frac{u}{v})\\\\), where \\\\(u\\\\) is the residual sum of squares `((y\\_true \\- y\\_pred)\\*\\* 2).sum()` and \\\\(v\\\\) is the total sum of squares `((y\\_true \\- y\\_true.mean()) \\*\\* 2).sum()`. The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of `y`, disregarding the input features, would get a \\\\(R^2\\\\) score of 0.0.\n   */\n  async score(opts: {\n    /**\n      Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape `(n\\_samples, n\\_samples\\_fitted)`, where `n\\_samples\\_fitted` is the number of samples used in the fitting for the estimator.\n     */\n    X?: ArrayLike[]\n\n    /**\n      True values for `X`.\n     */\n    y?: ArrayLike\n\n    /**\n      Sample weights.\n     */\n    sample_weight?: ArrayLike\n  }): Promise<number> {\n    if (this._isDisposed) {\n      throw new Error('This KernelRidge instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('KernelRidge must call init() before score()')\n    }\n\n    // set up method params\n    await this._py.ex`pms_KernelRidge_score = {'X': np.array(${\n      opts['X'] ?? undefined\n    }) if ${opts['X'] !== undefined} else None, 'y': np.array(${\n      opts['y'] ?? undefined\n    }) if ${opts['y'] !== undefined} else None, 'sample_weight': np.array(${\n      opts['sample_weight'] ?? undefined\n    }) if ${opts['sample_weight'] !== undefined} else None}\n\npms_KernelRidge_score = {k: v for k, v in pms_KernelRidge_score.items() if v is not None}`\n\n    // invoke method\n    await this._py\n      .ex`res_KernelRidge_score = bridgeKernelRidge[${this.id}].score(**pms_KernelRidge_score)`\n\n    // convert the result from python to node.js\n    return this\n      ._py`res_KernelRidge_score.tolist() if hasattr(res_KernelRidge_score, 'tolist') else res_KernelRidge_score`\n  }\n\n  /**\n    Representation of weight vector(s) in kernel space\n   */\n  get dual_coef_(): Promise<NDArray> {\n    if (this._isDisposed) {\n      throw new Error('This KernelRidge instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'KernelRidge must call init() before accessing dual_coef_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_KernelRidge_dual_coef_ = bridgeKernelRidge[${this.id}].dual_coef_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_KernelRidge_dual_coef_.tolist() if hasattr(attr_KernelRidge_dual_coef_, 'tolist') else attr_KernelRidge_dual_coef_`\n    })()\n  }\n\n  /**\n    Training data, which is also required for prediction. If kernel == “precomputed” this is instead the precomputed training matrix, of shape (n\\_samples, n\\_samples).\n   */\n  get X_fit_(): Promise<NDArray | SparseMatrix[]> {\n    if (this._isDisposed) {\n      throw new Error('This KernelRidge instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error('KernelRidge must call init() before accessing X_fit_')\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_KernelRidge_X_fit_ = bridgeKernelRidge[${this.id}].X_fit_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_KernelRidge_X_fit_.tolist() if hasattr(attr_KernelRidge_X_fit_, 'tolist') else attr_KernelRidge_X_fit_`\n    })()\n  }\n\n  /**\n    Number of features seen during [fit](../../glossary.html#term-fit).\n   */\n  get n_features_in_(): Promise<number> {\n    if (this._isDisposed) {\n      throw new Error('This KernelRidge instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'KernelRidge must call init() before accessing n_features_in_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_KernelRidge_n_features_in_ = bridgeKernelRidge[${this.id}].n_features_in_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_KernelRidge_n_features_in_.tolist() if hasattr(attr_KernelRidge_n_features_in_, 'tolist') else attr_KernelRidge_n_features_in_`\n    })()\n  }\n\n  /**\n    Names of features seen during [fit](../../glossary.html#term-fit). Defined only when `X` has feature names that are all strings.\n   */\n  get feature_names_in_(): Promise<NDArray> {\n    if (this._isDisposed) {\n      throw new Error('This KernelRidge instance has already been disposed')\n    }\n\n    if (!this._isInitialized) {\n      throw new Error(\n        'KernelRidge must call init() before accessing feature_names_in_'\n      )\n    }\n\n    return (async () => {\n      // invoke accessor\n      await this._py\n        .ex`attr_KernelRidge_feature_names_in_ = bridgeKernelRidge[${this.id}].feature_names_in_`\n\n      // convert the result from python to node.js\n      return this\n        ._py`attr_KernelRidge_feature_names_in_.tolist() if hasattr(attr_KernelRidge_feature_names_in_, 'tolist') else attr_KernelRidge_feature_names_in_`\n    })()\n  }\n}\n"],"mappings":";AAGA,OAAO,YAAY;AAiBZ,IAAM,cAAN,MAAkB;AAAA,EAQvB,YAAY,MAsCT;AAzCH,0BAA0B;AAC1B,uBAAuB;AAyCrB,SAAK,KAAK,cAAc,OAAO,WAAW,EAAE,MAAM,GAAG,EAAE,CAAC;AACxD,SAAK,OAAO,QAAQ,CAAC;AAAA,EACvB;AAAA,EAEA,IAAI,KAAmB;AACrB,WAAO,KAAK;AAAA,EACd;AAAA,EAEA,IAAI,GAAG,cAA4B;AACjC,SAAK,MAAM;AAAA,EACb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,KAAK,IAAiC;AAC1C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,qDAAqD;AAAA,IACvE;AAEA,QAAI,KAAK,gBAAgB;AACvB;AAAA,IACF;AAEA,QAAI,CAAC,IAAI;AACP,YAAM,IAAI,MAAM,mDAAmD;AAAA,IACrE;AAEA,SAAK,MAAM;AAEX,UAAM,KAAK,IAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAQf,UAAM,KAAK,IAAI,2CACb,KAAK,KAAK,OAAO,KAAK,cAChB,KAAK,KAAK,OAAO,MAAM,+BAC7B,KAAK,KAAK,QAAQ,KAAK,oBACX,KAAK,KAAK,OAAO,KAAK,qBAClC,KAAK,KAAK,QAAQ,KAAK,oBACX,KAAK,KAAK,OAAO,KAAK,4BAClC,KAAK,KAAK,eAAe,KAAK;AAAA;AAAA;AAKhC,UAAM,KAAK,IACR,uBAAuB,KAAK;AAE/B,SAAK,iBAAiB;AAAA,EACxB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,UAAU;AACd,QAAI,KAAK,aAAa;AACpB;AAAA,IACF;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB;AAAA,IACF;AAEA,UAAM,KAAK,IAAI,2BAA2B,KAAK;AAE/C,SAAK,cAAc;AAAA,EACrB;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,IAAI,MAeO;AACf,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,qDAAqD;AAAA,IACvE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,2CAA2C;AAAA,IAC7D;AAGA,UAAM,KAAK,IAAI,0CACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,mCACpB,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,+CACpB,KAAK,eAAe,KAAK,cACnB,KAAK,eAAe,MAAM;AAAA;AAAA;AAKlC,UAAM,KAAK,IACR,6CAA6C,KAAK;AAGrD,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,QAAQ,MAKO;AACnB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,qDAAqD;AAAA,IACvE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,+CAA+C;AAAA,IACjE;AAGA,UAAM,KAAK,IAAI,8CACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM;AAAA;AAAA;AAKtB,UAAM,KAAK,IACR,iDAAiD,KAAK;AAGzD,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,MAAM,MAeQ;AAClB,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,qDAAqD;AAAA,IACvE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,6CAA6C;AAAA,IAC/D;AAGA,UAAM,KAAK,IAAI,4CACb,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,mCACpB,KAAK,GAAG,KAAK,cACP,KAAK,GAAG,MAAM,+CACpB,KAAK,eAAe,KAAK,cACnB,KAAK,eAAe,MAAM;AAAA;AAAA;AAKlC,UAAM,KAAK,IACR,+CAA+C,KAAK;AAGvD,WAAO,KACJ;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,aAA+B;AACjC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,qDAAqD;AAAA,IACvE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,qDAAqD,KAAK;AAG7D,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,SAA4C;AAC9C,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,qDAAqD;AAAA,IACvE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI,MAAM,sDAAsD;AAAA,IACxE;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,iDAAiD,KAAK;AAGzD,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,iBAAkC;AACpC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,qDAAqD;AAAA,IACvE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,yDAAyD,KAAK;AAGjE,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AAAA;AAAA;AAAA;AAAA,EAKA,IAAI,oBAAsC;AACxC,QAAI,KAAK,aAAa;AACpB,YAAM,IAAI,MAAM,qDAAqD;AAAA,IACvE;AAEA,QAAI,CAAC,KAAK,gBAAgB;AACxB,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,YAAQ,YAAY;AAElB,YAAM,KAAK,IACR,4DAA4D,KAAK;AAGpE,aAAO,KACJ;AAAA,IACL,GAAG;AAAA,EACL;AACF;","names":[]}