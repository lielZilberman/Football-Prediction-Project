// src/generated/feature_extraction/text/TfidfVectorizer.ts
import crypto from "node:crypto";
var TfidfVectorizer = class {
  constructor(opts) {
    this._isInitialized = false;
    this._isDisposed = false;
    this.id = `TfidfVectorizer${crypto.randomUUID().split("-")[0]}`;
    this.opts = opts || {};
  }
  get py() {
    return this._py;
  }
  set py(pythonBridge) {
    this._py = pythonBridge;
  }
  /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
  async init(py) {
    if (this._isDisposed) {
      throw new Error("This TfidfVectorizer instance has already been disposed");
    }
    if (this._isInitialized) {
      return;
    }
    if (!py) {
      throw new Error("TfidfVectorizer.init requires a PythonBridge instance");
    }
    this._py = py;
    await this._py.ex`
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
try: bridgeTfidfVectorizer
except NameError: bridgeTfidfVectorizer = {}
`;
    await this._py.ex`ctor_TfidfVectorizer = {'input': ${this.opts["input"] ?? void 0}, 'encoding': ${this.opts["encoding"] ?? void 0}, 'decode_error': ${this.opts["decode_error"] ?? void 0}, 'strip_accents': ${this.opts["strip_accents"] ?? void 0}, 'lowercase': ${this.opts["lowercase"] ?? void 0}, 'preprocessor': ${this.opts["preprocessor"] ?? void 0}, 'tokenizer': ${this.opts["tokenizer"] ?? void 0}, 'analyzer': ${this.opts["analyzer"] ?? void 0}, 'stop_words': ${this.opts["stop_words"] ?? void 0}, 'token_pattern': ${this.opts["token_pattern"] ?? void 0}, 'ngram_range': ${this.opts["ngram_range"] ?? void 0}, 'max_df': ${this.opts["max_df"] ?? void 0}, 'min_df': ${this.opts["min_df"] ?? void 0}, 'max_features': ${this.opts["max_features"] ?? void 0}, 'vocabulary': ${this.opts["vocabulary"] ?? void 0}, 'binary': ${this.opts["binary"] ?? void 0}, 'dtype': ${this.opts["dtype"] ?? void 0}, 'norm': ${this.opts["norm"] ?? void 0}, 'use_idf': ${this.opts["use_idf"] ?? void 0}, 'smooth_idf': ${this.opts["smooth_idf"] ?? void 0}, 'sublinear_tf': ${this.opts["sublinear_tf"] ?? void 0}}

ctor_TfidfVectorizer = {k: v for k, v in ctor_TfidfVectorizer.items() if v is not None}`;
    await this._py.ex`bridgeTfidfVectorizer[${this.id}] = TfidfVectorizer(**ctor_TfidfVectorizer)`;
    this._isInitialized = true;
  }
  /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
  async dispose() {
    if (this._isDisposed) {
      return;
    }
    if (!this._isInitialized) {
      return;
    }
    await this._py.ex`del bridgeTfidfVectorizer[${this.id}]`;
    this._isDisposed = true;
  }
  /**
      Return a callable to process input data.
  
      The callable handles preprocessing, tokenization, and n-grams generation.
     */
  async build_analyzer(opts) {
    if (this._isDisposed) {
      throw new Error("This TfidfVectorizer instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "TfidfVectorizer must call init() before build_analyzer()"
      );
    }
    await this._py.ex`pms_TfidfVectorizer_build_analyzer = {}

pms_TfidfVectorizer_build_analyzer = {k: v for k, v in pms_TfidfVectorizer_build_analyzer.items() if v is not None}`;
    await this._py.ex`res_TfidfVectorizer_build_analyzer = bridgeTfidfVectorizer[${this.id}].build_analyzer(**pms_TfidfVectorizer_build_analyzer)`;
    return this._py`res_TfidfVectorizer_build_analyzer.tolist() if hasattr(res_TfidfVectorizer_build_analyzer, 'tolist') else res_TfidfVectorizer_build_analyzer`;
  }
  /**
    Return a function to preprocess the text before tokenization.
   */
  async build_preprocessor(opts) {
    if (this._isDisposed) {
      throw new Error("This TfidfVectorizer instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "TfidfVectorizer must call init() before build_preprocessor()"
      );
    }
    await this._py.ex`pms_TfidfVectorizer_build_preprocessor = {}

pms_TfidfVectorizer_build_preprocessor = {k: v for k, v in pms_TfidfVectorizer_build_preprocessor.items() if v is not None}`;
    await this._py.ex`res_TfidfVectorizer_build_preprocessor = bridgeTfidfVectorizer[${this.id}].build_preprocessor(**pms_TfidfVectorizer_build_preprocessor)`;
    return this._py`res_TfidfVectorizer_build_preprocessor.tolist() if hasattr(res_TfidfVectorizer_build_preprocessor, 'tolist') else res_TfidfVectorizer_build_preprocessor`;
  }
  /**
    Return a function that splits a string into a sequence of tokens.
   */
  async build_tokenizer(opts) {
    if (this._isDisposed) {
      throw new Error("This TfidfVectorizer instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "TfidfVectorizer must call init() before build_tokenizer()"
      );
    }
    await this._py.ex`pms_TfidfVectorizer_build_tokenizer = {}

pms_TfidfVectorizer_build_tokenizer = {k: v for k, v in pms_TfidfVectorizer_build_tokenizer.items() if v is not None}`;
    await this._py.ex`res_TfidfVectorizer_build_tokenizer = bridgeTfidfVectorizer[${this.id}].build_tokenizer(**pms_TfidfVectorizer_build_tokenizer)`;
    return this._py`res_TfidfVectorizer_build_tokenizer.tolist() if hasattr(res_TfidfVectorizer_build_tokenizer, 'tolist') else res_TfidfVectorizer_build_tokenizer`;
  }
  /**
      Decode the input into a string of unicode symbols.
  
      The decoding strategy depends on the vectorizer parameters.
     */
  async decode(opts) {
    if (this._isDisposed) {
      throw new Error("This TfidfVectorizer instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("TfidfVectorizer must call init() before decode()");
    }
    await this._py.ex`pms_TfidfVectorizer_decode = {'doc': ${opts["doc"] ?? void 0}}

pms_TfidfVectorizer_decode = {k: v for k, v in pms_TfidfVectorizer_decode.items() if v is not None}`;
    await this._py.ex`res_TfidfVectorizer_decode = bridgeTfidfVectorizer[${this.id}].decode(**pms_TfidfVectorizer_decode)`;
    return this._py`res_TfidfVectorizer_decode.tolist() if hasattr(res_TfidfVectorizer_decode, 'tolist') else res_TfidfVectorizer_decode`;
  }
  /**
    Learn vocabulary and idf from training set.
   */
  async fit(opts) {
    if (this._isDisposed) {
      throw new Error("This TfidfVectorizer instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("TfidfVectorizer must call init() before fit()");
    }
    await this._py.ex`pms_TfidfVectorizer_fit = {'raw_documents': ${opts["raw_documents"] ?? void 0}, 'y': ${opts["y"] ?? void 0}}

pms_TfidfVectorizer_fit = {k: v for k, v in pms_TfidfVectorizer_fit.items() if v is not None}`;
    await this._py.ex`res_TfidfVectorizer_fit = bridgeTfidfVectorizer[${this.id}].fit(**pms_TfidfVectorizer_fit)`;
    return this._py`res_TfidfVectorizer_fit.tolist() if hasattr(res_TfidfVectorizer_fit, 'tolist') else res_TfidfVectorizer_fit`;
  }
  /**
      Learn vocabulary and idf, return document-term matrix.
  
      This is equivalent to fit followed by transform, but more efficiently implemented.
     */
  async fit_transform(opts) {
    if (this._isDisposed) {
      throw new Error("This TfidfVectorizer instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("TfidfVectorizer must call init() before fit_transform()");
    }
    await this._py.ex`pms_TfidfVectorizer_fit_transform = {'raw_documents': ${opts["raw_documents"] ?? void 0}, 'y': ${opts["y"] ?? void 0}}

pms_TfidfVectorizer_fit_transform = {k: v for k, v in pms_TfidfVectorizer_fit_transform.items() if v is not None}`;
    await this._py.ex`res_TfidfVectorizer_fit_transform = bridgeTfidfVectorizer[${this.id}].fit_transform(**pms_TfidfVectorizer_fit_transform)`;
    return this._py`res_TfidfVectorizer_fit_transform.tolist() if hasattr(res_TfidfVectorizer_fit_transform, 'tolist') else res_TfidfVectorizer_fit_transform`;
  }
  /**
    Get output feature names for transformation.
   */
  async get_feature_names_out(opts) {
    if (this._isDisposed) {
      throw new Error("This TfidfVectorizer instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "TfidfVectorizer must call init() before get_feature_names_out()"
      );
    }
    await this._py.ex`pms_TfidfVectorizer_get_feature_names_out = {'input_features': ${opts["input_features"] ?? void 0}}

pms_TfidfVectorizer_get_feature_names_out = {k: v for k, v in pms_TfidfVectorizer_get_feature_names_out.items() if v is not None}`;
    await this._py.ex`res_TfidfVectorizer_get_feature_names_out = bridgeTfidfVectorizer[${this.id}].get_feature_names_out(**pms_TfidfVectorizer_get_feature_names_out)`;
    return this._py`res_TfidfVectorizer_get_feature_names_out.tolist() if hasattr(res_TfidfVectorizer_get_feature_names_out, 'tolist') else res_TfidfVectorizer_get_feature_names_out`;
  }
  /**
    Build or fetch the effective stop words list.
   */
  async get_stop_words(opts) {
    if (this._isDisposed) {
      throw new Error("This TfidfVectorizer instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "TfidfVectorizer must call init() before get_stop_words()"
      );
    }
    await this._py.ex`pms_TfidfVectorizer_get_stop_words = {}

pms_TfidfVectorizer_get_stop_words = {k: v for k, v in pms_TfidfVectorizer_get_stop_words.items() if v is not None}`;
    await this._py.ex`res_TfidfVectorizer_get_stop_words = bridgeTfidfVectorizer[${this.id}].get_stop_words(**pms_TfidfVectorizer_get_stop_words)`;
    return this._py`res_TfidfVectorizer_get_stop_words.tolist() if hasattr(res_TfidfVectorizer_get_stop_words, 'tolist') else res_TfidfVectorizer_get_stop_words`;
  }
  /**
    Return terms per document with nonzero entries in X.
   */
  async inverse_transform(opts) {
    if (this._isDisposed) {
      throw new Error("This TfidfVectorizer instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "TfidfVectorizer must call init() before inverse_transform()"
      );
    }
    await this._py.ex`pms_TfidfVectorizer_inverse_transform = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_TfidfVectorizer_inverse_transform = {k: v for k, v in pms_TfidfVectorizer_inverse_transform.items() if v is not None}`;
    await this._py.ex`res_TfidfVectorizer_inverse_transform = bridgeTfidfVectorizer[${this.id}].inverse_transform(**pms_TfidfVectorizer_inverse_transform)`;
    return this._py`res_TfidfVectorizer_inverse_transform.tolist() if hasattr(res_TfidfVectorizer_inverse_transform, 'tolist') else res_TfidfVectorizer_inverse_transform`;
  }
  /**
      Transform documents to document-term matrix.
  
      Uses the vocabulary and document frequencies (df) learned by fit (or fit\_transform).
     */
  async transform(opts) {
    if (this._isDisposed) {
      throw new Error("This TfidfVectorizer instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("TfidfVectorizer must call init() before transform()");
    }
    await this._py.ex`pms_TfidfVectorizer_transform = {'raw_documents': ${opts["raw_documents"] ?? void 0}}

pms_TfidfVectorizer_transform = {k: v for k, v in pms_TfidfVectorizer_transform.items() if v is not None}`;
    await this._py.ex`res_TfidfVectorizer_transform = bridgeTfidfVectorizer[${this.id}].transform(**pms_TfidfVectorizer_transform)`;
    return this._py`res_TfidfVectorizer_transform.tolist() if hasattr(res_TfidfVectorizer_transform, 'tolist') else res_TfidfVectorizer_transform`;
  }
  /**
    A mapping of terms to feature indices.
   */
  get vocabulary_() {
    if (this._isDisposed) {
      throw new Error("This TfidfVectorizer instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "TfidfVectorizer must call init() before accessing vocabulary_"
      );
    }
    return (async () => {
      await this._py.ex`attr_TfidfVectorizer_vocabulary_ = bridgeTfidfVectorizer[${this.id}].vocabulary_`;
      return this._py`attr_TfidfVectorizer_vocabulary_.tolist() if hasattr(attr_TfidfVectorizer_vocabulary_, 'tolist') else attr_TfidfVectorizer_vocabulary_`;
    })();
  }
  /**
    True if a fixed vocabulary of term to indices mapping is provided by the user.
   */
  get fixed_vocabulary_() {
    if (this._isDisposed) {
      throw new Error("This TfidfVectorizer instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "TfidfVectorizer must call init() before accessing fixed_vocabulary_"
      );
    }
    return (async () => {
      await this._py.ex`attr_TfidfVectorizer_fixed_vocabulary_ = bridgeTfidfVectorizer[${this.id}].fixed_vocabulary_`;
      return this._py`attr_TfidfVectorizer_fixed_vocabulary_.tolist() if hasattr(attr_TfidfVectorizer_fixed_vocabulary_, 'tolist') else attr_TfidfVectorizer_fixed_vocabulary_`;
    })();
  }
  /**
    Terms that were ignored because they either:
   */
  get stop_words_() {
    if (this._isDisposed) {
      throw new Error("This TfidfVectorizer instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "TfidfVectorizer must call init() before accessing stop_words_"
      );
    }
    return (async () => {
      await this._py.ex`attr_TfidfVectorizer_stop_words_ = bridgeTfidfVectorizer[${this.id}].stop_words_`;
      return this._py`attr_TfidfVectorizer_stop_words_.tolist() if hasattr(attr_TfidfVectorizer_stop_words_, 'tolist') else attr_TfidfVectorizer_stop_words_`;
    })();
  }
};
export {
  TfidfVectorizer
};
//# sourceMappingURL=TfidfVectorizer.js.map