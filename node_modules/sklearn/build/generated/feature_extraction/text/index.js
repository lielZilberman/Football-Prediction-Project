// src/generated/feature_extraction/text/CountVectorizer.ts
import crypto from "node:crypto";
var CountVectorizer = class {
  constructor(opts) {
    this._isInitialized = false;
    this._isDisposed = false;
    this.id = `CountVectorizer${crypto.randomUUID().split("-")[0]}`;
    this.opts = opts || {};
  }
  get py() {
    return this._py;
  }
  set py(pythonBridge) {
    this._py = pythonBridge;
  }
  /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
  async init(py) {
    if (this._isDisposed) {
      throw new Error("This CountVectorizer instance has already been disposed");
    }
    if (this._isInitialized) {
      return;
    }
    if (!py) {
      throw new Error("CountVectorizer.init requires a PythonBridge instance");
    }
    this._py = py;
    await this._py.ex`
import numpy as np
from sklearn.feature_extraction.text import CountVectorizer
try: bridgeCountVectorizer
except NameError: bridgeCountVectorizer = {}
`;
    await this._py.ex`ctor_CountVectorizer = {'input': ${this.opts["input"] ?? void 0}, 'encoding': ${this.opts["encoding"] ?? void 0}, 'decode_error': ${this.opts["decode_error"] ?? void 0}, 'strip_accents': ${this.opts["strip_accents"] ?? void 0}, 'lowercase': ${this.opts["lowercase"] ?? void 0}, 'preprocessor': ${this.opts["preprocessor"] ?? void 0}, 'tokenizer': ${this.opts["tokenizer"] ?? void 0}, 'stop_words': ${this.opts["stop_words"] ?? void 0}, 'token_pattern': ${this.opts["token_pattern"] ?? void 0}, 'ngram_range': ${this.opts["ngram_range"] ?? void 0}, 'analyzer': ${this.opts["analyzer"] ?? void 0}, 'max_df': ${this.opts["max_df"] ?? void 0}, 'min_df': ${this.opts["min_df"] ?? void 0}, 'max_features': ${this.opts["max_features"] ?? void 0}, 'vocabulary': ${this.opts["vocabulary"] ?? void 0}, 'binary': ${this.opts["binary"] ?? void 0}, 'dtype': ${this.opts["dtype"] ?? void 0}}

ctor_CountVectorizer = {k: v for k, v in ctor_CountVectorizer.items() if v is not None}`;
    await this._py.ex`bridgeCountVectorizer[${this.id}] = CountVectorizer(**ctor_CountVectorizer)`;
    this._isInitialized = true;
  }
  /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
  async dispose() {
    if (this._isDisposed) {
      return;
    }
    if (!this._isInitialized) {
      return;
    }
    await this._py.ex`del bridgeCountVectorizer[${this.id}]`;
    this._isDisposed = true;
  }
  /**
      Return a callable to process input data.
  
      The callable handles preprocessing, tokenization, and n-grams generation.
     */
  async build_analyzer(opts) {
    if (this._isDisposed) {
      throw new Error("This CountVectorizer instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "CountVectorizer must call init() before build_analyzer()"
      );
    }
    await this._py.ex`pms_CountVectorizer_build_analyzer = {}

pms_CountVectorizer_build_analyzer = {k: v for k, v in pms_CountVectorizer_build_analyzer.items() if v is not None}`;
    await this._py.ex`res_CountVectorizer_build_analyzer = bridgeCountVectorizer[${this.id}].build_analyzer(**pms_CountVectorizer_build_analyzer)`;
    return this._py`res_CountVectorizer_build_analyzer.tolist() if hasattr(res_CountVectorizer_build_analyzer, 'tolist') else res_CountVectorizer_build_analyzer`;
  }
  /**
    Return a function to preprocess the text before tokenization.
   */
  async build_preprocessor(opts) {
    if (this._isDisposed) {
      throw new Error("This CountVectorizer instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "CountVectorizer must call init() before build_preprocessor()"
      );
    }
    await this._py.ex`pms_CountVectorizer_build_preprocessor = {}

pms_CountVectorizer_build_preprocessor = {k: v for k, v in pms_CountVectorizer_build_preprocessor.items() if v is not None}`;
    await this._py.ex`res_CountVectorizer_build_preprocessor = bridgeCountVectorizer[${this.id}].build_preprocessor(**pms_CountVectorizer_build_preprocessor)`;
    return this._py`res_CountVectorizer_build_preprocessor.tolist() if hasattr(res_CountVectorizer_build_preprocessor, 'tolist') else res_CountVectorizer_build_preprocessor`;
  }
  /**
    Return a function that splits a string into a sequence of tokens.
   */
  async build_tokenizer(opts) {
    if (this._isDisposed) {
      throw new Error("This CountVectorizer instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "CountVectorizer must call init() before build_tokenizer()"
      );
    }
    await this._py.ex`pms_CountVectorizer_build_tokenizer = {}

pms_CountVectorizer_build_tokenizer = {k: v for k, v in pms_CountVectorizer_build_tokenizer.items() if v is not None}`;
    await this._py.ex`res_CountVectorizer_build_tokenizer = bridgeCountVectorizer[${this.id}].build_tokenizer(**pms_CountVectorizer_build_tokenizer)`;
    return this._py`res_CountVectorizer_build_tokenizer.tolist() if hasattr(res_CountVectorizer_build_tokenizer, 'tolist') else res_CountVectorizer_build_tokenizer`;
  }
  /**
      Decode the input into a string of unicode symbols.
  
      The decoding strategy depends on the vectorizer parameters.
     */
  async decode(opts) {
    if (this._isDisposed) {
      throw new Error("This CountVectorizer instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("CountVectorizer must call init() before decode()");
    }
    await this._py.ex`pms_CountVectorizer_decode = {'doc': ${opts["doc"] ?? void 0}}

pms_CountVectorizer_decode = {k: v for k, v in pms_CountVectorizer_decode.items() if v is not None}`;
    await this._py.ex`res_CountVectorizer_decode = bridgeCountVectorizer[${this.id}].decode(**pms_CountVectorizer_decode)`;
    return this._py`res_CountVectorizer_decode.tolist() if hasattr(res_CountVectorizer_decode, 'tolist') else res_CountVectorizer_decode`;
  }
  /**
    Learn a vocabulary dictionary of all tokens in the raw documents.
   */
  async fit(opts) {
    if (this._isDisposed) {
      throw new Error("This CountVectorizer instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("CountVectorizer must call init() before fit()");
    }
    await this._py.ex`pms_CountVectorizer_fit = {'raw_documents': ${opts["raw_documents"] ?? void 0}, 'y': ${opts["y"] ?? void 0}}

pms_CountVectorizer_fit = {k: v for k, v in pms_CountVectorizer_fit.items() if v is not None}`;
    await this._py.ex`res_CountVectorizer_fit = bridgeCountVectorizer[${this.id}].fit(**pms_CountVectorizer_fit)`;
    return this._py`res_CountVectorizer_fit.tolist() if hasattr(res_CountVectorizer_fit, 'tolist') else res_CountVectorizer_fit`;
  }
  /**
      Learn the vocabulary dictionary and return document-term matrix.
  
      This is equivalent to fit followed by transform, but more efficiently implemented.
     */
  async fit_transform(opts) {
    if (this._isDisposed) {
      throw new Error("This CountVectorizer instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("CountVectorizer must call init() before fit_transform()");
    }
    await this._py.ex`pms_CountVectorizer_fit_transform = {'raw_documents': ${opts["raw_documents"] ?? void 0}, 'y': ${opts["y"] ?? void 0}}

pms_CountVectorizer_fit_transform = {k: v for k, v in pms_CountVectorizer_fit_transform.items() if v is not None}`;
    await this._py.ex`res_CountVectorizer_fit_transform = bridgeCountVectorizer[${this.id}].fit_transform(**pms_CountVectorizer_fit_transform)`;
    return this._py`res_CountVectorizer_fit_transform.tolist() if hasattr(res_CountVectorizer_fit_transform, 'tolist') else res_CountVectorizer_fit_transform`;
  }
  /**
    Get output feature names for transformation.
   */
  async get_feature_names_out(opts) {
    if (this._isDisposed) {
      throw new Error("This CountVectorizer instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "CountVectorizer must call init() before get_feature_names_out()"
      );
    }
    await this._py.ex`pms_CountVectorizer_get_feature_names_out = {'input_features': ${opts["input_features"] ?? void 0}}

pms_CountVectorizer_get_feature_names_out = {k: v for k, v in pms_CountVectorizer_get_feature_names_out.items() if v is not None}`;
    await this._py.ex`res_CountVectorizer_get_feature_names_out = bridgeCountVectorizer[${this.id}].get_feature_names_out(**pms_CountVectorizer_get_feature_names_out)`;
    return this._py`res_CountVectorizer_get_feature_names_out.tolist() if hasattr(res_CountVectorizer_get_feature_names_out, 'tolist') else res_CountVectorizer_get_feature_names_out`;
  }
  /**
    Build or fetch the effective stop words list.
   */
  async get_stop_words(opts) {
    if (this._isDisposed) {
      throw new Error("This CountVectorizer instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "CountVectorizer must call init() before get_stop_words()"
      );
    }
    await this._py.ex`pms_CountVectorizer_get_stop_words = {}

pms_CountVectorizer_get_stop_words = {k: v for k, v in pms_CountVectorizer_get_stop_words.items() if v is not None}`;
    await this._py.ex`res_CountVectorizer_get_stop_words = bridgeCountVectorizer[${this.id}].get_stop_words(**pms_CountVectorizer_get_stop_words)`;
    return this._py`res_CountVectorizer_get_stop_words.tolist() if hasattr(res_CountVectorizer_get_stop_words, 'tolist') else res_CountVectorizer_get_stop_words`;
  }
  /**
    Return terms per document with nonzero entries in X.
   */
  async inverse_transform(opts) {
    if (this._isDisposed) {
      throw new Error("This CountVectorizer instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "CountVectorizer must call init() before inverse_transform()"
      );
    }
    await this._py.ex`pms_CountVectorizer_inverse_transform = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_CountVectorizer_inverse_transform = {k: v for k, v in pms_CountVectorizer_inverse_transform.items() if v is not None}`;
    await this._py.ex`res_CountVectorizer_inverse_transform = bridgeCountVectorizer[${this.id}].inverse_transform(**pms_CountVectorizer_inverse_transform)`;
    return this._py`res_CountVectorizer_inverse_transform.tolist() if hasattr(res_CountVectorizer_inverse_transform, 'tolist') else res_CountVectorizer_inverse_transform`;
  }
  /**
      Transform documents to document-term matrix.
  
      Extract token counts out of raw text documents using the vocabulary fitted with fit or the one provided to the constructor.
     */
  async transform(opts) {
    if (this._isDisposed) {
      throw new Error("This CountVectorizer instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("CountVectorizer must call init() before transform()");
    }
    await this._py.ex`pms_CountVectorizer_transform = {'raw_documents': ${opts["raw_documents"] ?? void 0}}

pms_CountVectorizer_transform = {k: v for k, v in pms_CountVectorizer_transform.items() if v is not None}`;
    await this._py.ex`res_CountVectorizer_transform = bridgeCountVectorizer[${this.id}].transform(**pms_CountVectorizer_transform)`;
    return this._py`res_CountVectorizer_transform.tolist() if hasattr(res_CountVectorizer_transform, 'tolist') else res_CountVectorizer_transform`;
  }
  /**
    A mapping of terms to feature indices.
   */
  get vocabulary_() {
    if (this._isDisposed) {
      throw new Error("This CountVectorizer instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "CountVectorizer must call init() before accessing vocabulary_"
      );
    }
    return (async () => {
      await this._py.ex`attr_CountVectorizer_vocabulary_ = bridgeCountVectorizer[${this.id}].vocabulary_`;
      return this._py`attr_CountVectorizer_vocabulary_.tolist() if hasattr(attr_CountVectorizer_vocabulary_, 'tolist') else attr_CountVectorizer_vocabulary_`;
    })();
  }
  /**
    True if a fixed vocabulary of term to indices mapping is provided by the user.
   */
  get fixed_vocabulary_() {
    if (this._isDisposed) {
      throw new Error("This CountVectorizer instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "CountVectorizer must call init() before accessing fixed_vocabulary_"
      );
    }
    return (async () => {
      await this._py.ex`attr_CountVectorizer_fixed_vocabulary_ = bridgeCountVectorizer[${this.id}].fixed_vocabulary_`;
      return this._py`attr_CountVectorizer_fixed_vocabulary_.tolist() if hasattr(attr_CountVectorizer_fixed_vocabulary_, 'tolist') else attr_CountVectorizer_fixed_vocabulary_`;
    })();
  }
  /**
    Terms that were ignored because they either:
   */
  get stop_words_() {
    if (this._isDisposed) {
      throw new Error("This CountVectorizer instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "CountVectorizer must call init() before accessing stop_words_"
      );
    }
    return (async () => {
      await this._py.ex`attr_CountVectorizer_stop_words_ = bridgeCountVectorizer[${this.id}].stop_words_`;
      return this._py`attr_CountVectorizer_stop_words_.tolist() if hasattr(attr_CountVectorizer_stop_words_, 'tolist') else attr_CountVectorizer_stop_words_`;
    })();
  }
};

// src/generated/feature_extraction/text/HashingVectorizer.ts
import crypto2 from "node:crypto";
var HashingVectorizer = class {
  constructor(opts) {
    this._isInitialized = false;
    this._isDisposed = false;
    this.id = `HashingVectorizer${crypto2.randomUUID().split("-")[0]}`;
    this.opts = opts || {};
  }
  get py() {
    return this._py;
  }
  set py(pythonBridge) {
    this._py = pythonBridge;
  }
  /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
  async init(py) {
    if (this._isDisposed) {
      throw new Error(
        "This HashingVectorizer instance has already been disposed"
      );
    }
    if (this._isInitialized) {
      return;
    }
    if (!py) {
      throw new Error("HashingVectorizer.init requires a PythonBridge instance");
    }
    this._py = py;
    await this._py.ex`
import numpy as np
from sklearn.feature_extraction.text import HashingVectorizer
try: bridgeHashingVectorizer
except NameError: bridgeHashingVectorizer = {}
`;
    await this._py.ex`ctor_HashingVectorizer = {'input': ${this.opts["input"] ?? void 0}, 'encoding': ${this.opts["encoding"] ?? void 0}, 'decode_error': ${this.opts["decode_error"] ?? void 0}, 'strip_accents': ${this.opts["strip_accents"] ?? void 0}, 'lowercase': ${this.opts["lowercase"] ?? void 0}, 'preprocessor': ${this.opts["preprocessor"] ?? void 0}, 'tokenizer': ${this.opts["tokenizer"] ?? void 0}, 'stop_words': ${this.opts["stop_words"] ?? void 0}, 'token_pattern': ${this.opts["token_pattern"] ?? void 0}, 'ngram_range': ${this.opts["ngram_range"] ?? void 0}, 'analyzer': ${this.opts["analyzer"] ?? void 0}, 'n_features': ${this.opts["n_features"] ?? void 0}, 'binary': ${this.opts["binary"] ?? void 0}, 'norm': ${this.opts["norm"] ?? void 0}, 'alternate_sign': ${this.opts["alternate_sign"] ?? void 0}, 'dtype': ${this.opts["dtype"] ?? void 0}}

ctor_HashingVectorizer = {k: v for k, v in ctor_HashingVectorizer.items() if v is not None}`;
    await this._py.ex`bridgeHashingVectorizer[${this.id}] = HashingVectorizer(**ctor_HashingVectorizer)`;
    this._isInitialized = true;
  }
  /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
  async dispose() {
    if (this._isDisposed) {
      return;
    }
    if (!this._isInitialized) {
      return;
    }
    await this._py.ex`del bridgeHashingVectorizer[${this.id}]`;
    this._isDisposed = true;
  }
  /**
      Return a callable to process input data.
  
      The callable handles preprocessing, tokenization, and n-grams generation.
     */
  async build_analyzer(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This HashingVectorizer instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "HashingVectorizer must call init() before build_analyzer()"
      );
    }
    await this._py.ex`pms_HashingVectorizer_build_analyzer = {}

pms_HashingVectorizer_build_analyzer = {k: v for k, v in pms_HashingVectorizer_build_analyzer.items() if v is not None}`;
    await this._py.ex`res_HashingVectorizer_build_analyzer = bridgeHashingVectorizer[${this.id}].build_analyzer(**pms_HashingVectorizer_build_analyzer)`;
    return this._py`res_HashingVectorizer_build_analyzer.tolist() if hasattr(res_HashingVectorizer_build_analyzer, 'tolist') else res_HashingVectorizer_build_analyzer`;
  }
  /**
    Return a function to preprocess the text before tokenization.
   */
  async build_preprocessor(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This HashingVectorizer instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "HashingVectorizer must call init() before build_preprocessor()"
      );
    }
    await this._py.ex`pms_HashingVectorizer_build_preprocessor = {}

pms_HashingVectorizer_build_preprocessor = {k: v for k, v in pms_HashingVectorizer_build_preprocessor.items() if v is not None}`;
    await this._py.ex`res_HashingVectorizer_build_preprocessor = bridgeHashingVectorizer[${this.id}].build_preprocessor(**pms_HashingVectorizer_build_preprocessor)`;
    return this._py`res_HashingVectorizer_build_preprocessor.tolist() if hasattr(res_HashingVectorizer_build_preprocessor, 'tolist') else res_HashingVectorizer_build_preprocessor`;
  }
  /**
    Return a function that splits a string into a sequence of tokens.
   */
  async build_tokenizer(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This HashingVectorizer instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "HashingVectorizer must call init() before build_tokenizer()"
      );
    }
    await this._py.ex`pms_HashingVectorizer_build_tokenizer = {}

pms_HashingVectorizer_build_tokenizer = {k: v for k, v in pms_HashingVectorizer_build_tokenizer.items() if v is not None}`;
    await this._py.ex`res_HashingVectorizer_build_tokenizer = bridgeHashingVectorizer[${this.id}].build_tokenizer(**pms_HashingVectorizer_build_tokenizer)`;
    return this._py`res_HashingVectorizer_build_tokenizer.tolist() if hasattr(res_HashingVectorizer_build_tokenizer, 'tolist') else res_HashingVectorizer_build_tokenizer`;
  }
  /**
      Decode the input into a string of unicode symbols.
  
      The decoding strategy depends on the vectorizer parameters.
     */
  async decode(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This HashingVectorizer instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("HashingVectorizer must call init() before decode()");
    }
    await this._py.ex`pms_HashingVectorizer_decode = {'doc': ${opts["doc"] ?? void 0}}

pms_HashingVectorizer_decode = {k: v for k, v in pms_HashingVectorizer_decode.items() if v is not None}`;
    await this._py.ex`res_HashingVectorizer_decode = bridgeHashingVectorizer[${this.id}].decode(**pms_HashingVectorizer_decode)`;
    return this._py`res_HashingVectorizer_decode.tolist() if hasattr(res_HashingVectorizer_decode, 'tolist') else res_HashingVectorizer_decode`;
  }
  /**
      Only validates estimator’s parameters.
  
      This method allows to: (i) validate the estimator’s parameters and (ii) be consistent with the scikit-learn transformer API.
     */
  async fit(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This HashingVectorizer instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("HashingVectorizer must call init() before fit()");
    }
    await this._py.ex`pms_HashingVectorizer_fit = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': ${opts["y"] ?? void 0}}

pms_HashingVectorizer_fit = {k: v for k, v in pms_HashingVectorizer_fit.items() if v is not None}`;
    await this._py.ex`res_HashingVectorizer_fit = bridgeHashingVectorizer[${this.id}].fit(**pms_HashingVectorizer_fit)`;
    return this._py`res_HashingVectorizer_fit.tolist() if hasattr(res_HashingVectorizer_fit, 'tolist') else res_HashingVectorizer_fit`;
  }
  /**
    Transform a sequence of documents to a document-term matrix.
   */
  async fit_transform(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This HashingVectorizer instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "HashingVectorizer must call init() before fit_transform()"
      );
    }
    await this._py.ex`pms_HashingVectorizer_fit_transform = {'X': ${opts["X"] ?? void 0}, 'y': ${opts["y"] ?? void 0}}

pms_HashingVectorizer_fit_transform = {k: v for k, v in pms_HashingVectorizer_fit_transform.items() if v is not None}`;
    await this._py.ex`res_HashingVectorizer_fit_transform = bridgeHashingVectorizer[${this.id}].fit_transform(**pms_HashingVectorizer_fit_transform)`;
    return this._py`res_HashingVectorizer_fit_transform.tolist() if hasattr(res_HashingVectorizer_fit_transform, 'tolist') else res_HashingVectorizer_fit_transform`;
  }
  /**
    Build or fetch the effective stop words list.
   */
  async get_stop_words(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This HashingVectorizer instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "HashingVectorizer must call init() before get_stop_words()"
      );
    }
    await this._py.ex`pms_HashingVectorizer_get_stop_words = {}

pms_HashingVectorizer_get_stop_words = {k: v for k, v in pms_HashingVectorizer_get_stop_words.items() if v is not None}`;
    await this._py.ex`res_HashingVectorizer_get_stop_words = bridgeHashingVectorizer[${this.id}].get_stop_words(**pms_HashingVectorizer_get_stop_words)`;
    return this._py`res_HashingVectorizer_get_stop_words.tolist() if hasattr(res_HashingVectorizer_get_stop_words, 'tolist') else res_HashingVectorizer_get_stop_words`;
  }
  /**
      Only validates estimator’s parameters.
  
      This method allows to: (i) validate the estimator’s parameters and (ii) be consistent with the scikit-learn transformer API.
     */
  async partial_fit(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This HashingVectorizer instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("HashingVectorizer must call init() before partial_fit()");
    }
    await this._py.ex`pms_HashingVectorizer_partial_fit = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': ${opts["y"] ?? void 0}}

pms_HashingVectorizer_partial_fit = {k: v for k, v in pms_HashingVectorizer_partial_fit.items() if v is not None}`;
    await this._py.ex`res_HashingVectorizer_partial_fit = bridgeHashingVectorizer[${this.id}].partial_fit(**pms_HashingVectorizer_partial_fit)`;
    return this._py`res_HashingVectorizer_partial_fit.tolist() if hasattr(res_HashingVectorizer_partial_fit, 'tolist') else res_HashingVectorizer_partial_fit`;
  }
  /**
      Set output container.
  
      See [Introducing the set\_output API](../../auto_examples/miscellaneous/plot_set_output.html#sphx-glr-auto-examples-miscellaneous-plot-set-output-py) for an example on how to use the API.
     */
  async set_output(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This HashingVectorizer instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("HashingVectorizer must call init() before set_output()");
    }
    await this._py.ex`pms_HashingVectorizer_set_output = {'transform': ${opts["transform"] ?? void 0}}

pms_HashingVectorizer_set_output = {k: v for k, v in pms_HashingVectorizer_set_output.items() if v is not None}`;
    await this._py.ex`res_HashingVectorizer_set_output = bridgeHashingVectorizer[${this.id}].set_output(**pms_HashingVectorizer_set_output)`;
    return this._py`res_HashingVectorizer_set_output.tolist() if hasattr(res_HashingVectorizer_set_output, 'tolist') else res_HashingVectorizer_set_output`;
  }
  /**
    Transform a sequence of documents to a document-term matrix.
   */
  async transform(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This HashingVectorizer instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("HashingVectorizer must call init() before transform()");
    }
    await this._py.ex`pms_HashingVectorizer_transform = {'X': ${opts["X"] ?? void 0}}

pms_HashingVectorizer_transform = {k: v for k, v in pms_HashingVectorizer_transform.items() if v is not None}`;
    await this._py.ex`res_HashingVectorizer_transform = bridgeHashingVectorizer[${this.id}].transform(**pms_HashingVectorizer_transform)`;
    return this._py`res_HashingVectorizer_transform.tolist() if hasattr(res_HashingVectorizer_transform, 'tolist') else res_HashingVectorizer_transform`;
  }
};

// src/generated/feature_extraction/text/TfidfTransformer.ts
import crypto3 from "node:crypto";
var TfidfTransformer = class {
  constructor(opts) {
    this._isInitialized = false;
    this._isDisposed = false;
    this.id = `TfidfTransformer${crypto3.randomUUID().split("-")[0]}`;
    this.opts = opts || {};
  }
  get py() {
    return this._py;
  }
  set py(pythonBridge) {
    this._py = pythonBridge;
  }
  /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
  async init(py) {
    if (this._isDisposed) {
      throw new Error(
        "This TfidfTransformer instance has already been disposed"
      );
    }
    if (this._isInitialized) {
      return;
    }
    if (!py) {
      throw new Error("TfidfTransformer.init requires a PythonBridge instance");
    }
    this._py = py;
    await this._py.ex`
import numpy as np
from sklearn.feature_extraction.text import TfidfTransformer
try: bridgeTfidfTransformer
except NameError: bridgeTfidfTransformer = {}
`;
    await this._py.ex`ctor_TfidfTransformer = {'norm': ${this.opts["norm"] ?? void 0}, 'use_idf': ${this.opts["use_idf"] ?? void 0}, 'smooth_idf': ${this.opts["smooth_idf"] ?? void 0}, 'sublinear_tf': ${this.opts["sublinear_tf"] ?? void 0}}

ctor_TfidfTransformer = {k: v for k, v in ctor_TfidfTransformer.items() if v is not None}`;
    await this._py.ex`bridgeTfidfTransformer[${this.id}] = TfidfTransformer(**ctor_TfidfTransformer)`;
    this._isInitialized = true;
  }
  /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
  async dispose() {
    if (this._isDisposed) {
      return;
    }
    if (!this._isInitialized) {
      return;
    }
    await this._py.ex`del bridgeTfidfTransformer[${this.id}]`;
    this._isDisposed = true;
  }
  /**
    Learn the idf vector (global term weights).
   */
  async fit(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This TfidfTransformer instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("TfidfTransformer must call init() before fit()");
    }
    await this._py.ex`pms_TfidfTransformer_fit = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': ${opts["y"] ?? void 0}}

pms_TfidfTransformer_fit = {k: v for k, v in pms_TfidfTransformer_fit.items() if v is not None}`;
    await this._py.ex`res_TfidfTransformer_fit = bridgeTfidfTransformer[${this.id}].fit(**pms_TfidfTransformer_fit)`;
    return this._py`res_TfidfTransformer_fit.tolist() if hasattr(res_TfidfTransformer_fit, 'tolist') else res_TfidfTransformer_fit`;
  }
  /**
      Fit to data, then transform it.
  
      Fits transformer to `X` and `y` with optional parameters `fit\_params` and returns a transformed version of `X`.
     */
  async fit_transform(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This TfidfTransformer instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "TfidfTransformer must call init() before fit_transform()"
      );
    }
    await this._py.ex`pms_TfidfTransformer_fit_transform = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None, 'y': np.array(${opts["y"] ?? void 0}) if ${opts["y"] !== void 0} else None, 'fit_params': ${opts["fit_params"] ?? void 0}}

pms_TfidfTransformer_fit_transform = {k: v for k, v in pms_TfidfTransformer_fit_transform.items() if v is not None}`;
    await this._py.ex`res_TfidfTransformer_fit_transform = bridgeTfidfTransformer[${this.id}].fit_transform(**pms_TfidfTransformer_fit_transform)`;
    return this._py`res_TfidfTransformer_fit_transform.tolist() if hasattr(res_TfidfTransformer_fit_transform, 'tolist') else res_TfidfTransformer_fit_transform`;
  }
  /**
    Get output feature names for transformation.
   */
  async get_feature_names_out(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This TfidfTransformer instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "TfidfTransformer must call init() before get_feature_names_out()"
      );
    }
    await this._py.ex`pms_TfidfTransformer_get_feature_names_out = {'input_features': ${opts["input_features"] ?? void 0}}

pms_TfidfTransformer_get_feature_names_out = {k: v for k, v in pms_TfidfTransformer_get_feature_names_out.items() if v is not None}`;
    await this._py.ex`res_TfidfTransformer_get_feature_names_out = bridgeTfidfTransformer[${this.id}].get_feature_names_out(**pms_TfidfTransformer_get_feature_names_out)`;
    return this._py`res_TfidfTransformer_get_feature_names_out.tolist() if hasattr(res_TfidfTransformer_get_feature_names_out, 'tolist') else res_TfidfTransformer_get_feature_names_out`;
  }
  /**
      Set output container.
  
      See [Introducing the set\_output API](../../auto_examples/miscellaneous/plot_set_output.html#sphx-glr-auto-examples-miscellaneous-plot-set-output-py) for an example on how to use the API.
     */
  async set_output(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This TfidfTransformer instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("TfidfTransformer must call init() before set_output()");
    }
    await this._py.ex`pms_TfidfTransformer_set_output = {'transform': ${opts["transform"] ?? void 0}}

pms_TfidfTransformer_set_output = {k: v for k, v in pms_TfidfTransformer_set_output.items() if v is not None}`;
    await this._py.ex`res_TfidfTransformer_set_output = bridgeTfidfTransformer[${this.id}].set_output(**pms_TfidfTransformer_set_output)`;
    return this._py`res_TfidfTransformer_set_output.tolist() if hasattr(res_TfidfTransformer_set_output, 'tolist') else res_TfidfTransformer_set_output`;
  }
  /**
    Transform a count matrix to a tf or tf-idf representation.
   */
  async transform(opts) {
    if (this._isDisposed) {
      throw new Error(
        "This TfidfTransformer instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error("TfidfTransformer must call init() before transform()");
    }
    await this._py.ex`pms_TfidfTransformer_transform = {'X': ${opts["X"] ?? void 0}, 'copy': ${opts["copy"] ?? void 0}}

pms_TfidfTransformer_transform = {k: v for k, v in pms_TfidfTransformer_transform.items() if v is not None}`;
    await this._py.ex`res_TfidfTransformer_transform = bridgeTfidfTransformer[${this.id}].transform(**pms_TfidfTransformer_transform)`;
    return this._py`res_TfidfTransformer_transform.tolist() if hasattr(res_TfidfTransformer_transform, 'tolist') else res_TfidfTransformer_transform`;
  }
  /**
    Number of features seen during [fit](../../glossary.html#term-fit).
   */
  get n_features_in_() {
    if (this._isDisposed) {
      throw new Error(
        "This TfidfTransformer instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "TfidfTransformer must call init() before accessing n_features_in_"
      );
    }
    return (async () => {
      await this._py.ex`attr_TfidfTransformer_n_features_in_ = bridgeTfidfTransformer[${this.id}].n_features_in_`;
      return this._py`attr_TfidfTransformer_n_features_in_.tolist() if hasattr(attr_TfidfTransformer_n_features_in_, 'tolist') else attr_TfidfTransformer_n_features_in_`;
    })();
  }
  /**
    Names of features seen during [fit](../../glossary.html#term-fit). Defined only when `X` has feature names that are all strings.
   */
  get feature_names_in_() {
    if (this._isDisposed) {
      throw new Error(
        "This TfidfTransformer instance has already been disposed"
      );
    }
    if (!this._isInitialized) {
      throw new Error(
        "TfidfTransformer must call init() before accessing feature_names_in_"
      );
    }
    return (async () => {
      await this._py.ex`attr_TfidfTransformer_feature_names_in_ = bridgeTfidfTransformer[${this.id}].feature_names_in_`;
      return this._py`attr_TfidfTransformer_feature_names_in_.tolist() if hasattr(attr_TfidfTransformer_feature_names_in_, 'tolist') else attr_TfidfTransformer_feature_names_in_`;
    })();
  }
};

// src/generated/feature_extraction/text/TfidfVectorizer.ts
import crypto4 from "node:crypto";
var TfidfVectorizer = class {
  constructor(opts) {
    this._isInitialized = false;
    this._isDisposed = false;
    this.id = `TfidfVectorizer${crypto4.randomUUID().split("-")[0]}`;
    this.opts = opts || {};
  }
  get py() {
    return this._py;
  }
  set py(pythonBridge) {
    this._py = pythonBridge;
  }
  /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
  async init(py) {
    if (this._isDisposed) {
      throw new Error("This TfidfVectorizer instance has already been disposed");
    }
    if (this._isInitialized) {
      return;
    }
    if (!py) {
      throw new Error("TfidfVectorizer.init requires a PythonBridge instance");
    }
    this._py = py;
    await this._py.ex`
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
try: bridgeTfidfVectorizer
except NameError: bridgeTfidfVectorizer = {}
`;
    await this._py.ex`ctor_TfidfVectorizer = {'input': ${this.opts["input"] ?? void 0}, 'encoding': ${this.opts["encoding"] ?? void 0}, 'decode_error': ${this.opts["decode_error"] ?? void 0}, 'strip_accents': ${this.opts["strip_accents"] ?? void 0}, 'lowercase': ${this.opts["lowercase"] ?? void 0}, 'preprocessor': ${this.opts["preprocessor"] ?? void 0}, 'tokenizer': ${this.opts["tokenizer"] ?? void 0}, 'analyzer': ${this.opts["analyzer"] ?? void 0}, 'stop_words': ${this.opts["stop_words"] ?? void 0}, 'token_pattern': ${this.opts["token_pattern"] ?? void 0}, 'ngram_range': ${this.opts["ngram_range"] ?? void 0}, 'max_df': ${this.opts["max_df"] ?? void 0}, 'min_df': ${this.opts["min_df"] ?? void 0}, 'max_features': ${this.opts["max_features"] ?? void 0}, 'vocabulary': ${this.opts["vocabulary"] ?? void 0}, 'binary': ${this.opts["binary"] ?? void 0}, 'dtype': ${this.opts["dtype"] ?? void 0}, 'norm': ${this.opts["norm"] ?? void 0}, 'use_idf': ${this.opts["use_idf"] ?? void 0}, 'smooth_idf': ${this.opts["smooth_idf"] ?? void 0}, 'sublinear_tf': ${this.opts["sublinear_tf"] ?? void 0}}

ctor_TfidfVectorizer = {k: v for k, v in ctor_TfidfVectorizer.items() if v is not None}`;
    await this._py.ex`bridgeTfidfVectorizer[${this.id}] = TfidfVectorizer(**ctor_TfidfVectorizer)`;
    this._isInitialized = true;
  }
  /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
  async dispose() {
    if (this._isDisposed) {
      return;
    }
    if (!this._isInitialized) {
      return;
    }
    await this._py.ex`del bridgeTfidfVectorizer[${this.id}]`;
    this._isDisposed = true;
  }
  /**
      Return a callable to process input data.
  
      The callable handles preprocessing, tokenization, and n-grams generation.
     */
  async build_analyzer(opts) {
    if (this._isDisposed) {
      throw new Error("This TfidfVectorizer instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "TfidfVectorizer must call init() before build_analyzer()"
      );
    }
    await this._py.ex`pms_TfidfVectorizer_build_analyzer = {}

pms_TfidfVectorizer_build_analyzer = {k: v for k, v in pms_TfidfVectorizer_build_analyzer.items() if v is not None}`;
    await this._py.ex`res_TfidfVectorizer_build_analyzer = bridgeTfidfVectorizer[${this.id}].build_analyzer(**pms_TfidfVectorizer_build_analyzer)`;
    return this._py`res_TfidfVectorizer_build_analyzer.tolist() if hasattr(res_TfidfVectorizer_build_analyzer, 'tolist') else res_TfidfVectorizer_build_analyzer`;
  }
  /**
    Return a function to preprocess the text before tokenization.
   */
  async build_preprocessor(opts) {
    if (this._isDisposed) {
      throw new Error("This TfidfVectorizer instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "TfidfVectorizer must call init() before build_preprocessor()"
      );
    }
    await this._py.ex`pms_TfidfVectorizer_build_preprocessor = {}

pms_TfidfVectorizer_build_preprocessor = {k: v for k, v in pms_TfidfVectorizer_build_preprocessor.items() if v is not None}`;
    await this._py.ex`res_TfidfVectorizer_build_preprocessor = bridgeTfidfVectorizer[${this.id}].build_preprocessor(**pms_TfidfVectorizer_build_preprocessor)`;
    return this._py`res_TfidfVectorizer_build_preprocessor.tolist() if hasattr(res_TfidfVectorizer_build_preprocessor, 'tolist') else res_TfidfVectorizer_build_preprocessor`;
  }
  /**
    Return a function that splits a string into a sequence of tokens.
   */
  async build_tokenizer(opts) {
    if (this._isDisposed) {
      throw new Error("This TfidfVectorizer instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "TfidfVectorizer must call init() before build_tokenizer()"
      );
    }
    await this._py.ex`pms_TfidfVectorizer_build_tokenizer = {}

pms_TfidfVectorizer_build_tokenizer = {k: v for k, v in pms_TfidfVectorizer_build_tokenizer.items() if v is not None}`;
    await this._py.ex`res_TfidfVectorizer_build_tokenizer = bridgeTfidfVectorizer[${this.id}].build_tokenizer(**pms_TfidfVectorizer_build_tokenizer)`;
    return this._py`res_TfidfVectorizer_build_tokenizer.tolist() if hasattr(res_TfidfVectorizer_build_tokenizer, 'tolist') else res_TfidfVectorizer_build_tokenizer`;
  }
  /**
      Decode the input into a string of unicode symbols.
  
      The decoding strategy depends on the vectorizer parameters.
     */
  async decode(opts) {
    if (this._isDisposed) {
      throw new Error("This TfidfVectorizer instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("TfidfVectorizer must call init() before decode()");
    }
    await this._py.ex`pms_TfidfVectorizer_decode = {'doc': ${opts["doc"] ?? void 0}}

pms_TfidfVectorizer_decode = {k: v for k, v in pms_TfidfVectorizer_decode.items() if v is not None}`;
    await this._py.ex`res_TfidfVectorizer_decode = bridgeTfidfVectorizer[${this.id}].decode(**pms_TfidfVectorizer_decode)`;
    return this._py`res_TfidfVectorizer_decode.tolist() if hasattr(res_TfidfVectorizer_decode, 'tolist') else res_TfidfVectorizer_decode`;
  }
  /**
    Learn vocabulary and idf from training set.
   */
  async fit(opts) {
    if (this._isDisposed) {
      throw new Error("This TfidfVectorizer instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("TfidfVectorizer must call init() before fit()");
    }
    await this._py.ex`pms_TfidfVectorizer_fit = {'raw_documents': ${opts["raw_documents"] ?? void 0}, 'y': ${opts["y"] ?? void 0}}

pms_TfidfVectorizer_fit = {k: v for k, v in pms_TfidfVectorizer_fit.items() if v is not None}`;
    await this._py.ex`res_TfidfVectorizer_fit = bridgeTfidfVectorizer[${this.id}].fit(**pms_TfidfVectorizer_fit)`;
    return this._py`res_TfidfVectorizer_fit.tolist() if hasattr(res_TfidfVectorizer_fit, 'tolist') else res_TfidfVectorizer_fit`;
  }
  /**
      Learn vocabulary and idf, return document-term matrix.
  
      This is equivalent to fit followed by transform, but more efficiently implemented.
     */
  async fit_transform(opts) {
    if (this._isDisposed) {
      throw new Error("This TfidfVectorizer instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("TfidfVectorizer must call init() before fit_transform()");
    }
    await this._py.ex`pms_TfidfVectorizer_fit_transform = {'raw_documents': ${opts["raw_documents"] ?? void 0}, 'y': ${opts["y"] ?? void 0}}

pms_TfidfVectorizer_fit_transform = {k: v for k, v in pms_TfidfVectorizer_fit_transform.items() if v is not None}`;
    await this._py.ex`res_TfidfVectorizer_fit_transform = bridgeTfidfVectorizer[${this.id}].fit_transform(**pms_TfidfVectorizer_fit_transform)`;
    return this._py`res_TfidfVectorizer_fit_transform.tolist() if hasattr(res_TfidfVectorizer_fit_transform, 'tolist') else res_TfidfVectorizer_fit_transform`;
  }
  /**
    Get output feature names for transformation.
   */
  async get_feature_names_out(opts) {
    if (this._isDisposed) {
      throw new Error("This TfidfVectorizer instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "TfidfVectorizer must call init() before get_feature_names_out()"
      );
    }
    await this._py.ex`pms_TfidfVectorizer_get_feature_names_out = {'input_features': ${opts["input_features"] ?? void 0}}

pms_TfidfVectorizer_get_feature_names_out = {k: v for k, v in pms_TfidfVectorizer_get_feature_names_out.items() if v is not None}`;
    await this._py.ex`res_TfidfVectorizer_get_feature_names_out = bridgeTfidfVectorizer[${this.id}].get_feature_names_out(**pms_TfidfVectorizer_get_feature_names_out)`;
    return this._py`res_TfidfVectorizer_get_feature_names_out.tolist() if hasattr(res_TfidfVectorizer_get_feature_names_out, 'tolist') else res_TfidfVectorizer_get_feature_names_out`;
  }
  /**
    Build or fetch the effective stop words list.
   */
  async get_stop_words(opts) {
    if (this._isDisposed) {
      throw new Error("This TfidfVectorizer instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "TfidfVectorizer must call init() before get_stop_words()"
      );
    }
    await this._py.ex`pms_TfidfVectorizer_get_stop_words = {}

pms_TfidfVectorizer_get_stop_words = {k: v for k, v in pms_TfidfVectorizer_get_stop_words.items() if v is not None}`;
    await this._py.ex`res_TfidfVectorizer_get_stop_words = bridgeTfidfVectorizer[${this.id}].get_stop_words(**pms_TfidfVectorizer_get_stop_words)`;
    return this._py`res_TfidfVectorizer_get_stop_words.tolist() if hasattr(res_TfidfVectorizer_get_stop_words, 'tolist') else res_TfidfVectorizer_get_stop_words`;
  }
  /**
    Return terms per document with nonzero entries in X.
   */
  async inverse_transform(opts) {
    if (this._isDisposed) {
      throw new Error("This TfidfVectorizer instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "TfidfVectorizer must call init() before inverse_transform()"
      );
    }
    await this._py.ex`pms_TfidfVectorizer_inverse_transform = {'X': np.array(${opts["X"] ?? void 0}) if ${opts["X"] !== void 0} else None}

pms_TfidfVectorizer_inverse_transform = {k: v for k, v in pms_TfidfVectorizer_inverse_transform.items() if v is not None}`;
    await this._py.ex`res_TfidfVectorizer_inverse_transform = bridgeTfidfVectorizer[${this.id}].inverse_transform(**pms_TfidfVectorizer_inverse_transform)`;
    return this._py`res_TfidfVectorizer_inverse_transform.tolist() if hasattr(res_TfidfVectorizer_inverse_transform, 'tolist') else res_TfidfVectorizer_inverse_transform`;
  }
  /**
      Transform documents to document-term matrix.
  
      Uses the vocabulary and document frequencies (df) learned by fit (or fit\_transform).
     */
  async transform(opts) {
    if (this._isDisposed) {
      throw new Error("This TfidfVectorizer instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error("TfidfVectorizer must call init() before transform()");
    }
    await this._py.ex`pms_TfidfVectorizer_transform = {'raw_documents': ${opts["raw_documents"] ?? void 0}}

pms_TfidfVectorizer_transform = {k: v for k, v in pms_TfidfVectorizer_transform.items() if v is not None}`;
    await this._py.ex`res_TfidfVectorizer_transform = bridgeTfidfVectorizer[${this.id}].transform(**pms_TfidfVectorizer_transform)`;
    return this._py`res_TfidfVectorizer_transform.tolist() if hasattr(res_TfidfVectorizer_transform, 'tolist') else res_TfidfVectorizer_transform`;
  }
  /**
    A mapping of terms to feature indices.
   */
  get vocabulary_() {
    if (this._isDisposed) {
      throw new Error("This TfidfVectorizer instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "TfidfVectorizer must call init() before accessing vocabulary_"
      );
    }
    return (async () => {
      await this._py.ex`attr_TfidfVectorizer_vocabulary_ = bridgeTfidfVectorizer[${this.id}].vocabulary_`;
      return this._py`attr_TfidfVectorizer_vocabulary_.tolist() if hasattr(attr_TfidfVectorizer_vocabulary_, 'tolist') else attr_TfidfVectorizer_vocabulary_`;
    })();
  }
  /**
    True if a fixed vocabulary of term to indices mapping is provided by the user.
   */
  get fixed_vocabulary_() {
    if (this._isDisposed) {
      throw new Error("This TfidfVectorizer instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "TfidfVectorizer must call init() before accessing fixed_vocabulary_"
      );
    }
    return (async () => {
      await this._py.ex`attr_TfidfVectorizer_fixed_vocabulary_ = bridgeTfidfVectorizer[${this.id}].fixed_vocabulary_`;
      return this._py`attr_TfidfVectorizer_fixed_vocabulary_.tolist() if hasattr(attr_TfidfVectorizer_fixed_vocabulary_, 'tolist') else attr_TfidfVectorizer_fixed_vocabulary_`;
    })();
  }
  /**
    Terms that were ignored because they either:
   */
  get stop_words_() {
    if (this._isDisposed) {
      throw new Error("This TfidfVectorizer instance has already been disposed");
    }
    if (!this._isInitialized) {
      throw new Error(
        "TfidfVectorizer must call init() before accessing stop_words_"
      );
    }
    return (async () => {
      await this._py.ex`attr_TfidfVectorizer_stop_words_ = bridgeTfidfVectorizer[${this.id}].stop_words_`;
      return this._py`attr_TfidfVectorizer_stop_words_.tolist() if hasattr(attr_TfidfVectorizer_stop_words_, 'tolist') else attr_TfidfVectorizer_stop_words_`;
    })();
  }
};
export {
  CountVectorizer,
  HashingVectorizer,
  TfidfTransformer,
  TfidfVectorizer
};
//# sourceMappingURL=index.js.map